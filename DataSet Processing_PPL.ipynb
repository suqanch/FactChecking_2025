{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyOKasVI0PUiSmuywCgDY+Js"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 2025 COMP90042 Project\n","\n","Group 24 Faiss Simces preprocessing pipeline\n","\n"],"metadata":{"id":"5bFN8mS9_gXk"}},{"cell_type":"markdown","source":["# 1.DataSet Processing\n","(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"],"metadata":{"id":"7LO__Dfk_kKj"}},{"cell_type":"markdown","source":["### Notebook: Ppl_preprocessing.ipynb\n","\n","This notebook is used to compute the perplexity for each evidence text, which is helpful for downstream preprocessing tasks. The notebook demonstrates perplexity computation using gold evidence from the training set as an example.\n","\n","Computing perplexity for all 1.2 million evidence texts would take approximately 7 hours on a T4 GPU. To speed up the process, we distribute the workload across multiple accounts.\n","\n","The final result, `evidence_perplexity.json`, which contains perplexity scores for 1.2 million pieces of evidence, will be available via a Google Drive link provided in the README."],"metadata":{"id":"fe6QJRhW_c-v"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from tqdm import tqdm\n","from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n","from accelerate.test_utils.testing import get_backend\n","from multiprocessing import Pool, cpu_count\n","from functools import partial\n","import json\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(cpu_count(), device)\n","# get num of gpu\n","print(torch.cuda.device_count())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yp_g4vLseZxP","executionInfo":{"status":"ok","timestamp":1747631752728,"user_tz":-600,"elapsed":21178,"user":{"displayName":"Miles He","userId":"05803022075428511954"}},"outputId":"9e3793b3-9aef-43eb-c099-8bdc21efa4de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2 cuda\n","1\n"]}]},{"cell_type":"markdown","source":["### Upload Data Files\n","\n","Upload the following files into the `data` folder:\n","\n","- `train-claims.json`\n","- `dev-claims.json`\n","- `test-claims-unlabelled.json`\n","- `evidence.json`\n","\n","### Output Files\n","\n","- `evidence_subset.json`: Contains gold evidence from train-claims in the format `{evidence_id: text}`\n","- `claims.json`: Contains claims in the format `{claim_id: text}`"],"metadata":{"id":"40eZvc1Z9G6o"}},{"cell_type":"code","source":["train_json_path = \"train-claims.json\"      # claim & evidence\n","dev_json_path = \"dev-claims.json\"      # claim & evidence\n","test_json_path = \"test-claims-unlabelled.json\"  # claim\n","evidence_json_path = \"evidence.json\"  # evidence\n","output_evidence_set_path = \"evidence_subset.json\"\n","output_claim_set_path = \"claims.json\"\n","\n","# output_dev_emb_path = \"local_data/dev-embed-1.json\"\n","\n","with open(train_json_path, \"r\", encoding=\"utf-8\") as f:\n","    train_data = json.load(f)\n","with open(dev_json_path, \"r\", encoding=\"utf-8\") as f:\n","    dev_data = json.load(f)\n","with open(test_json_path, \"r\", encoding=\"utf-8\") as f:\n","    test_data = json.load(f)\n","with open(evidence_json_path, \"r\", encoding=\"utf-8\") as f:\n","    evidence_data = json.load(f)\n","\n","#combine train and dev data\n","# merged_data = {**train_data, **dev_data}\n","merged_data = train_data\n","\n","evicence_set = {}\n","for claim_id, claim_info in merged_data.items():\n","\n","    claim_text = claim_info[\"claim_text\"]\n","    positive_ids = claim_info[\"evidences\"]\n","\n","    for pos_id in positive_ids:\n","        if pos_id not in evidence_data:\n","            print(f\"Warning: Evidence ID {pos_id} not found in evidence data.\")\n","            continue\n","        evicence_set[pos_id] = evidence_data[pos_id]\n","\n","print(len(evicence_set))\n","# Save the evidence set to a JSON file\n","with open(output_evidence_set_path, \"w\", encoding=\"utf-8\") as f:\n","    json.dump(evicence_set, f, ensure_ascii=False, indent=4)\n","\n","\n","claim_set = {}\n","\n","def get_claims(data):\n","\n","    claim_set = {}\n","    for claim_id, claim_info in data.items():\n","        claim_text = claim_info[\"claim_text\"]\n","        claim_set[claim_id] = {\n","            \"claim_text\": claim_text,\n","        }\n","    return claim_set\n","\n","train_claim_set = get_claims(train_data)\n","dev_claim_set = get_claims(dev_data)\n","test_claim_set = get_claims(test_data)\n","claim_set = {**train_claim_set, **dev_claim_set, **test_claim_set}\n","print(len(claim_set))\n","# Save the claim set to a JSON file\n","with open(output_claim_set_path, \"w\", encoding=\"utf-8\") as f:\n","    json.dump(claim_set, f, ensure_ascii=False, indent=4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZzQhqR6382al","executionInfo":{"status":"ok","timestamp":1747631754614,"user_tz":-600,"elapsed":1890,"user":{"displayName":"Miles He","userId":"05803022075428511954"}},"outputId":"08c684e9-6331-4e03-de9e-b5244cd5cf58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3121\n","1535\n"]}]},{"cell_type":"code","source":["model_id = \"openai-community/gpt2-large\"\n","model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n","tokenizer = GPT2TokenizerFast.from_pretrained(model_id)\n","tokenizer.pad_token = tokenizer.eos_token\n","model.config.pad_token_id = model.config.eos_token_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MKrCTraqGfiD","executionInfo":{"status":"ok","timestamp":1747631823197,"user_tz":-600,"elapsed":6607,"user":{"displayName":"Miles He","userId":"05803022075428511954"}},"outputId":"a5a8a273-d147-405b-8bc3-932e7cee5443"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["### Perplexity Computation\n","\n","The function `fast_perplexity_batch` computes the perplexity of a list of input texts using a language model. The formula for perplexity is given by:\n","\n","$$\n","PP(W) = \\sqrt[m]{\\frac{1}{P(W)}}\n","$$\n","\n","Taking the logarithm of both sides:\n","\n","$$\n","\\log{PP(W)} = -\\frac{1}{m} \\log{P(W)}\n","$$\n","\n","In the implementation:\n","\n","- Cross-entropy loss is used to estimate the negative log-likelihood.\n","- The loss is masked by the attention mask to ignore padding tokens.\n","- The average loss per sequence is exponentiated to get the perplexity."],"metadata":{"id":"kwJiiPIG93Jx"}},{"cell_type":"code","source":["def fast_perplexity_batch(text_list, tokenizer, model, device, max_length=128):\n","    encodings = tokenizer(text_list, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n","    input_ids = encodings.input_ids.to(device)\n","    attention_mask = encodings.attention_mask.to(device)\n","\n","    with torch.no_grad():\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","\n","    shift_logits = logits[:, :-1, :].contiguous()\n","    shift_labels = input_ids[:, 1:].contiguous()\n","    shift_attention = attention_mask[:, 1:]\n","\n","    loss_fct = torch.nn.CrossEntropyLoss(reduction=\"none\")\n","    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n","    loss = loss.view(shift_labels.size()) * shift_attention\n","\n","    seq_loss = loss.sum(dim=1) / shift_attention.sum(dim=1)\n","    perplexity = torch.exp(seq_loss)\n","    return perplexity.tolist()"],"metadata":{"id":"AkHTZqM5zkY-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_one_batch(batch_ids, batch_texts, tokenizer, model, device, max_length=128):\n","    \"\"\"\n","\n","    config\n","        batch_ids (List[str/int])\n","        batch_texts (List[str])\n","        tokenizer: Hugging Face tokenizer\n","\n","    return\n","        List[Tuple[eid, Dict]]\n","    \"\"\"\n","    results = []\n","    try:\n","        ppls = fast_perplexity_batch(batch_texts, tokenizer, model, device, max_length=max_length)\n","\n","        for eid, text, ppl in zip(batch_ids, batch_texts, ppls):\n","            results.append((eid, {\"text\": text, \"ppl\": ppl}))\n","\n","    except Exception as e:\n","        for eid, text in zip(batch_ids, batch_texts):\n","            results.append((eid, {\"text\": text, \"error\": f\"PPL error: {e}\"}))\n","\n","    return results"],"metadata":{"id":"zz1Drw4JnSdX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Run Full Evidence Perplexity Computation\n","\n","Uncomment the lines below in the notebook to compute perplexity for the full set of 1.2 million evidence texts."],"metadata":{"id":"VjAV11sB_xZU"}},{"cell_type":"code","source":["import json\n","\n","result = {}\n","save_every = 640\n","batch_size = 64\n","batch_id = 0\n","\n","# with open(\"evidence.json\", \"r\", encoding=\"utf-8\") as f:\n","#     evidence = json.load(f)\n","\n","with open(\"evidence_subset.json\", \"r\", encoding=\"utf-8\") as f:\n","    evidence = json.load(f)\n","\n","evidence = dict(list(evidence.items()))\n","print(f\"Total samples: {len(evidence)}\")\n","\n","eids = list(evidence.keys())\n","texts = list(evidence.values())\n","\n","for i in range(0, len(evidence), batch_size):\n","    batch_eids = eids[i:i + batch_size]\n","    batch_texts = texts[i:i + batch_size]\n","\n","    batch_results = process_one_batch(batch_eids, batch_texts, tokenizer, model, device)\n","\n","    for eid, res in batch_results:\n","        result[eid] = res\n","\n","    print(f\"Progress: {i + len(batch_results)}/{len(evidence)}\")\n","\n","    if (i + batch_size) % save_every == 0 or (i + batch_size) >= len(evidence):\n","        print(f'Saving batch {batch_id}: {i + batch_size} / {len(evidence)}')\n","        with open(f\"colab_partial_{batch_id}.json\", \"w\", encoding=\"utf-8\") as f:\n","            json.dump(result, f, ensure_ascii=False, indent=2)\n","        # with open(f\"drive/MyDrive/nlp_data/colab_partial_{batch_id}.json\", \"w\", encoding=\"utf-8\") as f:\n","        #     json.dump(result, f, ensure_ascii=False, indent=2)\n","        batch_id += 1\n","        result.clear()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"2CFVwvnEjnGV","outputId":"d6280a3b-6532-4aa6-8dfa-1c2ffb2c25fa","executionInfo":{"status":"ok","timestamp":1747631986790,"user_tz":-600,"elapsed":150095,"user":{"displayName":"Miles He","userId":"05803022075428511954"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total samples: 3121\n","Progress: 64/3121\n","Progress: 128/3121\n","Progress: 192/3121\n","Progress: 256/3121\n","Progress: 320/3121\n","Progress: 384/3121\n","Progress: 448/3121\n","Progress: 512/3121\n","Progress: 576/3121\n","Progress: 640/3121\n","Saving batch 0: 640 / 3121\n","Progress: 704/3121\n","Progress: 768/3121\n","Progress: 832/3121\n","Progress: 896/3121\n","Progress: 960/3121\n","Progress: 1024/3121\n","Progress: 1088/3121\n","Progress: 1152/3121\n","Progress: 1216/3121\n","Progress: 1280/3121\n","Saving batch 1: 1280 / 3121\n","Progress: 1344/3121\n","Progress: 1408/3121\n","Progress: 1472/3121\n","Progress: 1536/3121\n","Progress: 1600/3121\n","Progress: 1664/3121\n","Progress: 1728/3121\n","Progress: 1792/3121\n","Progress: 1856/3121\n","Progress: 1920/3121\n","Saving batch 2: 1920 / 3121\n","Progress: 1984/3121\n","Progress: 2048/3121\n","Progress: 2112/3121\n","Progress: 2176/3121\n","Progress: 2240/3121\n","Progress: 2304/3121\n","Progress: 2368/3121\n","Progress: 2432/3121\n","Progress: 2496/3121\n","Progress: 2560/3121\n","Saving batch 3: 2560 / 3121\n","Progress: 2624/3121\n","Progress: 2688/3121\n","Progress: 2752/3121\n","Progress: 2816/3121\n","Progress: 2880/3121\n","Progress: 2944/3121\n","Progress: 3008/3121\n","Progress: 3072/3121\n","Progress: 3121/3121\n","Saving batch 4: 3136 / 3121\n"]}]},{"cell_type":"code","source":["import glob\n","\n","result_files = glob.glob(\"colab_partial_*.json\")\n","final = {}\n","for file in result_files:\n","    with open(file, \"r\", encoding=\"utf-8\") as f:\n","        final.update(json.load(f))\n","\n","with open(\"evidence_perplexity.json\", \"w\", encoding=\"utf-8\") as f:\n","    json.dump(final, f, indent=2)"],"metadata":{"id":"3AuusT0OKV9D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Analysis Gold standard\n"],"metadata":{"id":"Go6FdeRgQrp6"}},{"cell_type":"code","source":["import json\n","with open(\"evidence_perplexity.json\", \"r\", encoding=\"utf-8\") as f:\n","    evidence = json.load(f)\n"],"metadata":{"id":"PMbz-LdXQrB0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(evidence)"],"metadata":{"id":"oNkead0cmhWW","executionInfo":{"status":"ok","timestamp":1747631986842,"user_tz":-600,"elapsed":4,"user":{"displayName":"Miles He","userId":"05803022075428511954"}},"outputId":"80a2643f-0557-4186-de38-9c157b909f27","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3364"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["good_one = {}\n","bad_one = {}\n","for eid, data in evidence.items():\n","    if (data.get(\"ppl\", 0) < 85) :\n","        ppl = data.get(\"ppl\", 0)\n","        good_one[eid] = (data)\n","    else:\n","        bad_one[eid] = data\n","print(len(bad_one), len(bad_one)/len(evidence))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5Ze4ocnpA1Y","executionInfo":{"status":"ok","timestamp":1747631986850,"user_tz":-600,"elapsed":9,"user":{"displayName":"Miles He","userId":"05803022075428511954"}},"outputId":"fbf17ea3-be7e-4b2d-b6bc-65b6564193bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["220 0.06539833531510107\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Ljz1GWUQ9u6e"},"execution_count":null,"outputs":[]}]}