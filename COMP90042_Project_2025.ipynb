{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2025 COMP90042 Project Group 24\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.*\n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpOq1mn0sHUd"
      },
      "source": [
        "# 1. EDA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6XrYmp-T9hR"
      },
      "source": [
        "## 1.1 Exmain the Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXO29Nt7V0eD"
      },
      "source": [
        "Each train data has:\n",
        "1. claim_text\n",
        "2. claim_label\n",
        "3. (multiple) evidences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qAkjjG-WJMn"
      },
      "source": [
        "### for claim_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vNemh3MTwan",
        "outputId": "c25e2e0a-818c-45a9-c27f-a0da117851ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total number of training claims: 1228\n",
            "max training claim length: 332\n",
            "min training claim length: 26\n",
            "mean training claim length: 122.95521172638436\n"
          ]
        }
      ],
      "source": [
        "claim_lengths = [len(item[\"claim_text\"]) for item in train_data.values()]\n",
        "print(\"total number of training claims:\", len(train_data))\n",
        "print(\"max training claim length:\", max(claim_lengths))\n",
        "print(\"min training claim length:\", min(claim_lengths)) \n",
        "print(\"mean training claim length:\", sum(claim_lengths) / len(claim_lengths))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws7wiU6lWME0"
      },
      "source": [
        "### for evidences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7qB5-HYT52R",
        "outputId": "07d7463c-1c4a-4df0-9ce8-b0af75d90d78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max evidence count for one training data: 5\n",
            "min evidence count for one training data: 1\n",
            "mean evidence count for one training data: 3.3566775244299674\n"
          ]
        }
      ],
      "source": [
        "evi_counts = [len(item[\"evidences\"]) for item in train_data.values()]\n",
        "print(\"max evidence count for one training data:\", max(evi_counts))\n",
        "print(\"min evidence count for one training data:\", min(evi_counts))\n",
        "print(\"mean evidence count for one training data:\", sum(evi_counts) / len(evi_counts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHpe3aDnVTzX"
      },
      "source": [
        "### for label distribution - unbalanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N--oTwwAVSHK",
        "outputId": "87a1c164-f68d-4460-f425-f8b4d1a49bb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({'SUPPORTS': 519, 'NOT_ENOUGH_INFO': 386, 'REFUTES': 199, 'DISPUTED': 124})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "labels = [item[\"claim_label\"] for item in train_data.values()]\n",
        "print(Counter(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvff21Hv8zjk",
        "outputId": "8bf161aa-e622-4461-a23f-3039dc45d076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qz_s645DMd-",
        "outputId": "0f8635df-4e53-4820-ee53-72fc42eed5db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 154 dev claims.\n",
            "Loaded 1228 train claims.\n",
            "Loaded 153 test claims.\n",
            "Loaded 1208827 evidence entries.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Set directory path\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "\n",
        "# Define file paths\n",
        "dev_claims_path = os.path.join(data_dir, \"dev-claims.json\")\n",
        "train_claims_path = os.path.join(data_dir, \"train-claims.json\")\n",
        "test_claims_path = os.path.join(data_dir, \"test-claims-unlabelled.json\")\n",
        "evidence_path = os.path.join(data_dir, \"evidence.json\")\n",
        "\n",
        "with open(dev_claims_path, \"r\") as f:\n",
        "    dev_data = json.load(f)\n",
        "print(f\"Loaded {len(dev_data)} dev claims.\")\n",
        "\n",
        "with open(train_claims_path, \"r\") as f:\n",
        "    train_data = json.load(f)\n",
        "print(f\"Loaded {len(train_data)} train claims.\")\n",
        "\n",
        "with open(test_claims_path, \"r\") as f:\n",
        "    test_data = json.load(f)\n",
        "print(f\"Loaded {len(test_data)} test claims.\")\n",
        "\n",
        "with open(evidence_path, \"r\") as f:\n",
        "    evidence = json.load(f)\n",
        "print(f\"Loaded {len(evidence)} evidence entries.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlwY1MyVG4Wr",
        "outputId": "da29668f-4ebb-4441-bed4-d4f61f07c185"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess(text, remove_stopwords=True, apply_lemma=True):\n",
        "    # Normalize unicode characters\n",
        "    text = unicodedata.normalize(\"NFKD\", text)\n",
        "\n",
        "    # Remove non-ASCII characters\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
        "\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove placeholder citations\n",
        "    text = re.sub(r'\\[citation needed\\]', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove bracketed content like [example]\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "    text = re.sub(r'[\\[\\]]', '', text)\n",
        "\n",
        "    # Remove repeated dots and normalize whitespace\n",
        "    text = re.sub(r'\\.{2,}', '.', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    text = re.sub(r'[\\'\"`“”‘’]', '', text)\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    # Remove punctuation tokens\n",
        "    tokens = [tok for tok in tokens if tok not in string.punctuation]\n",
        "\n",
        "    # Lemmatize (optional)\n",
        "    if apply_lemma:\n",
        "        tokens = [lemmatizer.lemmatize(tok) for tok in tokens]\n",
        "\n",
        "    # Remove stopwords (optional)\n",
        "    if remove_stopwords:\n",
        "        tokens = [tok for tok in tokens if tok not in stop_words]\n",
        "\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmRXD79OSjWq",
        "outputId": "76a43b2f-5a20-45e5-cd02-7d7684f0a58c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying preprocess_1 (lemma + stopwords) to evidence...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "preprocess_1: 100%|██████████| 1208827/1208827 [04:16<00:00, 4710.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying preprocess_2 (no lemma + stopwords) to evidence...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "preprocess_2: 100%|██████████| 1208827/1208827 [02:42<00:00, 7450.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying preprocess_3 (lemma + no stopwords) to evidence...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "preprocess_3: 100%|██████████| 1208827/1208827 [04:14<00:00, 4757.09it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "\n",
        "def apply_claim_preprocessing(claim_dict, preprocess_fn, field=\"claim_text\"):\n",
        "    result = {}\n",
        "    for cid, data in claim_dict.items():\n",
        "        processed = preprocess_fn(data[field])\n",
        "        result[cid] = data.copy()\n",
        "        result[cid][field] = processed\n",
        "    return result\n",
        "\n",
        "# Claim Preprocessing\n",
        "train_p1 = apply_claim_preprocessing(train_data, lambda x: preprocess(x, remove_stopwords=True, apply_lemma=True))\n",
        "train_p2 = apply_claim_preprocessing(train_data, lambda x: preprocess(x, remove_stopwords=True, apply_lemma=False))\n",
        "train_p3 = apply_claim_preprocessing(train_data, lambda x: preprocess(x, remove_stopwords=False, apply_lemma=True))\n",
        "\n",
        "dev_p1 = apply_claim_preprocessing(dev_data, lambda x: preprocess(x, remove_stopwords=True, apply_lemma=True))\n",
        "dev_p2 = apply_claim_preprocessing(dev_data, lambda x: preprocess(x, remove_stopwords=True, apply_lemma=False))\n",
        "dev_p3 = apply_claim_preprocessing(dev_data, lambda x: preprocess(x, remove_stopwords=False, apply_lemma=True))\n",
        "\n",
        "test_p1 = apply_claim_preprocessing(test_data, lambda x: preprocess(x, remove_stopwords=True, apply_lemma=True))\n",
        "test_p2 = apply_claim_preprocessing(test_data, lambda x: preprocess(x, remove_stopwords=True, apply_lemma=False))\n",
        "test_p3 = apply_claim_preprocessing(test_data, lambda x: preprocess(x, remove_stopwords=False, apply_lemma=True))\n",
        "\n",
        "# Evidence Preprocessing\n",
        "evidence_p1, evidence_p2, evidence_p3 = {}, {}, {}\n",
        "\n",
        "print(\"Applying preprocess_1 (lemma + stopwords) to evidence...\")\n",
        "for k in tqdm(evidence, desc=\"preprocess_1\"):\n",
        "    evidence_p1[k] = preprocess(evidence[k], remove_stopwords=True, apply_lemma=True)\n",
        "\n",
        "print(\"Applying preprocess_2 (no lemma + stopwords) to evidence...\")\n",
        "for k in tqdm(evidence, desc=\"preprocess_2\"):\n",
        "    evidence_p2[k] = preprocess(evidence[k], remove_stopwords=True, apply_lemma=False)\n",
        "\n",
        "print(\"Applying preprocess_3 (lemma + no stopwords) to evidence...\")\n",
        "for k in tqdm(evidence, desc=\"preprocess_3\"):\n",
        "    evidence_p3[k] = preprocess(evidence[k], remove_stopwords=False, apply_lemma=True)\n",
        "\n",
        "json.dump(train_p1, open(os.path.join(data_dir, \"train-claims-preprocessed1.json\"), \"w\"), indent=2)\n",
        "json.dump(train_p2, open(os.path.join(data_dir, \"train-claims-preprocessed2.json\"), \"w\"), indent=2)\n",
        "json.dump(train_p3, open(os.path.join(data_dir, \"train-claims-preprocessed3.json\"), \"w\"), indent=2)\n",
        "\n",
        "json.dump(dev_p1, open(os.path.join(data_dir, \"dev-claims-preprocessed1.json\"), \"w\"), indent=2)\n",
        "json.dump(dev_p2, open(os.path.join(data_dir, \"dev-claims-preprocessed2.json\"), \"w\"), indent=2)\n",
        "json.dump(dev_p3, open(os.path.join(data_dir, \"dev-claims-preprocessed3.json\"), \"w\"), indent=2)\n",
        "\n",
        "json.dump(test_p1, open(os.path.join(data_dir, \"test-claims-unlabelled-preprocessed1.json\"), \"w\"), indent=2)\n",
        "json.dump(test_p2, open(os.path.join(data_dir, \"test-claims-unlabelled-preprocessed2.json\"), \"w\"), indent=2)\n",
        "json.dump(test_p3, open(os.path.join(data_dir, \"test-claims-unlabelled-preprocessed3.json\"), \"w\"), indent=2)\n",
        "\n",
        "json.dump(evidence_p1, open(os.path.join(data_dir, \"evidence-preprocessed1.json\"), \"w\"), indent=2)\n",
        "json.dump(evidence_p2, open(os.path.join(data_dir, \"evidence-preprocessed2.json\"), \"w\"), indent=2)\n",
        "json.dump(evidence_p3, open(os.path.join(data_dir, \"evidence-preprocessed3.json\"), \"w\"), indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Gr4a9ucXI4h"
      },
      "outputs": [],
      "source": [
        "# Preview of three preprocessing mthods\n",
        "first_claim_id = next(iter(train_data))\n",
        "first_evidence_id = next(iter(evidence))\n",
        "\n",
        "original_claim = train_data[first_claim_id][\"claim_text\"]\n",
        "preprocessed_claim_p1 = train_p1[first_claim_id][\"claim_text\"]\n",
        "preprocessed_claim_p2 = train_p2[first_claim_id][\"claim_text\"]\n",
        "preprocessed_claim_p3 = train_p3[first_claim_id][\"claim_text\"]\n",
        "\n",
        "print(\"Original claim:\")\n",
        "print(original_claim)\n",
        "print(\"\\n Preprocessed claim (preprocess_1: lemma + stopwords removed):\")\n",
        "print(preprocessed_claim_p1)\n",
        "print(\"\\n Preprocessed claim (preprocess_2: no lemma + stopwords removed):\")\n",
        "print(preprocessed_claim_p2)\n",
        "print(\"\\n Preprocessed claim (preprocess_3: lemma + stopwords kept):\")\n",
        "print(preprocessed_claim_p3)\n",
        "\n",
        "original_evidence = evidence[first_evidence_id]\n",
        "preprocessed_evidence_p1 = evidence_p1[first_evidence_id]\n",
        "preprocessed_evidence_p2 = evidence_p2[first_evidence_id]\n",
        "preprocessed_evidence_p3 = evidence_p3[first_evidence_id]\n",
        "\n",
        "print(\"\\n\\n Original evidence:\")\n",
        "print(original_evidence)\n",
        "print(\"\\n Preprocessed evidence (preprocess_1: lemma + stopwords removed):\")\n",
        "print(preprocessed_evidence_p1)\n",
        "print(\"\\n Preprocessed evidence (preprocess_2: no lemma + stopwords removed):\")\n",
        "print(preprocessed_evidence_p2)\n",
        "print(\"\\n Preprocessed evidence (preprocess_3: lemma + stopwords kept):\")\n",
        "print(preprocessed_evidence_p3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBiIofDQgkYD",
        "outputId": "0629a6c1-c0e9-427d-c586-0e1ff35c04a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Collecting evidence_p1 texts: 100%|██████████| 1208827/1208827 [00:00<00:00, 2058748.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔧 TF-IDF Vectorizing...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitting TF-IDF on evidence: 100%|██████████| 1208827/1208827 [00:08<00:00, 147232.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ TF-IDF vectors and model saved.\n",
            "\n",
            "🔧 BoW Vectorizing...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitting BoW on evidence: 100%|██████████| 1208827/1208827 [00:08<00:00, 147262.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ BoW vectors and model saved.\n",
            "\n",
            "📐 Vector Shapes:\n",
            "TF-IDF (train):    (1228, 5000)\n",
            "TF-IDF (evidence): (1208827, 5000)\n",
            "BoW (train):       (1228, 5000)\n",
            "BoW (evidence):    (1208827, 5000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import scipy.sparse\n",
        "import joblib\n",
        "\n",
        "def whitespace_tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "train_p1_texts = [claim[\"claim_text\"] for claim in train_p1.values()]\n",
        "evidence_p1_ids = list(evidence_p1.keys())\n",
        "evidence_p1_texts = [evidence_p1[eid] for eid in tqdm(evidence_p1_ids, desc=\"Collecting evidence_p1 texts\")]\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "print(\"\\n TF-IDF Vectorizing...\")\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, tokenizer=whitespace_tokenizer)\n",
        "evidence_p1_tfidf = tfidf_vectorizer.fit_transform(tqdm(evidence_p1_texts, desc=\"Fitting TF-IDF on evidence\"))\n",
        "train_p1_tfidf = tfidf_vectorizer.transform(train_p1_texts)\n",
        "\n",
        "# Save TF-IDF Results\n",
        "scipy.sparse.save_npz(os.path.join(data_dir, \"evidence_p1_tfidf.npz\"), evidence_p1_tfidf)\n",
        "scipy.sparse.save_npz(os.path.join(data_dir, \"train_p1_tfidf.npz\"), train_p1_tfidf)\n",
        "joblib.dump(tfidf_vectorizer, os.path.join(data_dir, \"tfidf_vectorizer.pkl\"))\n",
        "print(\" TF-IDF vectors and model saved.\")\n",
        "\n",
        "# BoW Vectorization\n",
        "print(\"\\n BoW Vectorizing...\")\n",
        "\n",
        "bow_vectorizer = CountVectorizer(max_features=5000, tokenizer=whitespace_tokenizer)\n",
        "evidence_p1_bow = bow_vectorizer.fit_transform(tqdm(evidence_p1_texts, desc=\"Fitting BoW on evidence\"))\n",
        "train_p1_bow = bow_vectorizer.transform(train_p1_texts)\n",
        "\n",
        "# Save BoW Results\n",
        "scipy.sparse.save_npz(os.path.join(data_dir, \"evidence_p1_bow.npz\"), evidence_p1_bow)\n",
        "scipy.sparse.save_npz(os.path.join(data_dir, \"train_p1_bow.npz\"), train_p1_bow)\n",
        "joblib.dump(bow_vectorizer, os.path.join(data_dir, \"bow_vectorizer.pkl\"))\n",
        "print(\" BoW vectors and model saved.\")\n",
        "\n",
        "# Vector shapes\n",
        "print(\"\\nVector Shapes:\")\n",
        "print(f\"TF-IDF (train):    {train_p1_tfidf.shape}\")\n",
        "print(f\"TF-IDF (evidence): {evidence_p1_tfidf.shape}\")\n",
        "print(f\"BoW (train):       {train_p1_bow.shape}\")\n",
        "print(f\"BoW (evidence):    {evidence_p1_bow.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlJf5jn1P6Dz",
        "outputId": "5135aee5-43e0-4dde-8bfc-8f731c97a734"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building vocabulary...\n",
            "Vocabulary size: 111585\n",
            "Processing texts to index sequences...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1228/1228 [00:00<00:00, 8643.94it/s]\n",
            "Dev: 100%|██████████| 154/154 [00:00<00:00, 11119.15it/s]\n",
            "Test: 100%|██████████| 153/153 [00:00<00:00, 11839.35it/s]\n",
            "Evidence: 100%|██████████| 1208827/1208827 [01:33<00:00, 12959.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All sequences processed and vocabulary saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import nltk\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "#Building Vocalbulary for sequential models\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "# Config\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "min_freq = 5\n",
        "special_tokens = (\"<pad>\", \"<unk>\", \"<cls>\")\n",
        "\n",
        "# Load data\n",
        "def load_json_file(filename):\n",
        "    with open(os.path.join(data_dir, filename)) as f:\n",
        "        return json.load(f)\n",
        "\n",
        "train_data = load_json_file(\"train-claims-preprocessed2.json\")\n",
        "dev_data = load_json_file(\"dev-claims-preprocessed2.json\")\n",
        "test_data = load_json_file(\"test-claims-unlabelled-preprocessed2.json\")\n",
        "evidence_data = load_json_file(\"evidence-preprocessed2.json\")\n",
        "\n",
        "train_texts = [v[\"claim_text\"] for v in train_data.values()]\n",
        "dev_texts = [v[\"claim_text\"] for v in dev_data.values()]\n",
        "test_texts = [v[\"claim_text\"] for v in test_data.values()]\n",
        "evidence_texts = [v for v in evidence_data.values()]\n",
        "\n",
        "# oken Iterator\n",
        "def yield_tokens(data):\n",
        "    for item in data:\n",
        "        yield word_tokenize(item.lower())\n",
        "\n",
        "# Build Vocabulary\n",
        "def build_vocab_from_iterator(iterator, min_freq=5, special_tokens=(\"<pad>\", \"<unk>\", \"<cls>\")):\n",
        "    counter = Counter()\n",
        "    for tokens in iterator:\n",
        "        counter.update(tokens)\n",
        "\n",
        "    vocab = {tok: idx for idx, tok in enumerate(special_tokens)}\n",
        "    cur_idx = len(special_tokens)\n",
        "\n",
        "    for token, freq in counter.items():\n",
        "        if freq >= min_freq and token not in vocab:\n",
        "            vocab[token] = cur_idx\n",
        "            cur_idx += 1\n",
        "\n",
        "    idx_to_token = {idx: tok for tok, idx in vocab.items()}\n",
        "    return vocab, idx_to_token\n",
        "\n",
        "print(\"Building vocabulary...\")\n",
        "vocab, idx_to_token = build_vocab_from_iterator(\n",
        "    yield_tokens(train_texts + evidence_texts),\n",
        "    min_freq=min_freq,\n",
        "    special_tokens=special_tokens\n",
        ")\n",
        "\n",
        "print(f\"Vocabulary size: {len(vocab)}\")\n",
        "\n",
        "def process_text(text, vocab):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    return [vocab[\"<cls>\"]] + [vocab.get(tok, vocab[\"<unk>\"]) for tok in tokens]\n",
        "\n",
        "# Convert All to Indices\n",
        "print(\"Processing texts to index sequences...\")\n",
        "train_texts_indices = [process_text(text, vocab) for text in tqdm(train_texts, desc=\"Train\")]\n",
        "dev_texts_indices = [process_text(text, vocab) for text in tqdm(dev_texts, desc=\"Dev\")]\n",
        "test_texts_indices = [process_text(text, vocab) for text in tqdm(test_texts, desc=\"Test\")]\n",
        "evidence_texts_indices = [process_text(text, vocab) for text in tqdm(evidence_texts, desc=\"Evidence\")]\n",
        "\n",
        "# Save indexed versions\n",
        "np.save(os.path.join(data_dir, \"train_claim_indices.npy\"), np.array(train_texts_indices, dtype=object))\n",
        "np.save(os.path.join(data_dir, \"dev_claim_indices.npy\"), np.array(dev_texts_indices, dtype=object))\n",
        "np.save(os.path.join(data_dir, \"test_claim_indices.npy\"), np.array(test_texts_indices, dtype=object))\n",
        "np.save(os.path.join(data_dir, \"evidence_indices.npy\"), np.array(evidence_texts_indices, dtype=object))\n",
        "\n",
        "# Save vocabulary\n",
        "with open(os.path.join(data_dir, \"seq_models_vocab.json\"), \"w\") as f:\n",
        "    json.dump(vocab, f, indent=2)\n",
        "\n",
        "print(\"All sequences processed and vocabulary saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB_8YXejR-dq"
      },
      "outputs": [],
      "source": [
        "# Extra Preprocessing\n",
        "import json\n",
        "import os\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "\n",
        "with open(os.path.join(data_dir, \"evidence-preprocessed2.json\")) as f:\n",
        "    evidence = json.load(f)\n",
        "\n",
        "indexed_evidence = {\n",
        "    i: {\n",
        "        \"evidence_id\": eid,\n",
        "        \"text\": evidence[eid]\n",
        "    }\n",
        "    for i, eid in enumerate(evidence)\n",
        "}\n",
        "\n",
        "output_path = os.path.join(data_dir, \"evidence-preprocessed2-indexed.json\")\n",
        "with open(output_path, \"w\") as f:\n",
        "    json.dump(indexed_evidence, f, indent=2)\n",
        "\n",
        "print(f\"Saved indexed evidence to: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne6_9y-0VliA"
      },
      "source": [
        "## 1.2 Exmain the Dev Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpD53DgvVgVn",
        "outputId": "40705294-51c5-46b3-91b5-9e5a6b65ae53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max evidence count for one training data: 5\n",
            "min evidence count for one training data: 1\n",
            "mean evidence count for one training data: 3.188311688311688\n"
          ]
        }
      ],
      "source": [
        "evi_counts = [len(item[\"evidences\"]) for item in dev_data.values()]\n",
        "print(\"max evidence count for one dev data:\", max(evi_counts))\n",
        "print(\"min evidence count for one dev data:\", min(evi_counts))\n",
        "print(\"mean evidence count for one dev data:\", sum(evi_counts) / len(evi_counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep3ZWwdIYUja",
        "outputId": "3be460f6-bbe7-40c2-9ce4-2dc0012af2e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({'SUPPORTS': 68, 'NOT_ENOUGH_INFO': 41, 'REFUTES': 27, 'DISPUTED': 18})\n"
          ]
        }
      ],
      "source": [
        "labels = [item[\"claim_label\"] for item in dev_data.values()]\n",
        "print(Counter(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mWqbWTJZQAg"
      },
      "source": [
        "## 1.3 Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBHGoanyZSOb",
        "outputId": "ee92aac8-92aa-4e92-d080-2775c1340282"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import unicodedata\n",
        "\n",
        "\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess(text, remove_stopwords=True):\n",
        "    # Normalize unicode\n",
        "    text = unicodedata.normalize(\"NFKD\", text)\n",
        "\n",
        "    # Remove non-ASCII characters\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
        "\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove speaker patterns like \"Mark Latham said\", \"Chris Bowen claimed\"\n",
        "    text = re.sub(\n",
        "        r'^[A-Z][a-z]+(?:\\s[A-Z][a-z]+)*\\s'\n",
        "        r'(?:said|says|claimed|claims|stated|states|argued|argues|asserts|asserted):?\\s*',\n",
        "        '',\n",
        "        text\n",
        "    )\n",
        "\n",
        "    # Remove bracketed noise like [ ... ]\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "\n",
        "    # Remove repeated dots and normalize whitespace\n",
        "    text = re.sub(r'\\.{2,}', '.', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    text = re.sub(r'[\\'\"`“”‘’]', '', text)  # removes any form of stray quotes from both ends\n",
        "\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # Lemmatize\n",
        "    tokens = [lemmatizer.lemmatize(tok) for tok in tokens]\n",
        "    # Optional: remove stopwords\n",
        "    if remove_stopwords:\n",
        "        tokens = [tok for tok in tokens if tok not in stop_words]\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x1VUWs7aBs8"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing\n",
        "for cid in train_data:\n",
        "    text = train_data[cid][\"claim_text\"]\n",
        "    train_data[cid][\"claim_text\"] = preprocess(text, remove_stopwords=False)\n",
        "\n",
        "with open(\"train-claims-cleaned.json\", \"w\") as f:\n",
        "    json.dump(train_data, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmyaP68Vi6Ea",
        "outputId": "3c26e7ef-14e6-4b72-9e36-de2605119761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max cleaned training claim length: 329\n",
            "min cleaned training claim length: 26\n",
            "mean cleaned training claim length: 121.52524429967427\n"
          ]
        }
      ],
      "source": [
        "with open(\"train-claims-cleaned.json\", \"r\") as f:\n",
        "    train_data_cleaned = json.load(f)\n",
        "\n",
        "claim_lengths = [len(item[\"claim_text\"]) for item in train_data_cleaned.values()]\n",
        "print(\"max cleaned training claim length:\", max(claim_lengths))\n",
        "print(\"min cleaned training claim length:\", min(claim_lengths))\n",
        "print(\"mean cleaned training claim length:\", sum(claim_lengths) / len(claim_lengths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiEFXL4sigev"
      },
      "outputs": [],
      "source": [
        "cleaned_evidence = {\n",
        "    evid_id: preprocess(text) for evid_id, text in evidence_data.items()\n",
        "}\n",
        "\n",
        "with open(\"evidence-cleaned.json\", \"w\") as f:\n",
        "    json.dump(cleaned_evidence, f, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr8ir9vGy1QD"
      },
      "source": [
        "# Task 1: Evidence Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IODfyiJLy5Ma"
      },
      "source": [
        "## Model 1: BERTTopic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Clustering the training claims using BERTopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install bertopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load training claims\n",
        "with open(\"train-claims.json\", \"r\") as f:\n",
        "    train_claims = json.load(f)\n",
        "\n",
        "# Extract claim texts and IDs\n",
        "claim_ids = list(train_claims.keys())\n",
        "claim_texts = [train_claims[cid][\"claim_text\"] for cid in claim_ids]\n",
        "\n",
        "# Create and fit BERTopic model\n",
        "topic_model = BERTopic(embedding_model=\"all-MiniLM-L6-v2\")  # Small and Colab-friendly\n",
        "topics, probs = topic_model.fit_transform(claim_texts)\n",
        "\n",
        "# Save topic model for reuse\n",
        "topic_model.save(\"bertopic_claims_model\")\n",
        "\n",
        "# Save clustering results\n",
        "claim_cluster_df = pd.DataFrame({\n",
        "    \"claim_id\": claim_ids,\n",
        "    \"claim_text\": claim_texts,\n",
        "    \"topic\": topics,\n",
        "    \"probability\": probs\n",
        "})\n",
        "claim_cluster_df.to_csv(\"claim_clusters.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topic_model = BERTopic.load(\"bertopic_claims_model\")\n",
        "\n",
        "topic_model.visualize_topics()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topic_model.visualize_heatmap()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of clusters (excluding outliers): 22\n"
          ]
        }
      ],
      "source": [
        "n_clusters = len(set(claim_cluster_df[\"topic\"])) - (\"-1\" in set(claim_cluster_df[\"topic\"]))\n",
        "print(f\"Number of clusters (excluding outliers): {n_clusters}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Extract Evidence Text per Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "# === LOAD DATA ===\n",
        "with open(\"train-claims.json\", \"r\") as f:\n",
        "    train_claims = json.load(f)\n",
        "\n",
        "with open(\"evidence.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    evidence_data = json.load(f)\n",
        "\n",
        "# Load claim cluster assignments\n",
        "claim_cluster_df = pd.read_csv(\"claim_clusters.csv\")  # must contain: claim_id, topic\n",
        "\n",
        "# === MAP EACH TOPIC TO ITS EVIDENCE PASSAGES ===\n",
        "cluster_evidence_map = defaultdict(list)\n",
        "\n",
        "for _, row in claim_cluster_df.iterrows():\n",
        "    claim_id = row[\"claim_id\"]\n",
        "    topic = row[\"topic\"]\n",
        "\n",
        "    if claim_id in train_claims:\n",
        "        evidence_ids = train_claims[claim_id].get(\"evidences\", [])\n",
        "        for eid in evidence_ids:\n",
        "            passage = evidence_data.get(eid)\n",
        "            if passage:\n",
        "                cluster_evidence_map[topic].append(passage)\n",
        "\n",
        "# === OPTIONAL: Convert to a DataFrame for downstream use ===\n",
        "clustered_evidence_df = pd.DataFrame([\n",
        "    {\"topic\": topic, \"evidence_text\": evidence}\n",
        "    for topic, evidences in cluster_evidence_map.items()\n",
        "    for evidence in evidences\n",
        "])\n",
        "\n",
        "# === SAVE IF NEEDED ===\n",
        "clustered_evidence_df.to_csv(\"clustered_evidence.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Extract Evidence Keywords by Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"keywords_df\",\n  \"rows\": 23,\n  \"fields\": [\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": -1,\n        \"max\": 21,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          8,\n          11,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"change, climate, data, emissions, feedback, future, global, greenhouse, increase, measurements, model, models, predict, rate, report, rise, surface, temperature, temperatures, warming\",\n          \"atmosphere, change, climate, clouds, earth, effect, feedback, global, greenhouse, heating, increase, negative, planet, positive, radiation, surface, temperature, vapor, warming, water\",\n          \"atmosphere, atmospheric, carbon, climate, co2, concentrations, dioxide, earth, emissions, gas, gases, global, greenhouse, human, increased, levels, methane, temperature, warming, years\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "keywords_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-897af475-365e-4019-a50f-abf2c2aec842\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>atmosphere, atmospheric, carbon, climate, co2,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>carbon, change, changes, climate, earth, emiss...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>assessment, caused, change, climate, consensus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>average, celsius, century, climate, data, deca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>antarctic, arctic, climate, glaciers, global, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-897af475-365e-4019-a50f-abf2c2aec842')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-897af475-365e-4019-a50f-abf2c2aec842 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-897af475-365e-4019-a50f-abf2c2aec842');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-20b641d3-9e61-4c78-b148-6d9b4a12df8c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20b641d3-9e61-4c78-b148-6d9b4a12df8c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-20b641d3-9e61-4c78-b148-6d9b4a12df8c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   topic                                           keywords\n",
              "0      0  atmosphere, atmospheric, carbon, climate, co2,...\n",
              "1     -1  carbon, change, changes, climate, earth, emiss...\n",
              "2      2  assessment, caused, change, climate, consensus...\n",
              "3      3  average, celsius, century, climate, data, deca...\n",
              "4      1  antarctic, arctic, climate, glaciers, global, ..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load the evidence dataframe (sample already saved)\n",
        "clustered_evidence_df = pd.read_csv(\"clustered_evidence.csv\")\n",
        "\n",
        "##################### Limit to first 2000 rows for sampling (per topic if needed)\n",
        "#sampled_df = clustered_evidence_df.groupby(\"topic\").head(2000)\n",
        "\n",
        "# Build a mapping: topic -> list of evidence texts\n",
        "topic_to_texts = defaultdict(list)\n",
        "for _, row in clustered_evidence_df.iterrows():\n",
        "    topic_to_texts[row[\"topic\"]].append(row[\"evidence_text\"])\n",
        "\n",
        "# === Extract keywords using TF-IDF per topic ===\n",
        "topic_keywords = {}\n",
        "\n",
        "for topic, texts in topic_to_texts.items():\n",
        "    # Combine all evidence into a single \"document\" per topic\n",
        "    corpus = [\" \".join(texts)]\n",
        "\n",
        "    # Use TF-IDF to get important terms\n",
        "    vectorizer = TfidfVectorizer(max_features=20, stop_words='english')\n",
        "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "    keywords = vectorizer.get_feature_names_out()\n",
        "\n",
        "    topic_keywords[topic] = keywords.tolist()\n",
        "\n",
        "# Convert to DataFrame for inspection\n",
        "keywords_df = pd.DataFrame([\n",
        "    {\"topic\": topic, \"keywords\": \", \".join(words)}\n",
        "    for topic, words in topic_keywords.items()\n",
        "])\n",
        "\n",
        "# Save if needed\n",
        "keywords_df.to_csv(\"topic_keywords_by_cluster.csv\", index=False)\n",
        "\n",
        "# Preview output\n",
        "keywords_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Extract Keywords from ALL Evidence Passages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "evidence_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e5b666a9-2eb4-42fd-b88e-e27436bd6fa8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>evidence_id</th>\n",
              "      <th>text</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>evidence-0</td>\n",
              "      <td>John Bennet Lawes, English entrepreneur and ag...</td>\n",
              "      <td>[john, english]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>evidence-1</td>\n",
              "      <td>Lindberg began his professional career at the ...</td>\n",
              "      <td>[eventually, 1977, age, began, 16, career, pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>evidence-2</td>\n",
              "      <td>``Boston (Ladies of Cambridge)'' by Vampire We...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>evidence-3</td>\n",
              "      <td>Gerald Francis Goyer (born October 20, 1936) w...</td>\n",
              "      <td>[hockey, 1936, 40, ice, 20, games, professiona...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>evidence-4</td>\n",
              "      <td>He detected abnormalities of oxytocinergic fun...</td>\n",
              "      <td>[release, post]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5b666a9-2eb4-42fd-b88e-e27436bd6fa8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5b666a9-2eb4-42fd-b88e-e27436bd6fa8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5b666a9-2eb4-42fd-b88e-e27436bd6fa8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2c37f0f2-d3fe-40cb-a29d-532398fbb047\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c37f0f2-d3fe-40cb-a29d-532398fbb047')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2c37f0f2-d3fe-40cb-a29d-532398fbb047 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  evidence_id                                               text  \\\n",
              "0  evidence-0  John Bennet Lawes, English entrepreneur and ag...   \n",
              "1  evidence-1  Lindberg began his professional career at the ...   \n",
              "2  evidence-2  ``Boston (Ladies of Cambridge)'' by Vampire We...   \n",
              "3  evidence-3  Gerald Francis Goyer (born October 20, 1936) w...   \n",
              "4  evidence-4  He detected abnormalities of oxytocinergic fun...   \n",
              "\n",
              "                                            keywords  \n",
              "0                                    [john, english]  \n",
              "1  [eventually, 1977, age, began, 16, career, pro...  \n",
              "2                                                 []  \n",
              "3  [hockey, 1936, 40, ice, 20, games, professiona...  \n",
              "4                                    [release, post]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# === Load full evidence corpus ===\n",
        "with open(\"evidence.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    evidence_data = json.load(f)\n",
        "\n",
        "# Convert to DataFrame\n",
        "evidence_df = pd.DataFrame([\n",
        "    {\"evidence_id\": eid, \"text\": text}\n",
        "    for eid, text in evidence_data.items()\n",
        "])\n",
        "\n",
        "# === Apply TF-IDF per evidence passage ===\n",
        "\n",
        "# Vectorize all passages together to ensure consistent vocabulary\n",
        "vectorizer = TfidfVectorizer(max_features=1000, stop_words=\"english\")\n",
        "tfidf_matrix = vectorizer.fit_transform(evidence_df[\"text\"])\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Extract top N keywords per passage (set N = 15 here)\n",
        "top_n = 15\n",
        "evidence_keywords = []\n",
        "\n",
        "for i, row in enumerate(tfidf_matrix):\n",
        "    row_data = row.toarray().flatten()\n",
        "    top_indices = row_data.argsort()[::-1][:top_n]\n",
        "    top_words = [feature_names[idx] for idx in top_indices if row_data[idx] > 0]\n",
        "    evidence_keywords.append(top_words)\n",
        "\n",
        "evidence_df[\"keywords\"] = evidence_keywords\n",
        "\n",
        "# Save for matching later\n",
        "evidence_df.to_csv(\"evidence_keywords.csv\", index=False)\n",
        "\n",
        "# Preview\n",
        "evidence_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TFIDF perform terribly, so we alter back to the BertTopic Model (tradeoff b/w computation efficiency and prediction accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# === Load evidence data ===\n",
        "with open(\"evidence.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    evidence_data = json.load(f)\n",
        "\n",
        "evidence_ids = list(evidence_data.keys())\n",
        "evidence_texts = list(evidence_data.values())\n",
        "\n",
        "# === Train BERTopic model on all evidence ===\n",
        "topic_model = BERTopic(embedding_model=\"all-MiniLM-L6-v2\", calculate_probabilities=False, verbose=True)\n",
        "topics, _ = topic_model.fit_transform(evidence_texts)\n",
        "\n",
        "# === Extract keywords for EACH evidence ===\n",
        "evidence_keywords = []\n",
        "\n",
        "for idx, text in enumerate(evidence_texts):\n",
        "    topic = topics[idx]\n",
        "    if topic == -1:\n",
        "        # -1 is outlier topic — assign empty keywords or fallback\n",
        "        keywords = []\n",
        "    else:\n",
        "        # Extract keywords for the current topic and filter those relevant to this doc\n",
        "        topic_words = topic_model.get_topic(topic)\n",
        "        doc_keywords = []\n",
        "        for word, _ in topic_words:\n",
        "            if word.lower() in text.lower():\n",
        "                doc_keywords.append(word)\n",
        "            if len(doc_keywords) >= 10:\n",
        "                break\n",
        "        keywords = doc_keywords\n",
        "\n",
        "    evidence_keywords.append({\n",
        "        \"evidence_id\": evidence_ids[idx],\n",
        "        \"text\": text,\n",
        "        \"keywords\": keywords\n",
        "    })\n",
        "\n",
        "# === Save as DataFrame ===\n",
        "df = pd.DataFrame(evidence_keywords)\n",
        "df.to_csv(\"evidence_keywords.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Using NER-mased matching mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "get NER on claims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy<2.0 in /Users/Wen/opt/anaconda3/envs/nlp_env/lib/python3.10/site-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install \"numpy<2.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load spaCy English NER model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load evidence data\n",
        "with open(\"evidence.json\", \"r\") as f:\n",
        "    evidence_data = json.load(f)\n",
        "\n",
        "# Extract NER for each evidence entry\n",
        "evidence_ner = {}\n",
        "for eid, text in tqdm(evidence_data.items(), desc=\"Extracting NER\"):\n",
        "    doc = nlp(text)\n",
        "    ner_entities = list(set(ent.text for ent in doc.ents if ent.label_))  # deduplicated\n",
        "    evidence_ner[eid] = ner_entities\n",
        "\n",
        "# Save to JSON\n",
        "with open(\"evidence_ner.json\", \"w\") as f:\n",
        "    json.dump(evidence_ner, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 154/154 [00:00<00:00, 227.69it/s]\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load spaCy and NER JSON\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "with open(\"dev-claims.json\") as f:\n",
        "    claims = json.load(f)\n",
        "\n",
        "claim_ner = {}\n",
        "for cid, entry in tqdm(claims.items()):\n",
        "    doc = nlp(entry[\"claim_text\"])\n",
        "    ents = list(set(ent.text.lower() for ent in doc.ents if ent.label_))\n",
        "    claim_ner[cid] = ents\n",
        "\n",
        "with open(\"claim_ner.json\", \"w\") as f:\n",
        "    json.dump(claim_ner, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "evidence_ner.json is obtained in preprocess_evidence_for_ner.ipynb \\\n",
        "now load both of them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"claim_ner.json\", \"r\") as f:\n",
        "    claim_ner = json.load(f)\n",
        "\n",
        "with open(\"evidence_ner.json\", \"r\") as f:\n",
        "    evidence_ner = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute NER Overlap Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_ner_overlap(claim_entities, evidence_entities):\n",
        "    claim_set = set(e.lower() for e in claim_entities)\n",
        "    evidence_set = set(e.lower() for e in evidence_entities)\n",
        "    overlap = claim_set & evidence_set\n",
        "    return len(overlap) / (len(claim_set) + 1e-6)  # +1e-6 to avoid div-by-zero\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the NER similarity scoring function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ner_overlap_score(claim_ents, evidence_ents):\n",
        "    if not claim_ents or not evidence_ents:\n",
        "        return 0.0\n",
        "\n",
        "    # Partial match allowed — token overlap\n",
        "    count = 0\n",
        "    for ce in claim_ents:\n",
        "        for ee in evidence_ents:\n",
        "            if ce in ee or ee in ce:\n",
        "                count += 1\n",
        "                break  # avoid multiple matches for same ce\n",
        "\n",
        "    return count / len(claim_ents)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: FineTune SentenceTransformer for Next Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from sentence_transformers import SentenceTransformer, SentenceTransformerTrainer, SentenceTransformerTrainingArguments\n",
        "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
        "import json\n",
        "\n",
        "# === Step 1: Load and prepare data ===\n",
        "with open(\"train-claims.json\", \"r\") as f:\n",
        "    train_claims = json.load(f)\n",
        "with open(\"evidence.json\", \"r\") as f:\n",
        "    evidence_data = json.load(f)\n",
        "\n",
        "anchor_texts = []\n",
        "positive_texts = []\n",
        "\n",
        "for claim in train_claims.values():\n",
        "    claim_text = claim[\"claim_text\"]\n",
        "    for eid in claim.get(\"evidences\", []):\n",
        "        if eid in evidence_data:\n",
        "            anchor_texts.append(claim_text)\n",
        "            positive_texts.append(evidence_data[eid])\n",
        "\n",
        "dataset = Dataset.from_dict({\n",
        "    \"anchor\": anchor_texts,\n",
        "    \"positive\": positive_texts,\n",
        "})\n",
        "\n",
        "# === Step 2: Initialize model and loss ===\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "loss = MultipleNegativesRankingLoss(model)\n",
        "\n",
        "# === Step 3: Training arguments ===\n",
        "args = SentenceTransformerTrainingArguments(\n",
        "    output_dir=\"fine-tuned-sentence-transformer\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=16,\n",
        "    learning_rate=2e-5,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"no\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "# === Step 4: Trainer and Training ===\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=dataset,\n",
        "    loss=loss,\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "# Save model\n",
        "model.save(\"fine-tuned-sentence-transformer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 7: Evidence Retrieval via Weighted Keyword Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each test claim, match it to the most relevant evidence passages, using both:\n",
        "- Keywords from the claim itself, and\n",
        "- Keywords from the nearest cluster (with inverse distance weighting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "186f0800d37d45b8b69f7de9fe0d58e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4722 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[1/5] Claim ID: claim-752\n",
            "  → Claim text: [South Australia] has the most expensive electricity in the world.\n",
            "    Rank 1: evidence-67732 (score: 0.8175)\n",
            "    Rank 2: evidence-572512 (score: 0.7730)\n",
            "    Rank 3: evidence-780332 (score: 0.6659)\n",
            "    Rank 4: evidence-1061888 (score: 0.6277)\n",
            "    Rank 5: evidence-452156 (score: 0.6275)\n",
            "\n",
            "[2/5] Claim ID: claim-375\n",
            "  → Claim text: when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod­uces 1.3 per cent of this 3 per cent, then no amount of emissions reductio­n here will have any effect on global climate.\n",
            "    Rank 1: evidence-647121 (score: 0.7270)\n",
            "    Rank 2: evidence-559290 (score: 0.6956)\n",
            "    Rank 3: evidence-415619 (score: 0.6742)\n",
            "    Rank 4: evidence-361694 (score: 0.6684)\n",
            "    Rank 5: evidence-949910 (score: 0.6644)\n",
            "\n",
            "[3/5] Claim ID: claim-1266\n",
            "  → Claim text: This means that the world is now 1C warmer than it was in pre-industrial times\n",
            "    Rank 1: evidence-694262 (score: 0.6901)\n",
            "    Rank 2: evidence-403673 (score: 0.6211)\n",
            "    Rank 3: evidence-332770 (score: 0.6176)\n",
            "    Rank 4: evidence-527805 (score: 0.6141)\n",
            "    Rank 5: evidence-1084381 (score: 0.6090)\n",
            "\n",
            "[4/5] Claim ID: claim-871\n",
            "  → Claim text: “As it happens, Zika may also be a good model of the second worrying effect — disease mutation.\n",
            "    Rank 1: evidence-472751 (score: 0.6776)\n",
            "    Rank 2: evidence-745642 (score: 0.6643)\n",
            "    Rank 3: evidence-856375 (score: 0.6398)\n",
            "    Rank 4: evidence-641043 (score: 0.6242)\n",
            "    Rank 5: evidence-101223 (score: 0.5757)\n",
            "\n",
            "[5/5] Claim ID: claim-2164\n",
            "  → Claim text: Greenland has only lost a tiny fraction of its ice mass\n",
            "    Rank 1: evidence-264761 (score: 0.7819)\n",
            "    Rank 2: evidence-52981 (score: 0.7795)\n",
            "    Rank 3: evidence-44751 (score: 0.7422)\n",
            "    Rank 4: evidence-640229 (score: 0.7197)\n",
            "    Rank 5: evidence-691825 (score: 0.7180)\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import ast\n",
        "\n",
        "# === Load Data ===\n",
        "with open(\"dev-claims.json\", \"r\") as f:\n",
        "    test_claims = json.load(f)\n",
        "\n",
        "evidence_df = pd.read_csv(\"evidence_keywords.csv\")\n",
        "evidence_df[\"keywords\"] = evidence_df[\"keywords\"].apply(ast.literal_eval)\n",
        "\n",
        "# === Embed Evidence Passages ===\n",
        "embedder = SentenceTransformer(\"fine-tuned-sentence-transformer\")\n",
        "evidence_texts = evidence_df[\"text\"].tolist()\n",
        "evidence_embeddings = embedder.encode(evidence_texts, batch_size=256, show_progress_bar=True)\n",
        "\n",
        "# === Process All Claims ===\n",
        "retrieval_results = {}\n",
        "top_k = 5\n",
        "\n",
        "for idx, (cid, cinfo) in enumerate(test_claims.items()):\n",
        "    claim_text = cinfo[\"claim_text\"]\n",
        "    print(f\"\\n[{idx+1}/{len(test_claims)}] Claim ID: {cid}\")\n",
        "    print(f\"  → Claim text: {claim_text}\")\n",
        "\n",
        "    # Embed claim\n",
        "    claim_embedding = embedder.encode([claim_text])[0]\n",
        "\n",
        "    # Compute cosine similarity to all evidence passages\n",
        "    similarities = cosine_similarity([claim_embedding], evidence_embeddings)[0]\n",
        "\n",
        "    # Get top-k evidence\n",
        "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "    top_evidence_ids = evidence_df.iloc[top_indices][\"evidence_id\"].tolist()\n",
        "    top_scores = similarities[top_indices]\n",
        "\n",
        "    for i, eid in enumerate(top_evidence_ids):\n",
        "        print(f\"    Rank {i+1}: {eid} (score: {top_scores[i]:.4f})\")\n",
        "\n",
        "    retrieval_results[cid] = top_evidence_ids\n",
        "\n",
        "# === Save Output in Required Format ===\n",
        "formatted_predictions = {\n",
        "    cid: {\n",
        "        \"claim_label\": \"NOT_ENOUGH_INFO\",\n",
        "        \"evidences\": evids\n",
        "    }\n",
        "    for cid, evids in retrieval_results.items()\n",
        "}\n",
        "\n",
        "with open(\"dev-claims-predictions.json\", \"w\") as f:\n",
        "    json.dump(formatted_predictions, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternative: combine with NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import ast\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Load Data ===\n",
        "with open(\"dev-claims.json\", \"r\") as f:\n",
        "    test_claims = json.load(f)\n",
        "\n",
        "evidence_df = pd.read_csv(\"evidence_keywords.csv\")\n",
        "evidence_df[\"keywords\"] = evidence_df[\"keywords\"].apply(ast.literal_eval)\n",
        "\n",
        "with open(\"claim_ner.json\", \"r\") as f:\n",
        "    claim_ner = json.load(f)\n",
        "\n",
        "with open(\"evidence_ner.json\", \"r\") as f:\n",
        "    evidence_ner = json.load(f)\n",
        "\n",
        "# === Load fine-tuned SentenceTransformer ===\n",
        "embedder = SentenceTransformer(\"fine-tuned-sentence-transformer\")\n",
        "evidence_texts = evidence_df[\"text\"].tolist()\n",
        "evidence_ids = evidence_df[\"evidence_id\"].tolist()\n",
        "evidence_embeddings = embedder.encode(evidence_texts, batch_size=256, show_progress_bar=True)\n",
        "\n",
        "# === Define NER overlap scoring ===\n",
        "def ner_overlap_score(claim_ents, evidence_ents):\n",
        "    if not claim_ents or not evidence_ents:\n",
        "        return 0.0\n",
        "    count = 0\n",
        "    for ce in claim_ents:\n",
        "        for ee in evidence_ents:\n",
        "            if ce in ee or ee in ce:\n",
        "                count += 1\n",
        "                break\n",
        "    return count / len(claim_ents)\n",
        "\n",
        "# === Perform Retrieval with Combined Score ===\n",
        "top_k = 5\n",
        "alpha = 0.8  # adjust this weight between [0, 1] — more toward semantic\n",
        "\n",
        "retrieval_results = {}\n",
        "\n",
        "for idx, (cid, cinfo) in enumerate(tqdm(test_claims.items(), desc=\"Retrieving evidences\")):\n",
        "    claim_text = cinfo[\"claim_text\"]\n",
        "    claim_embedding = embedder.encode([claim_text])[0]\n",
        "    claim_entities = claim_ner.get(cid, [])\n",
        "\n",
        "    similarities = cosine_similarity([claim_embedding], evidence_embeddings)[0]\n",
        "\n",
        "    combined_scores = []\n",
        "    for i, eid in enumerate(evidence_ids):\n",
        "        ner_entities = evidence_ner.get(eid, [])\n",
        "        ner_score = ner_overlap_score(claim_entities, ner_entities)\n",
        "        combined = alpha * similarities[i] + (1 - alpha) * ner_score\n",
        "        combined_scores.append((eid, combined))\n",
        "\n",
        "    # Rank by combined score\n",
        "    top_evidences = sorted(combined_scores, key=lambda x: x[1], reverse=True)[:top_k]\n",
        "    retrieval_results[cid] = [eid for eid, _ in top_evidences]\n",
        "\n",
        "# === Format and Save Output ===\n",
        "formatted_predictions = {\n",
        "    cid: {\n",
        "        \"claim_label\": \"NOT_ENOUGH_INFO\",\n",
        "        \"evidences\": evids\n",
        "    }\n",
        "    for cid, evids in retrieval_results.items()\n",
        "}\n",
        "\n",
        "with open(\"dev-claims-predictions_fine_tuned_with_ner.json\", \"w\") as f:\n",
        "    json.dump(formatted_predictions, f, indent=2)\n",
        "\n",
        "print(\"✅ Retrieval complete. Output saved to dev-claims-predictions_fine_tuned.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import ast\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Load Data ===\n",
        "with open(\"dev-claims.json\", \"r\") as f:\n",
        "    test_claims = json.load(f)\n",
        "\n",
        "evidence_df = pd.read_csv(\"evidence_keywords.csv\")\n",
        "evidence_df[\"keywords\"] = evidence_df[\"keywords\"].apply(ast.literal_eval)\n",
        "\n",
        "with open(\"claim_ner.json\", \"r\") as f:\n",
        "    claim_ner = json.load(f)\n",
        "\n",
        "with open(\"evidence_ner.json\", \"r\") as f:\n",
        "    evidence_ner = json.load(f)\n",
        "\n",
        "# === Load fine-tuned SentenceTransformer ===\n",
        "embedder = SentenceTransformer(\"fine-tuned-sentence-transformer\")\n",
        "evidence_texts = evidence_df[\"text\"].tolist()\n",
        "evidence_ids = evidence_df[\"evidence_id\"].tolist()\n",
        "evidence_embeddings = embedder.encode(evidence_texts, batch_size=256, show_progress_bar=True)\n",
        "\n",
        "# === Define NER overlap scoring ===\n",
        "def ner_overlap_score(claim_ents, evidence_ents):\n",
        "    if not claim_ents or not evidence_ents:\n",
        "        return 0.0\n",
        "    count = 0\n",
        "    for ce in claim_ents:\n",
        "        for ee in evidence_ents:\n",
        "            if ce in ee or ee in ce:\n",
        "                count += 1\n",
        "                break\n",
        "    return count / len(claim_ents)\n",
        "\n",
        "# === Perform Retrieval with Combined Score ===\n",
        "top_k = 5\n",
        "\n",
        "retrieval_results = {}\n",
        "\n",
        "for idx, (cid, cinfo) in enumerate(tqdm(test_claims.items(), desc=\"Retrieving evidences\")):\n",
        "    claim_text = cinfo[\"claim_text\"]\n",
        "    claim_embedding = embedder.encode([claim_text])[0]\n",
        "    claim_entities = claim_ner.get(cid, [])\n",
        "\n",
        "    similarities = cosine_similarity([claim_embedding], evidence_embeddings)[0]\n",
        "\n",
        "    combined_scores = []\n",
        "    for i, eid in enumerate(evidence_ids):\n",
        "        ner_entities = evidence_ner.get(eid, [])\n",
        "        ner_score = ner_overlap_score(claim_entities, ner_entities)\n",
        "        ner_boosted = 0.6 + 0.5 * ner_score  # map [0,1] → [0.6,1.0]\n",
        "\n",
        "        combined = max(similarities[i], ner_boosted)\n",
        "        combined_scores.append((eid, combined))\n",
        "\n",
        "    # Rank by combined score\n",
        "    top_evidences = sorted(combined_scores, key=lambda x: x[1], reverse=True)[:top_k]\n",
        "    retrieval_results[cid] = [eid for eid, _ in top_evidences]\n",
        "\n",
        "# === Format and Save Output ===\n",
        "formatted_predictions = {\n",
        "    cid: {\n",
        "        \"claim_label\": \"NOT_ENOUGH_INFO\",\n",
        "        \"evidences\": evids\n",
        "    }\n",
        "    for cid, evids in retrieval_results.items()\n",
        "}\n",
        "\n",
        "with open(\"dev-claims-predictions_fine_tuned_with_ner.json\", \"w\") as f:\n",
        "    json.dump(formatted_predictions, f, indent=2)\n",
        "\n",
        "print(\"✅ Retrieval complete. Output saved to dev-claims-predictions_fine_tuned.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 8: BERTTopic Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load predictions and ground truth\n",
        "with open(\"dev-claims-predictions_fine_tuned_with_ner.json\", \"r\") as f:\n",
        "    predictions = json.load(f)\n",
        "\n",
        "with open(\"dev-claims.json\", \"r\") as f:\n",
        "    ground_truth = json.load(f)\n",
        "\n",
        "# Evaluate prediction recall\n",
        "total_gold = 0\n",
        "total_matched = 0\n",
        "\n",
        "print(\"Match count per claim:\")\n",
        "\n",
        "for cid, info in ground_truth.items():\n",
        "    gold_evidence = set(info.get(\"evidences\", []))\n",
        "    pred_evidence = set(predictions.get(cid, {}).get(\"evidences\", []))\n",
        "\n",
        "    matched = len(gold_evidence & pred_evidence)\n",
        "    total = len(gold_evidence)\n",
        "\n",
        "    print(f\"  {cid}: {matched}/{total}\")\n",
        "    total_matched += matched\n",
        "    total_gold += total\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "print(f\"  Total gold evidences: {total_gold}\")\n",
        "print(f\"  Total matched evidences: {total_matched}\")\n",
        "print(f\"  Recall: {total_matched / total_gold:.2%}\" if total_gold > 0 else \"  No gold evidences found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "## Model 2: Pre-ranking + Re-ranking\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS4uHgU5EyzU"
      },
      "source": [
        "### 2.1 Evidence Retrieval - Pre-ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB5WNbEotNYh"
      },
      "outputs": [],
      "source": [
        "def whitespace_tokenizer(text):\n",
        "    return text.split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSCmLLqchahh"
      },
      "source": [
        "#### 2.1.1 Experiments - TIDF/BoW Similarity Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIEqDDT78q39",
        "outputId": "f92b7896-b502-4699-cb4d-0c775419de64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📥 Loading saved TF-IDF vectors and model...\n",
            "🔄 Vectorizing claims...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transforming claims: 100%|██████████| 1228/1228 [00:00<00:00, 2167763.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔧 Applying Truncated SVD: reducing to 200 dimensions\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ SVD model saved to: /content/drive/MyDrive/NLP_content/tfidf_svd_model.pkl\n",
            "\n",
            "🔍 Calculating cosine similarity (SVD-reduced TF-IDF)...\n",
            "📈 Scanning to find maximum k needed to include all gold evidences...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scanning max k: 100%|██████████| 1228/1228 [09:11<00:00,  2.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Global max_k needed to include all gold evidence: 2001\n",
            "\n",
            "📌 Retrieving top-2001 evidence for each claim...\n",
            "\n",
            "✅ Saved SVD-based TF-IDF retrieval results to /content/drive/MyDrive/NLP_content/train_claims_retrieved_tfidf_svd.json\n",
            "📊 Saved final max_k to: /content/drive/MyDrive/NLP_content/train_claims_final_k_svd.json\n",
            "\n",
            "📊 Analyzing cosine similarity thresholds at max_k cutoff...\n",
            "📐 Final max_k = 2001\n",
            "📊 Average similarity threshold at position 2001: 0.6389\n",
            "📉 Min similarity at cutoff: 0.3706\n",
            "📈 Max similarity at cutoff: 0.9595\n",
            "\n",
            "⚠️ 1158 claims failed to retrieve all gold evidence within k_cap = 2000.\n",
            "📊 This is 94.30% of all training claims.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import joblib\n",
        "import scipy.sparse\n",
        "from tqdm import tqdm\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# --- Config ---\n",
        "top_k = 4\n",
        "k_cap = 5000\n",
        "force_include_gold = True\n",
        "n_components = 200\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "\n",
        "print(\"Loading saved TF-IDF vectors and model...\")\n",
        "evidence_p1_tfidf = scipy.sparse.load_npz(os.path.join(data_dir, \"evidence_p1_tfidf.npz\"))\n",
        "tfidf_vectorizer = joblib.load(os.path.join(data_dir, \"tfidf_vectorizer.pkl\"))\n",
        "\n",
        "# Reload if interrupt\n",
        "train_p1 = json.load(open(os.path.join(data_dir, \"train-claims-preprocessed1.json\")))\n",
        "evidence_p1 = json.load(open(os.path.join(data_dir, \"evidence-preprocessed1.json\")))\n",
        "train_data = json.load(open(os.path.join(data_dir, \"train-claims.json\")))\n",
        "\n",
        "\n",
        "train_claims_ids = list(train_p1.keys())\n",
        "evidence_ids = list(evidence_p1.keys())\n",
        "\n",
        "print(\"Vectorizing claims...\")\n",
        "train_claim_vectors = tfidf_vectorizer.transform(\n",
        "    [train_p1[cid][\"claim_text\"] for cid in tqdm(train_claims_ids, desc=\"Transforming claims\")]\n",
        ")\n",
        "\n",
        "# Apply SVD\n",
        "print(f\"\\n Applying Truncated SVD: reducing to {n_components} dimensions\")\n",
        "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
        "evidence_tfidf_reduced = svd.fit_transform(evidence_p1_tfidf)\n",
        "train_tfidf_reduced = svd.transform(train_claim_vectors)\n",
        "\n",
        "svd_path = os.path.join(data_dir, \"tfidf_svd_model.pkl\")\n",
        "joblib.dump(svd, svd_path)\n",
        "print(f\" SVD model saved to: {svd_path}\")\n",
        "\n",
        "# Compute cosine similarity\n",
        "print(\"\\n Calculating cosine similarity (SVD-reduced TF-IDF)...\")\n",
        "cosine_similarities = cosine_similarity(train_tfidf_reduced, evidence_tfidf_reduced)\n",
        "\n",
        "# Step 1: Find global max_k to cover all gold evidence\n",
        "print(\" Scanning to find maximum k needed to include all gold evidences...\")\n",
        "ranked_indices_all = np.argsort(-cosine_similarities, axis=1)\n",
        "max_k = top_k\n",
        "overflow_claims = []\n",
        "\n",
        "for i, claim_id in enumerate(tqdm(train_claims_ids, desc=\"Scanning max k\")):\n",
        "    gold_evids = set(train_data[claim_id].get(\"evidences\", []))\n",
        "    if not force_include_gold or not gold_evids:\n",
        "        continue\n",
        "\n",
        "    ranked_ids = [evidence_ids[j] for j in ranked_indices_all[i]]\n",
        "    dynamic_k = top_k\n",
        "    while dynamic_k <= len(ranked_ids):\n",
        "        if gold_evids.issubset(set(ranked_ids[:dynamic_k])):\n",
        "            break\n",
        "        dynamic_k += 1\n",
        "        if dynamic_k > k_cap:\n",
        "            overflow_claims.append(claim_id)\n",
        "            break\n",
        "\n",
        "    max_k = max(max_k, dynamic_k)\n",
        "\n",
        "print(f\"\\n Global max_k needed to include all gold evidence: {max_k}\")\n",
        "\n",
        "# Step 2: Retrieve top max_k for all claims\n",
        "print(f\"\\n Retrieving top-{max_k} evidence for each claim...\")\n",
        "top_k_evidence_tfidf = {\n",
        "    claim_id: ranked_indices_all[i][:max_k].tolist()\n",
        "    for i, claim_id in enumerate(train_claims_ids)\n",
        "}\n",
        "\n",
        "# Step 3: Build claim-evidence dictionary\n",
        "train_claims_retrieved_tfidf = {\n",
        "    claim_id: {\n",
        "        \"claim_text\": train_p1[claim_id][\"claim_text\"],\n",
        "        \"claim_label\": train_data[claim_id].get(\"claim_label\"),\n",
        "        \"evidences\": train_data[claim_id].get(\"evidences\", []),\n",
        "        \"pre_ranked_evidences\": [evidence_ids[i] for i in top_k_evidence_tfidf[claim_id]]\n",
        "    }\n",
        "    for claim_id in train_claims_ids\n",
        "}\n",
        "\n",
        "# Step 4: Save retrieved result\n",
        "output_path = os.path.join(data_dir, \"train_claims_retrieved_tfidf_svd.json\")\n",
        "with open(output_path, \"w\") as f:\n",
        "    json.dump(train_claims_retrieved_tfidf, f, indent=2)\n",
        "print(f\"\\n Saved SVD-based TF-IDF retrieval results to {output_path}\")\n",
        "\n",
        "k_path = os.path.join(data_dir, \"train_claims_final_k_svd.json\")\n",
        "with open(k_path, \"w\") as f:\n",
        "    json.dump({\"final_k\": max_k}, f, indent=2)\n",
        "print(f\" Saved final max_k to: {k_path}\")\n",
        "\n",
        "# Step 5: Analyze cosine threshold at cutoff\n",
        "print(\"\\n Analyzing cosine similarity thresholds at max_k cutoff...\")\n",
        "\n",
        "cutoff_similarities = []\n",
        "for i in range(len(train_claims_ids)):\n",
        "    sims = cosine_similarities[i]\n",
        "    sorted_sims = np.sort(sims)[::-1]\n",
        "    if len(sorted_sims) >= max_k:\n",
        "        cutoff_similarities.append(sorted_sims[max_k - 1])\n",
        "    else:\n",
        "        cutoff_similarities.append(sorted_sims[-1])\n",
        "\n",
        "avg_threshold = np.mean(cutoff_similarities)\n",
        "min_threshold = np.min(cutoff_similarities)\n",
        "max_threshold_sim = np.max(cutoff_similarities)\n",
        "\n",
        "print(f\" Final max_k = {max_k}\")\n",
        "print(f\" Average similarity threshold at position {max_k}: {avg_threshold:.4f}\")\n",
        "print(f\" Min similarity at cutoff: {min_threshold:.4f}\")\n",
        "print(f\" Max similarity at cutoff: {max_threshold_sim:.4f}\")\n",
        "\n",
        "# --- Step 6: Report overflow statistics ---\n",
        "num_overflows = len(overflow_claims)\n",
        "total_claims = len(train_claims_ids)\n",
        "percentage = 100 * num_overflows / total_claims\n",
        "\n",
        "print(f\"\\n {num_overflows} claims failed to retrieve all gold evidence within k_cap = {k_cap}.\")\n",
        "print(f\" This is {percentage:.2f}% of all training claims.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_UKYzxjrvU5",
        "outputId": "911e8204-8410-483f-bb64-dab421779728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📥 Loading saved BoW vectors and model...\n",
            "\n",
            "🔍 Calculating cosine similarity (BoW)...\n",
            "📈 Scanning to find maximum k needed to include all gold evidences...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scanning max k (BoW): 100%|██████████| 1228/1228 [03:28<00:00,  5.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Global max_k (BoW) needed to include all gold evidence: 2001\n",
            "\n",
            "✅ Saved BoW retrieval results to /content/drive/MyDrive/NLP_content/train_claims_retrieved_bow.json\n",
            "📊 Saved final max_k (BoW) to: /content/drive/MyDrive/NLP_content/train_claims_final_k_bow.json\n",
            "\n",
            "📊 Analyzing cosine similarity thresholds at BoW max_k cutoff...\n",
            "📐 Final max_k (BoW) = 2001\n",
            "📊 Average similarity threshold at cutoff: 0.2076\n",
            "📉 Min similarity: 0.0000\n",
            "📈 Max similarity: 0.4714\n",
            "\n",
            "⚠️ 879 claims failed to retrieve gold under k_cap=2000 using BoW.\n",
            "📊 That’s 71.58% of all claims.\n",
            "📝 Saved BoW overflow claim IDs to overflow_claims_bow.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import joblib\n",
        "import scipy.sparse\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "top_k = 4\n",
        "k_cap = 2000\n",
        "force_include_gold = True\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "\n",
        "# Load BoW vectors and vectorizer\n",
        "print(\" Loading saved BoW vectors and model...\")\n",
        "evidence_p1_bow = scipy.sparse.load_npz(os.path.join(data_dir, \"evidence_p1_bow.npz\"))\n",
        "train_p1_bow = scipy.sparse.load_npz(os.path.join(data_dir, \"train_p1_bow.npz\"))\n",
        "bow_vectorizer = joblib.load(os.path.join(data_dir, \"bow_vectorizer.pkl\"))\n",
        "\n",
        "# Reload if interrupt\n",
        "train_p1 = json.load(open(os.path.join(data_dir, \"train-claims-preprocessed1.json\")))\n",
        "evidence_p1 = json.load(open(os.path.join(data_dir, \"evidence-preprocessed1.json\")))\n",
        "train_data = json.load(open(os.path.join(data_dir, \"train-claims.json\")))\n",
        "\n",
        "train_claims_ids = list(train_p1.keys())\n",
        "evidence_ids = list(evidence_p1.keys())\n",
        "\n",
        "# Step 1: Compute cosine similarity\n",
        "print(\"\\n Calculating cosine similarity (BoW)...\")\n",
        "bow_cosine_similarities = cosine_similarity(train_p1_bow, evidence_p1_bow)\n",
        "\n",
        "# Step 2: Find global max_k to cover all gold evidence\n",
        "print(\" Scanning to find maximum k needed to include all gold evidences...\")\n",
        "ranked_indices_all_bow = np.argsort(-bow_cosine_similarities, axis=1)\n",
        "max_k_bow = top_k\n",
        "overflow_claims_bow = []\n",
        "\n",
        "for i, claim_id in enumerate(tqdm(train_claims_ids, desc=\"Scanning max k (BoW)\")):\n",
        "    gold_evids = set(train_data[claim_id].get(\"evidences\", []))\n",
        "    if not force_include_gold or not gold_evids:\n",
        "        continue\n",
        "\n",
        "    ranked_ids = [evidence_ids[j] for j in ranked_indices_all_bow[i]]\n",
        "    dynamic_k = top_k\n",
        "    while dynamic_k <= len(ranked_ids):\n",
        "        if gold_evids.issubset(set(ranked_ids[:dynamic_k])):\n",
        "            break\n",
        "        dynamic_k += 1\n",
        "        if dynamic_k > k_cap:\n",
        "            overflow_claims_bow.append(claim_id)\n",
        "            break\n",
        "\n",
        "    max_k_bow = max(max_k_bow, dynamic_k)\n",
        "\n",
        "print(f\"\\n Global max_k (BoW) needed to include all gold evidence: {max_k_bow}\")\n",
        "\n",
        "# Step 3: Retrieve top max_k for each claim\n",
        "top_k_evidence_bow = {\n",
        "    claim_id: ranked_indices_all_bow[i][:max_k_bow].tolist()\n",
        "    for i, claim_id in enumerate(train_claims_ids)\n",
        "}\n",
        "\n",
        "# Step 4: Build final claim-evidence map\n",
        "train_claims_retrieved_bow = {\n",
        "    claim_id: {\n",
        "        \"claim_text\": train_p1[claim_id][\"claim_text\"],\n",
        "        \"claim_label\": train_data[claim_id].get(\"claim_label\"),\n",
        "        \"evidences\": train_data[claim_id].get(\"evidences\", []),\n",
        "        \"pre_ranked_evidences\": [evidence_ids[i] for i in top_k_evidence_bow[claim_id]]\n",
        "    }\n",
        "    for claim_id in train_claims_ids\n",
        "}\n",
        "\n",
        "bow_output_path = os.path.join(data_dir, \"train_claims_retrieved_bow.json\")\n",
        "with open(bow_output_path, \"w\") as f:\n",
        "    json.dump(train_claims_retrieved_bow, f, indent=2)\n",
        "print(f\"\\n Saved BoW retrieval results to {bow_output_path}\")\n",
        "\n",
        "k_bow_path = os.path.join(data_dir, \"train_claims_final_k_bow.json\")\n",
        "with open(k_bow_path, \"w\") as f:\n",
        "    json.dump({\"final_k\": max_k_bow}, f, indent=2)\n",
        "print(f\" Saved final max_k (BoW) to: {k_bow_path}\")\n",
        "\n",
        "# Report threshold statistics\n",
        "print(\"\\n Analyzing cosine similarity thresholds at BoW max_k cutoff...\")\n",
        "\n",
        "cutoff_similarities_bow = []\n",
        "for i in range(len(train_claims_ids)):\n",
        "    sims = bow_cosine_similarities[i]\n",
        "    sorted_sims = np.sort(sims)[::-1]\n",
        "    if len(sorted_sims) >= max_k_bow:\n",
        "        cutoff_similarities_bow.append(sorted_sims[max_k_bow - 1])\n",
        "    else:\n",
        "        cutoff_similarities_bow.append(sorted_sims[-1])\n",
        "\n",
        "avg_sim_bow = np.mean(cutoff_similarities_bow)\n",
        "min_sim_bow = np.min(cutoff_similarities_bow)\n",
        "max_sim_bow = np.max(cutoff_similarities_bow)\n",
        "\n",
        "print(f\" Final max_k (BoW) = {max_k_bow}\")\n",
        "print(f\" Average similarity threshold at cutoff: {avg_sim_bow:.4f}\")\n",
        "print(f\" Min similarity: {min_sim_bow:.4f}\")\n",
        "print(f\" Max similarity: {max_sim_bow:.4f}\")\n",
        "\n",
        "# Report overflow stats\n",
        "num_overflows = len(overflow_claims_bow)\n",
        "total = len(train_claims_ids)\n",
        "percent = 100 * num_overflows / total\n",
        "\n",
        "print(f\"\\n {num_overflows} claims failed to retrieve gold under k_cap={k_cap} using BoW.\")\n",
        "print(f\" That’s {percent:.2f}% of all claims.\")\n",
        "\n",
        "with open(os.path.join(data_dir, \"overflow_claims_bow.json\"), \"w\") as f:\n",
        "    json.dump(overflow_claims_bow, f, indent=2)\n",
        "print(\" Saved BoW overflow claim IDs to overflow_claims_bow.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqiA8osNpz3E",
        "outputId": "b8eb921f-1c0f-47d6-d8e1-66e3ed343bea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vectorizing and reducing claims...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transforming claims: 100%|██████████| 1228/1228 [00:00<00:00, 1740657.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating cosine similarities...\n",
            "\n",
            "Evaluating top-5000 evidence coverage...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Top-5000: 100%|██████████| 1228/1228 [00:04<00:00, 295.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating top-10000 evidence coverage...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Top-10000: 100%|██████████| 1228/1228 [00:08<00:00, 149.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating top-15000 evidence coverage...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Top-15000: 100%|██████████| 1228/1228 [00:12<00:00, 101.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating top-20000 evidence coverage...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Top-20000: 100%|██████████| 1228/1228 [00:17<00:00, 72.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating top-25000 evidence coverage...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Top-25000: 100%|██████████| 1228/1228 [00:20<00:00, 59.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating top-50000 evidence coverage...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Top-50000: 100%|██████████| 1228/1228 [00:38<00:00, 31.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fixed-K Evidence Coverage Results:\n",
            " tested_k  total_claims_with_gold  claims_missing_gold  coverage_percent\n",
            "     5000                    1228                 1092             11.07\n",
            "    10000                    1228                 1011             17.67\n",
            "    15000                    1228                  943             23.21\n",
            "    20000                    1228                  884             28.01\n",
            "    25000                    1228                  840             31.60\n",
            "    50000                    1228                  649             47.15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import scipy.sparse\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Config\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "n_components = 200\n",
        "fixed_k_values = [5000, 10000, 15000, 20000, 25000, 50000, ]\n",
        "\n",
        "# Load necessary files\n",
        "train_data = json.load(open(os.path.join(data_dir, \"train-claims.json\")))\n",
        "train_p1 = json.load(open(os.path.join(data_dir, \"train-claims-preprocessed1.json\")))\n",
        "evidence_p1 = json.load(open(os.path.join(data_dir, \"evidence-preprocessed1.json\")))\n",
        "\n",
        "train_claims_ids = list(train_p1.keys())\n",
        "evidence_ids = list(evidence_p1.keys())\n",
        "\n",
        "# Load vectorizer and matrix\n",
        "tfidf_vectorizer = joblib.load(os.path.join(data_dir, \"tfidf_vectorizer.pkl\"))\n",
        "evidence_p1_tfidf = scipy.sparse.load_npz(os.path.join(data_dir, \"evidence_p1_tfidf.npz\"))\n",
        "svd = joblib.load(os.path.join(data_dir, \"tfidf_svd_model.pkl\"))\n",
        "\n",
        "# Transform claim vectors and reduce dimensions\n",
        "print(\"Vectorizing and reducing claims...\")\n",
        "train_claim_vectors = tfidf_vectorizer.transform(\n",
        "    [train_p1[cid][\"claim_text\"] for cid in tqdm(train_claims_ids, desc=\"Transforming claims\")]\n",
        ")\n",
        "evidence_tfidf_reduced = svd.transform(evidence_p1_tfidf)\n",
        "train_tfidf_reduced = svd.transform(train_claim_vectors)\n",
        "\n",
        "# Compute cosine similarities and sort\n",
        "print(\"Calculating cosine similarities...\")\n",
        "cosine_similarities = cosine_similarity(train_tfidf_reduced, evidence_tfidf_reduced)\n",
        "ranked_indices_all = np.argsort(-cosine_similarities, axis=1)\n",
        "\n",
        "# Evaluate for each k\n",
        "coverage_results = []\n",
        "\n",
        "for fixed_k in fixed_k_values:\n",
        "    missed = 0\n",
        "    total = 0\n",
        "\n",
        "    print(f\"\\nEvaluating top-{fixed_k} evidence coverage...\")\n",
        "    for i, claim_id in enumerate(tqdm(train_claims_ids, desc=f\"Top-{fixed_k}\")):\n",
        "        gold_evidence = set(train_data[claim_id].get(\"evidences\", []))\n",
        "        if not gold_evidence:\n",
        "            continue\n",
        "\n",
        "        retrieved_ids = [evidence_ids[j] for j in ranked_indices_all[i][:fixed_k]]\n",
        "        if not gold_evidence.issubset(set(retrieved_ids)):\n",
        "            missed += 1\n",
        "        total += 1\n",
        "\n",
        "    coverage_percent = 100 * (1 - missed / total)\n",
        "    coverage_results.append({\n",
        "        \"tested_k\": fixed_k,\n",
        "        \"total_claims_with_gold\": total,\n",
        "        \"claims_missing_gold\": missed,\n",
        "        \"coverage_percent\": round(coverage_percent, 2)\n",
        "    })\n",
        "\n",
        "# Output results as DataFrame\n",
        "coverage_df = pd.DataFrame(coverage_results)\n",
        "print(\"\\nFixed-K Evidence Coverage Results:\")\n",
        "print(coverage_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGLeHyFe66Fy",
        "outputId": "dcaf1505-144b-46dc-ae50-97c3850f645b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating cosine similarities (BoW)...\n",
            "\n",
            "Evaluating top-5000 evidence coverage (BoW)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Top-5000 BoW: 100%|██████████| 1228/1228 [00:03<00:00, 313.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating top-10000 evidence coverage (BoW)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Top-10000 BoW: 100%|██████████| 1228/1228 [00:07<00:00, 163.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating top-15000 evidence coverage (BoW)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Top-15000 BoW: 100%|██████████| 1228/1228 [00:11<00:00, 109.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating top-20000 evidence coverage (BoW)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Top-20000 BoW: 100%|██████████| 1228/1228 [00:16<00:00, 74.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating top-25000 evidence coverage (BoW)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Top-25000 BoW: 100%|██████████| 1228/1228 [00:19<00:00, 63.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating top-50000 evidence coverage (BoW)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Top-50000 BoW: 100%|██████████| 1228/1228 [00:30<00:00, 39.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fixed-K Evidence Coverage Results (BoW):\n",
            " tested_k  total_claims_with_gold  claims_missing_gold  coverage_percent\n",
            "     5000                    1228                  727             40.80\n",
            "    10000                    1228                  632             48.53\n",
            "    15000                    1228                  564             54.07\n",
            "    20000                    1228                  522             57.49\n",
            "    25000                    1228                  477             61.16\n",
            "    50000                    1228                  365             70.28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import scipy.sparse\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Config\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "fixed_k_values = [5000, 10000, 15000, 20000, 25000, 50000]\n",
        "\n",
        "# Load necessary files\n",
        "train_data = json.load(open(os.path.join(data_dir, \"train-claims.json\")))\n",
        "train_p1 = json.load(open(os.path.join(data_dir, \"train-claims-preprocessed1.json\")))\n",
        "evidence_p1 = json.load(open(os.path.join(data_dir, \"evidence-preprocessed1.json\")))\n",
        "\n",
        "train_claims_ids = list(train_p1.keys())\n",
        "evidence_ids = list(evidence_p1.keys())\n",
        "\n",
        "# Load BoW vectorizer and matrix\n",
        "bow_vectorizer = joblib.load(os.path.join(data_dir, \"bow_vectorizer.pkl\"))\n",
        "evidence_p1_bow = scipy.sparse.load_npz(os.path.join(data_dir, \"evidence_p1_bow.npz\"))\n",
        "train_p1_bow = scipy.sparse.load_npz(os.path.join(data_dir, \"train_p1_bow.npz\"))\n",
        "\n",
        "# Compute cosine similarities and sort\n",
        "print(\"Calculating cosine similarities (BoW)...\")\n",
        "cosine_similarities = cosine_similarity(train_p1_bow, evidence_p1_bow)\n",
        "ranked_indices_all = np.argsort(-cosine_similarities, axis=1)\n",
        "\n",
        "# Evaluate for each k\n",
        "coverage_results = []\n",
        "\n",
        "for fixed_k in fixed_k_values:\n",
        "    missed = 0\n",
        "    total = 0\n",
        "\n",
        "    print(f\"\\nEvaluating top-{fixed_k} evidence coverage (BoW)...\")\n",
        "    for i, claim_id in enumerate(tqdm(train_claims_ids, desc=f\"Top-{fixed_k} BoW\")):\n",
        "        gold_evidence = set(train_data[claim_id].get(\"evidences\", []))\n",
        "        if not gold_evidence:\n",
        "            continue\n",
        "\n",
        "        retrieved_ids = [evidence_ids[j] for j in ranked_indices_all[i][:fixed_k]]\n",
        "        if not gold_evidence.issubset(set(retrieved_ids)):\n",
        "            missed += 1\n",
        "        total += 1\n",
        "\n",
        "    coverage_percent = 100 * (1 - missed / total)\n",
        "    coverage_results.append({\n",
        "        \"tested_k\": fixed_k,\n",
        "        \"total_claims_with_gold\": total,\n",
        "        \"claims_missing_gold\": missed,\n",
        "        \"coverage_percent\": round(coverage_percent, 2)\n",
        "    })\n",
        "\n",
        "# Output results as DataFrame\n",
        "coverage_df = pd.DataFrame(coverage_results)\n",
        "print(\"\\nFixed-K Evidence Coverage Results (BoW):\")\n",
        "print(coverage_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcBNQ3Sl8Ghg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrFzZXatILTL"
      },
      "source": [
        "#### 2.1.2 Hybrid Method - BM25 & MiniLM Bi-Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYgDyPbQ8DOX"
      },
      "source": [
        "##### 2.1.2.1. BM25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hjb7MJs7fFOy",
        "outputId": "f4c70655-44d9-4a21-de89-c548681d5ada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,676 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,934 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,939 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,546 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,245 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,363 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,517 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
            "Get:20 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,723 kB]\n",
            "Fetched 30.5 MB in 4s (6,972 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxt-dev libxtst6 libxxf86dga1 openjdk-11-jre\n",
            "  x11-utils\n",
            "Suggested packages:\n",
            "  libxt-doc openjdk-11-demo openjdk-11-source visualvm mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxt-dev libxtst6 libxxf86dga1 openjdk-11-jdk\n",
            "  openjdk-11-jre x11-utils\n",
            "0 upgraded, 10 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 6,920 kB of archives.\n",
            "After this operation, 16.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.27+6~us1-0ubuntu1~22.04 [214 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk amd64 11.0.27+6~us1-0ubuntu1~22.04 [2,895 kB]\n",
            "Fetched 6,920 kB in 2s (3,390 kB/s)\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../0-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../1-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../2-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../3-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../4-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../5-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../6-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../7-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-11-jre:amd64.\n",
            "Preparing to unpack .../8-openjdk-11-jre_11.0.27+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-11-jre:amd64 (11.0.27+6~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-11-jdk:amd64.\n",
            "Preparing to unpack .../9-openjdk-11-jdk_11.0.27+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-11-jdk:amd64 (11.0.27+6~us1-0ubuntu1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up openjdk-11-jre:amd64 (11.0.27+6~us1-0ubuntu1~22.04) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up openjdk-11-jdk:amd64 (11.0.27+6~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "update-alternatives: warning: forcing reinstallation of alternative /usr/lib/jvm/java-11-openjdk-amd64/bin/java because link group java is broken\n",
            "openjdk version \"11.0.27\" 2025-04-15\n",
            "OpenJDK Runtime Environment (build 11.0.27+6-post-Ubuntu-0ubuntu122.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.27+6-post-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y openjdk-11-jdk\n",
        "!update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-11-openjdk-amd64/bin/java 1\n",
        "!update-alternatives --set java /usr/lib/jvm/java-11-openjdk-amd64/bin/java\n",
        "!java -version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dq8sr1UcMVd3",
        "outputId": "7a9a49c2-b3af-4629-e0ff-a28dcb04f725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyserini==0.17.0\n",
            "  Downloading pyserini-0.17.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Downloading pyserini-0.17.0-py3-none-any.whl (109.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyserini\n",
            "Successfully installed pyserini-0.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyserini==0.17.0 --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oCz9n-IKkCun",
        "outputId": "2b2f3157-e774-4534-8f86-a42e6ed8bd9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (3.0.12)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyserini 0.17.0 requires nmslib>=2.1.1, which is not installed.\n",
            "pyserini 0.17.0 requires pyjnius>=1.4.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.22.0\n",
            "Collecting pyjnius\n",
            "  Downloading pyjnius-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Downloading pyjnius-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyjnius\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyserini 0.17.0 requires nmslib>=2.1.1, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pyjnius-1.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install cython\n",
        "!pip install onnxruntime\n",
        "!pip install pyjnius"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I6-lWpKXyPpH",
        "outputId": "e5bac114-b35a-4dee-c543-493f6a82fb23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_LOGToGBhE71",
        "outputId": "ba75d096-0061-4c35-d5bb-cf6a234df636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pyserini.index is deprecated, please use pyserini.index.lucene.\n",
            "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
            "2025-05-13 03:53:07,649 INFO  [main] index.IndexCollection (IndexCollection.java:645) - Setting log level to INFO\n",
            "2025-05-13 03:53:07,652 INFO  [main] index.IndexCollection (IndexCollection.java:648) - Starting indexer...\n",
            "2025-05-13 03:53:07,652 INFO  [main] index.IndexCollection (IndexCollection.java:649) - ============ Loading Parameters ============\n",
            "2025-05-13 03:53:07,653 INFO  [main] index.IndexCollection (IndexCollection.java:650) - DocumentCollection path: corpus_json\n",
            "2025-05-13 03:53:07,653 INFO  [main] index.IndexCollection (IndexCollection.java:651) - CollectionClass: JsonCollection\n",
            "2025-05-13 03:53:07,653 INFO  [main] index.IndexCollection (IndexCollection.java:652) - Generator: DefaultLuceneDocumentGenerator\n",
            "2025-05-13 03:53:07,654 INFO  [main] index.IndexCollection (IndexCollection.java:653) - Threads: 4\n",
            "2025-05-13 03:53:07,654 INFO  [main] index.IndexCollection (IndexCollection.java:654) - Language: en\n",
            "2025-05-13 03:53:07,654 INFO  [main] index.IndexCollection (IndexCollection.java:655) - Stemmer: porter\n",
            "2025-05-13 03:53:07,654 INFO  [main] index.IndexCollection (IndexCollection.java:656) - Keep stopwords? false\n",
            "2025-05-13 03:53:07,655 INFO  [main] index.IndexCollection (IndexCollection.java:657) - Stopwords: null\n",
            "2025-05-13 03:53:07,655 INFO  [main] index.IndexCollection (IndexCollection.java:658) - Store positions? true\n",
            "2025-05-13 03:53:07,655 INFO  [main] index.IndexCollection (IndexCollection.java:659) - Store docvectors? true\n",
            "2025-05-13 03:53:07,655 INFO  [main] index.IndexCollection (IndexCollection.java:660) - Store document \"contents\" field? false\n",
            "2025-05-13 03:53:07,656 INFO  [main] index.IndexCollection (IndexCollection.java:661) - Store document \"raw\" field? true\n",
            "2025-05-13 03:53:07,656 INFO  [main] index.IndexCollection (IndexCollection.java:662) - Additional fields to index: []\n",
            "2025-05-13 03:53:07,656 INFO  [main] index.IndexCollection (IndexCollection.java:663) - Optimize (merge segments)? false\n",
            "2025-05-13 03:53:07,656 INFO  [main] index.IndexCollection (IndexCollection.java:664) - Whitelist: null\n",
            "2025-05-13 03:53:07,656 INFO  [main] index.IndexCollection (IndexCollection.java:665) - Pretokenized?: false\n",
            "2025-05-13 03:53:07,657 INFO  [main] index.IndexCollection (IndexCollection.java:685) - Directly building Lucene indexes...\n",
            "2025-05-13 03:53:07,657 INFO  [main] index.IndexCollection (IndexCollection.java:686) - Index path: indexes/evidence_index\n",
            "2025-05-13 03:53:07,666 INFO  [main] index.IndexCollection (IndexCollection.java:741) - ============ Indexing Collection ============\n",
            "2025-05-13 03:53:07,829 INFO  [main] index.IndexCollection (IndexCollection.java:845) - Thread pool with 4 threads initialized.\n",
            "2025-05-13 03:53:07,829 INFO  [main] index.IndexCollection (IndexCollection.java:847) - Initializing collection in corpus_json\n",
            "2025-05-13 03:53:07,832 INFO  [main] index.IndexCollection (IndexCollection.java:856) - 1 file found\n",
            "2025-05-13 03:53:07,832 INFO  [main] index.IndexCollection (IndexCollection.java:857) - Starting to index...\n",
            "2025-05-13 03:53:40,216 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:250) - corpus_json/evidence_corpus.jsonl: 1208504 docs added.\n",
            "2025-05-13 03:53:47,309 INFO  [main] index.IndexCollection (IndexCollection.java:941) - Indexing Complete! 1,208,504 documents indexed\n",
            "2025-05-13 03:53:47,309 INFO  [main] index.IndexCollection (IndexCollection.java:942) - ============ Final Counter Values ============\n",
            "2025-05-13 03:53:47,309 INFO  [main] index.IndexCollection (IndexCollection.java:943) - indexed:        1,208,504\n",
            "2025-05-13 03:53:47,309 INFO  [main] index.IndexCollection (IndexCollection.java:944) - unindexable:            0\n",
            "2025-05-13 03:53:47,309 INFO  [main] index.IndexCollection (IndexCollection.java:945) - empty:                323\n",
            "2025-05-13 03:53:47,310 INFO  [main] index.IndexCollection (IndexCollection.java:946) - skipped:                0\n",
            "2025-05-13 03:53:47,310 INFO  [main] index.IndexCollection (IndexCollection.java:947) - errors:                 0\n",
            "2025-05-13 03:53:47,314 INFO  [main] index.IndexCollection (IndexCollection.java:950) - Total 1,208,504 documents indexed in 00:00:39\n"
          ]
        }
      ],
      "source": [
        "!rm -rf indexes/evidence_index\n",
        "!python -m pyserini.index \\\n",
        "  --collection JsonCollection \\\n",
        "  --input corpus_json \\\n",
        "  --index indexes/evidence_index \\\n",
        "  --generator DefaultLuceneDocumentGenerator \\\n",
        "  --threads 4 \\\n",
        "  --storePositions --storeDocvectors --storeRaw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PfWvUK4hyemA",
        "outputId": "b93213c6-f7d3-410e-d927-0c1d7db8f0e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m136.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyserini 0.17.0 requires nmslib>=2.1.1, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip install onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o6Bm7kngBSo",
        "outputId": "d77a2ec4-125e-4f75-b7c0-3f329077c2e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Converted 1208827 evidence entries to Pyserini JSONL format at corpus_json/evidence_corpus.jsonl\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "evidence_path = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "output_jsonl_dir = \"corpus_json\"\n",
        "output_jsonl_file = os.path.join(output_jsonl_dir, \"evidence_corpus.jsonl\")\n",
        "\n",
        "os.makedirs(output_jsonl_dir, exist_ok=True)\n",
        "\n",
        "with open(evidence_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    evidence_corpus = json.load(f)\n",
        "\n",
        "# Convert to Pyserini-compatible JSONL\n",
        "with open(output_jsonl_file, \"w\", encoding=\"utf-8\") as out_f:\n",
        "    for evid, text in evidence_corpus.items():\n",
        "        doc = {\"id\": str(evid), \"contents\": text}\n",
        "        out_f.write(json.dumps(doc) + \"\\n\")\n",
        "\n",
        "print(f\" Converted {len(evidence_corpus)} evidence entries to Pyserini JSONL format at {output_jsonl_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GsbxljPXvC-h",
        "outputId": "5f689f81-9562-4e42-c7c9-277307149a66"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/NLP_content/indexes/evidence_index'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the evidence BM25 index\n",
        "import shutil\n",
        "DATA_DIR = \"/content/drive/MyDrive/NLP_content\"\n",
        "shutil.copytree(\"indexes/evidence_index\", f\"{DATA_DIR}/indexes/evidence_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQKoLOW3h9pb",
        "outputId": "1c6ec501-b0cf-4f5f-cceb-f0184bc469f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running parallel BM25 grid search on 80 configs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [36:57<00:00, 27.72s/it]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from itertools import product\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from pyserini.search.lucene import LuceneSearcher\n",
        "\n",
        "# Paths and grid\n",
        "DATA_DIR = \"/content/drive/MyDrive/NLP_content\"\n",
        "INDEX_PATH = \"indexes/evidence_index\"\n",
        "SAVE_PATH = os.path.join(DATA_DIR, \"bm25_grid_results.json\")\n",
        "\n",
        "PARAM_GRID = {\n",
        "    \"k1\": [0.5, 1.0, 1.5, 2.0],\n",
        "    \"b\": [0.3, 0.5, 0.7, 0.9],\n",
        "    \"top_k\": [100, 500, 1000, 2000, 5000]\n",
        "}\n",
        "\n",
        "# Load data\n",
        "def load_json_file(filename):\n",
        "    with open(os.path.join(DATA_DIR, filename)) as f:\n",
        "        return json.load(f)\n",
        "\n",
        "train_data = load_json_file(\"train-claims-preprocessed2.json\")\n",
        "\n",
        "# Evaluate BM25\n",
        "def evaluate_bm25(params):\n",
        "    k1, b, top_k = params\n",
        "    try:\n",
        "        searcher = LuceneSearcher(INDEX_PATH)\n",
        "        searcher.set_bm25(k1=k1, b=b)\n",
        "\n",
        "        total_claims = 0\n",
        "        total_gold = 0\n",
        "        total_retrieved_gold = 0\n",
        "        full_coverage_count = 0\n",
        "\n",
        "        for claim_data in train_data.values():\n",
        "            gold_evid_ids = set(claim_data.get(\"evidences\", []))\n",
        "            if not gold_evid_ids:\n",
        "                continue\n",
        "\n",
        "            hits = searcher.search(claim_data[\"claim_text\"], top_k)\n",
        "            retrieved_ids = set(hit.docid for hit in hits)\n",
        "            matched = gold_evid_ids.intersection(retrieved_ids)\n",
        "\n",
        "            total_gold += len(gold_evid_ids)\n",
        "            total_retrieved_gold += len(matched)\n",
        "            total_claims += 1\n",
        "            if matched == gold_evid_ids:\n",
        "                full_coverage_count += 1\n",
        "\n",
        "        return {\n",
        "            \"k1\": k1,\n",
        "            \"b\": b,\n",
        "            \"top_k\": top_k,\n",
        "            \"avg_retrieved_gold\": round(total_retrieved_gold / total_claims, 2),\n",
        "            \"recall\": round(total_retrieved_gold / total_gold * 100, 2),\n",
        "            \"full_coverage_pct\": round(full_coverage_count / total_claims * 100, 2)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"k1\": k1, \"b\": b, \"top_k\": top_k, \"error\": str(e)}\n",
        "\n",
        "# Load prior results\n",
        "results = []\n",
        "done_configs = set()\n",
        "if os.path.exists(SAVE_PATH):\n",
        "    with open(SAVE_PATH, \"r\") as f:\n",
        "        results = json.load(f)\n",
        "        done_configs = {(r[\"k1\"], r[\"b\"], r[\"top_k\"]) for r in results}\n",
        "\n",
        "# Run parallel search with checkpointing\n",
        "grid = list(product(PARAM_GRID[\"k1\"], PARAM_GRID[\"b\"], PARAM_GRID[\"top_k\"]))\n",
        "grid = [params for params in grid if params not in done_configs]\n",
        "\n",
        "print(f\"Running parallel BM25 grid search on {len(grid)} configs...\")\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "    for result in tqdm(executor.map(evaluate_bm25, grid), total=len(grid)):\n",
        "        results.append(result)\n",
        "        with open(SAVE_PATH, \"w\") as f:\n",
        "            json.dump(results, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsfkYgO276eB",
        "outputId": "3643edad-863d-4195-f08d-243ac92d988a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 configurations for top_k = 5000:\n",
            "\n",
            "{'k1': 0.5, 'b': 0.3, 'top_k': 5000, 'avg_retrieved_gold': 2.83, 'recall': 84.33, 'full_coverage_pct': 68.0}\n",
            "{'k1': 0.5, 'b': 0.5, 'top_k': 5000, 'avg_retrieved_gold': 2.83, 'recall': 84.18, 'full_coverage_pct': 67.83}\n",
            "{'k1': 1.0, 'b': 0.3, 'top_k': 5000, 'avg_retrieved_gold': 2.82, 'recall': 84.16, 'full_coverage_pct': 67.75}\n",
            "{'k1': 0.5, 'b': 0.7, 'top_k': 5000, 'avg_retrieved_gold': 2.82, 'recall': 84.04, 'full_coverage_pct': 67.18}\n",
            "{'k1': 1.0, 'b': 0.5, 'top_k': 5000, 'avg_retrieved_gold': 2.82, 'recall': 83.94, 'full_coverage_pct': 67.1}\n",
            "{'k1': 1.5, 'b': 0.3, 'top_k': 5000, 'avg_retrieved_gold': 2.82, 'recall': 83.89, 'full_coverage_pct': 67.1}\n",
            "{'k1': 0.5, 'b': 0.9, 'top_k': 5000, 'avg_retrieved_gold': 2.81, 'recall': 83.79, 'full_coverage_pct': 66.69}\n",
            "{'k1': 1.0, 'b': 0.7, 'top_k': 5000, 'avg_retrieved_gold': 2.81, 'recall': 83.72, 'full_coverage_pct': 66.21}\n",
            "{'k1': 1.5, 'b': 0.5, 'top_k': 5000, 'avg_retrieved_gold': 2.81, 'recall': 83.67, 'full_coverage_pct': 66.45}\n",
            "{'k1': 2.0, 'b': 0.3, 'top_k': 5000, 'avg_retrieved_gold': 2.81, 'recall': 83.65, 'full_coverage_pct': 66.61}\n",
            "\n",
            "Top 10 configurations for top_k = 2000:\n",
            "\n",
            "{'k1': 0.5, 'b': 0.5, 'top_k': 2000, 'avg_retrieved_gold': 2.58, 'recall': 76.86, 'full_coverage_pct': 57.17}\n",
            "{'k1': 0.5, 'b': 0.3, 'top_k': 2000, 'avg_retrieved_gold': 2.58, 'recall': 76.78, 'full_coverage_pct': 56.76}\n",
            "{'k1': 0.5, 'b': 0.7, 'top_k': 2000, 'avg_retrieved_gold': 2.57, 'recall': 76.69, 'full_coverage_pct': 56.68}\n",
            "{'k1': 1.0, 'b': 0.3, 'top_k': 2000, 'avg_retrieved_gold': 2.57, 'recall': 76.54, 'full_coverage_pct': 56.51}\n",
            "{'k1': 1.5, 'b': 0.3, 'top_k': 2000, 'avg_retrieved_gold': 2.57, 'recall': 76.42, 'full_coverage_pct': 56.35}\n",
            "{'k1': 1.0, 'b': 0.5, 'top_k': 2000, 'avg_retrieved_gold': 2.56, 'recall': 76.39, 'full_coverage_pct': 56.35}\n",
            "{'k1': 0.5, 'b': 0.9, 'top_k': 2000, 'avg_retrieved_gold': 2.56, 'recall': 76.25, 'full_coverage_pct': 56.43}\n",
            "{'k1': 1.5, 'b': 0.5, 'top_k': 2000, 'avg_retrieved_gold': 2.55, 'recall': 75.89, 'full_coverage_pct': 55.46}\n",
            "{'k1': 2.0, 'b': 0.3, 'top_k': 2000, 'avg_retrieved_gold': 2.55, 'recall': 75.89, 'full_coverage_pct': 56.03}\n",
            "{'k1': 1.0, 'b': 0.7, 'top_k': 2000, 'avg_retrieved_gold': 2.54, 'recall': 75.69, 'full_coverage_pct': 55.05}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Load saved results\n",
        "results_path = \"/content/drive/MyDrive/NLP_content/bm25_grid_results.json\"\n",
        "with open(results_path, \"r\") as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "# Filter for top_k = 5000 and sort by recall\n",
        "results_k5000 = sorted(\n",
        "    [r for r in results if r[\"top_k\"] == 5000],\n",
        "    key=lambda x: -x[\"recall\"]\n",
        ")\n",
        "\n",
        "# Filter for top_k = 2000 and sort by recall\n",
        "results_k2000 = sorted(\n",
        "    [r for r in results if r[\"top_k\"] == 2000],\n",
        "    key=lambda x: -x[\"recall\"]\n",
        ")\n",
        "\n",
        "# Print top 10 for k = 5000\n",
        "print(\"Top 10 configurations for top_k = 5000:\\n\")\n",
        "for res in results_k5000[:10]:\n",
        "    print(res)\n",
        "\n",
        "# Print top 10 for k = 2000\n",
        "print(\"\\nTop 10 configurations for top_k = 2000:\\n\")\n",
        "for res in results_k2000[:10]:\n",
        "    print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwEmRZiZXWAx",
        "outputId": "44321cd7-bb93-47e8-e2dc-e3919079ccfb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Mining BM25 and Hard Negatives: 100%|██████████| 1228/1228 [05:32<00:00,  3.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved enriched claim data with BM25 scores to: /content/drive/MyDrive/NLP_content/train-claims-with-negatives-bm25.json\n"
          ]
        }
      ],
      "source": [
        "# Mining BM25 Hard Negatives (explicitly sorted by scores)\n",
        "import os\n",
        "import json\n",
        "from pyserini.search.lucene import LuceneSearcher\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Constants\n",
        "DATA_DIR = \"/content/drive/MyDrive/NLP_content\"\n",
        "INDEX_PATH = os.path.join(DATA_DIR, \"indexes/evidence_index\")\n",
        "INPUT_PATH = os.path.join(DATA_DIR, \"train-claims-preprocessed2.json\")\n",
        "OUTPUT_PATH = os.path.join(DATA_DIR, \"train-claims-with-negatives-bm25.json\")\n",
        "\n",
        "# BM25 params\n",
        "k1 = 0.5\n",
        "b = 0.3\n",
        "top_k = 5000\n",
        "\n",
        "# Load training claims\n",
        "with open(INPUT_PATH, 'r') as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "# Init searcher\n",
        "searcher = LuceneSearcher(INDEX_PATH)\n",
        "searcher.set_bm25(k1=k1, b=b)\n",
        "\n",
        "# Output\n",
        "updated_data = {}\n",
        "\n",
        "# Search and add BM25 evidence + hard negatives with scores\n",
        "for claim_id, claim_data in tqdm(train_data.items(), desc=\"Mining BM25 and Hard Negatives\"):\n",
        "    claim_text = claim_data[\"claim_text\"]\n",
        "    gold_ids = set(claim_data.get(\"evidences\", []))\n",
        "\n",
        "    hits = searcher.search(claim_text, top_k)\n",
        "\n",
        "    # Separate matched golds and hard negatives with score\n",
        "    bm25_evidence = [\n",
        "        {\"id\": hit.docid, \"score\": hit.score}\n",
        "        for hit in hits if hit.docid in gold_ids\n",
        "    ]\n",
        "    hard_negatives = [\n",
        "        {\"id\": hit.docid, \"score\": hit.score}\n",
        "        for hit in hits if hit.docid not in gold_ids\n",
        "    ]\n",
        "\n",
        "    updated_data[claim_id] = {\n",
        "        \"claim_text\": claim_text,\n",
        "        \"claim_label\": claim_data.get(\"claim_label\", \"\"),\n",
        "        \"evidences\": list(gold_ids),\n",
        "        \"BM25_evidence\": bm25_evidence,\n",
        "        \"hard_negative\": hard_negatives\n",
        "    }\n",
        "\n",
        "# Save to JSON\n",
        "with open(OUTPUT_PATH, \"w\") as f:\n",
        "    json.dump(updated_data, f, indent=2)\n",
        "\n",
        "print(f\" Saved enriched claim data with BM25 scores to: {OUTPUT_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6OXw9j3X_Fw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhd-Cjgh8PQ9"
      },
      "source": [
        "##### 2.1.2.2. MiniLM Bi-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "nuGZPYqqwryF",
        "outputId": "cf4b5cdb-67b2-42c8-89a7-1e44277a174f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "7e651669522a4a35a435250f07340f6c",
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2H6mB1u1L1UD",
        "outputId": "50c02fc0-b687-491b-d0ae-a604ac305ea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.27.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgR0Tcp9Qx_O",
        "outputId": "211bf6da-19e7-4044-a168-05e1c42a33ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meachann1018\u001b[0m (\u001b[33meachann1018-the-university-of-melbourne\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_API_KEY\"] = \"d5028d81ac9f90338e2452cbdbb9635c9d506007\"\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hx2hl7dUxRm",
        "outputId": "295f93d8-bc08-4213-cc64-9e23fca41c9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7hQUGF1VpZX",
        "outputId": "40b322df-5b79-48e2-8391-cc6fde74119d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "!wandb login --relogin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a284ba47f0194d0dae7a0af2ca3f572b",
            "e5595cf0efd5478d9cf9276990928548",
            "5a30fadc98414f1fbc6a4936c114f1c6",
            "d913aea91bd241e08b4ac0270ba66a3f",
            "6f31188390f743d6876373b9e926b927",
            "36e027cf2e38486199cea7fca76bff29",
            "217dbb470042445bbe182584db9d3ee7",
            "31f77a8913644541a2d2779152e38eb3",
            "5983771b1ff84ecebd687bb40600fd14",
            "deb15ee6cbb449f2a71b3bd887b0b522",
            "fcf1401362b74fd08dba2422d4b9badb",
            "20aa3a5475db40218be2f2515a164488",
            "8186681c5c3b468891db65493a69d88e",
            "3b76daa4eadb4a9fa95f9dad517ee9ab",
            "f6c172a0952f48b6a89245cd256f538a",
            "d5a31385f10948d48a326839053023d0",
            "4f3786b346c64ae682876cf7b51daf88",
            "4cafbf81dece421ea0749812587c7a90",
            "930a1f9b795a4ad490c63c799de0e5e5",
            "b0d44775e5134acb9ff54457fe0c2da7",
            "5011c2b8cbcf4e64a889285333243ea6",
            "602a6aef87ac4bc39a45789a3d464a35",
            "fa7d869ed6a44920816669ff19107f72",
            "3825a949fa7046aeb5dfeb1c35d0ef30",
            "e92e5a35908b43a793ca49da2bc83f45",
            "23fb174689e942a2b6b560a2b47f9efb",
            "87aaff89a0f244ef82129fb45595e5d7",
            "5d3e49bb0e664aa9b8e3a92ee502dd79",
            "48c983a1aa3f43b5b746ad1ed93df3e6",
            "f7f2b9ce9cf549f784c33df8c06093ea",
            "49bb8c7a738141fa968e59f2cc99f829",
            "87d1df9ec78142bc871b612a7fa0146b",
            "be53796edb134a228a96c590b955dd13",
            "5ca1a822c6904ffba99bc59bf1d10930",
            "f443a057bbdb4874bebdc9cb3a984012",
            "ae10c0be2f2e46f8a3981f1bd8c598f6",
            "4ef86e22b2934fb58509cfbaa3c766d9",
            "e82abf7a887d43c798ae1dd265b656c7",
            "71e2256e98c840c8baad385c54646cce",
            "500114f4c7694bb6a94ca0051b7bb7e8",
            "3fd918f3eca344a59d081cb3f2a0c225",
            "a6d82789820c4a1f9a50d837b98fe292",
            "9e856a14cbaa4e19b5ffeb1a0b93d96c",
            "2bff6428ab684ed3a940099eb1a6c400",
            "93ab1c350b1c4352bf5a48d74021a303",
            "0a3366b6fbfa4027a92023f2af454088",
            "7b0853bbacf846569f08bacbae7e3b95",
            "48410095b41e4b80a9c0d288cf4e5491",
            "abfc0d9e53894d668bd4b2fae4e23b97",
            "9fc222c9d68e4d3b9e408eab62e96ec7",
            "da2e03b743c446d9a23844fc145b91cd",
            "6d88b543318d47f2af9d61fafed75f8f",
            "8f02be075907411cb3b1fc0e8f194211",
            "eac1ebb3c3104f2c9ba18fbef2dd0681",
            "75e7fb34345249378d5359fa76083f18",
            "40b01e7b84394ed3842793bacd30db72",
            "d33a2a451f374928ae1847f9226063b4",
            "1c80ee6343944b0c9eb9e0d38c0cc115",
            "b0f251cafe1b417282b1542fd5055718",
            "b92ec1277ab343cb8a0012b78228374c",
            "7e3f5b53b8664954b67545935417d2f7",
            "5fdb65e837eb41ac9939c669992436a4",
            "210cd858d57e4a258a85471cfac35ec5",
            "673e8b94c474446187261a3a8e3d83f0",
            "39b470e915d84cd9b6dfb2020041f478",
            "31620a6d010d4a4cb0add4ecbc74e79f",
            "ea7d1b0add57479b872a48e446d5f9cd",
            "988c476294034cd793d6c332c90b3c91",
            "cb110b7dfba04f10996331bebf5b9adc",
            "20962f360c2d4a24a197a2c29d849be7",
            "4c30463a6dc04baeb6db1da9a9dbd878",
            "a049c36706af4574b615c27c0bfcf21f",
            "d3eaa160df0943308591ef2c93aa47e1",
            "8d77c036742e40e896abc183ff53b55d",
            "bcd962d17143472c9d55de9734155891",
            "77056c33d67c48d2948e44ea43dd6412",
            "d25340a09d244f69a81b4f6e9dd46f23",
            "5c13d5e47d6f4b0caebf5e1ecbec6d38",
            "455070d5878b47bb9a7e0f52adc55075",
            "51c69a2249f749dcb1f65e3d2ad86b2b",
            "e240989783324999a295455535008f67",
            "fb6685afc509401590f055296dd9e35d",
            "604bb16234ad4ff391ab08a3306cd247",
            "0e453801e8b24aadb134fe4fb7e25d86",
            "0352425c5228493596c4e6bd0acebce0",
            "b37d9ad9996e4aa8917bac6b5f9a1990",
            "69486fbc512f4ea29133c7c072af3b38",
            "1849298134d3487fa730b33b354de942",
            "74e327f1c4974392af4903eb7001d98b",
            "3ff372ec8c2a4dda85906a609c023351",
            "de8b890b526e4dd7a52f413c0617d27d",
            "678de676cad44f57a4e86a1abaa6771a",
            "35685f7fc77d438480b182f3116c37f5",
            "a6ef1de376674965840ca13a20d3b3c5",
            "76e867625f6042c39ef6210f507edb65",
            "42e89f08f7bf41aea4cf7b73f64dfe25",
            "1774d0da3e5c4e448f069f15fe5844f6",
            "4e27e614d6d544d59d72f09befba9cd7",
            "767245744ff548eabb1fcf5a1910bd65",
            "f32f048c6f274ff79396def6c867d640",
            "19871eb281914fc0810d95d717bbd6e2",
            "f391e1b820e44f7f91d41ed293a33b74",
            "805e36cb74734913a633d9f12c9b19d4",
            "65099359d482443d9914f4f1473d9a34",
            "c819e8e024a44262be4a09d3580b691a",
            "7d0c72e274dd4a929fb513733a151588",
            "38c58dfd4a9e4be0bfcf02125798f744",
            "ad3ca0606ca34f10badf7370490293f4",
            "216f5cceaf234621b364b808ab9f0eb5",
            "a8360e40715f48d0b168c90f0058556d",
            "5940ed873508463d8885dcd7a778a8e5",
            "ac68dd22ae5a4b25a2828c2cd2d5de96",
            "588b06a179df4ac1aff4663690ff0942",
            "c70cd3d4c82245228d005b4c88957586",
            "0146f95811134b778f2b96cb49697f66",
            "6409c7b96045486184be7bea5bcfb46f",
            "d876af2d1bfe4d189e58400bd35badaf",
            "825d1df7b821415d829b619abd0b8449",
            "017cbebcc9294ec797a50ab13c3b8815",
            "b4366ce21ed7416487bf76f306fa92f9",
            "5455dafb03544f3998f31f80863454bb",
            "1ae4d182ba8145ec910960cc037f5faf",
            "7dc2b4637afc42d39fe95daf202285be",
            "bb4a705623d34fe3a1ca80f4b58f7557",
            "89f51ccc2775496f880167da8ea1eadf",
            "1b45b8389cf94e488c49b62a43283f48",
            "7c8da8544f784b9aa50973766d4bcf6b",
            "d0b970afe07f479aa78b0093f2d3f405",
            "e4a43c722a8f4073be47cd3482c84687",
            "22a8a4a5b09d4731b0746f353fdec15a",
            "291007ab7474474bb4f14a847eb5ba27",
            "2aa26fd385fc47b7b57b146eb9ce809a",
            "1f21db38cf98420587b7af56f6120dbb",
            "6aa85dc139024e979a17a810074f476f",
            "64a52f1ba523441f97aed9de9503b118",
            "63cd1e778208466ab190c9e0c1f99c61",
            "6a7e1a62176b47df8de4b36c312d3158",
            "38d0547ac5e14c3c86d4c1d9e7b537f0",
            "bdc5d2599d3d446d92689b90e738b982",
            "9609adc6a825429087e1ebdeaf4670b7",
            "0405c3a0280c4ee890b9dd55528c9cb7",
            "16c6a087fc3b42dc830cc5e04509c1fb",
            "9e66a5966c664fb6980e6d12de64e042"
          ]
        },
        "id": "RMznI2ZdziN5",
        "outputId": "3c03ac3f-f05c-4889-c06d-070841403ec7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Constructing triplets: 100%|██████████| 1228/1228 [00:00<00:00, 13728.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prepared 10428 triplet examples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a284ba47f0194d0dae7a0af2ca3f572b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20aa3a5475db40218be2f2515a164488",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa7d869ed6a44920816669ff19107f72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ca1a822c6904ffba99bc59bf1d10930",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93ab1c350b1c4352bf5a48d74021a303",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40b01e7b84394ed3842793bacd30db72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea7d1b0add57479b872a48e446d5f9cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c13d5e47d6f4b0caebf5e1ecbec6d38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74e327f1c4974392af4903eb7001d98b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f32f048c6f274ff79396def6c867d640",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5940ed873508463d8885dcd7a778a8e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ae4d182ba8145ec910960cc037f5faf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250513_120326-2a4foqvf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/eachann1018-the-university-of-melbourne/sentence-transformers/runs/2a4foqvf' target=\"_blank\">checkpoints/model</a></strong> to <a href='https://wandb.ai/eachann1018-the-university-of-melbourne/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/eachann1018-the-university-of-melbourne/sentence-transformers' target=\"_blank\">https://wandb.ai/eachann1018-the-university-of-melbourne/sentence-transformers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/eachann1018-the-university-of-melbourne/sentence-transformers/runs/2a4foqvf' target=\"_blank\">https://wandb.ai/eachann1018-the-university-of-melbourne/sentence-transformers/runs/2a4foqvf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5216' max='5216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5216/5216 05:18, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.052100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.035300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.025900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.016100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.014600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.009400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.008000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.006900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to: /content/drive/MyDrive/NLP_content/fine_tuned_dpr_triplet_model\n",
            "Encoding evidence for FAISS index...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f21db38cf98420587b7af56f6120dbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/18888 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index built with 1208827 documents and saved to: /content/drive/MyDrive/NLP_content/evidence_faiss.index\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import faiss\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Config and Data Load\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "triplet_source_file = os.path.join(data_dir, \"train-claims-with-negatives.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "model_save_path = os.path.join(data_dir, \"fine_tuned_dpr_triplet_model\")\n",
        "faiss_index_path = os.path.join(data_dir, \"evidence_faiss.index\")\n",
        "\n",
        "with open(triplet_source_file, 'r') as f:\n",
        "    claim_data = json.load(f)\n",
        "with open(evidence_file, 'r') as f:\n",
        "    evidence_corpus = json.load(f)\n",
        "\n",
        "# Construct Triplet Training Examples\n",
        "triplet_examples = []\n",
        "for cid, item in tqdm(claim_data.items(), desc=\"Constructing triplets\"):\n",
        "    claim_text = item[\"claim_text\"]\n",
        "    bm25_evidence = item.get(\"BM25_evidence\", [])\n",
        "    hard_negatives = item.get(\"hard_negative\", [])\n",
        "\n",
        "    if not bm25_evidence or not hard_negatives:\n",
        "        continue\n",
        "\n",
        "    for pos_id in bm25_evidence:\n",
        "        if pos_id not in evidence_corpus:\n",
        "            continue\n",
        "        pos_text = evidence_corpus[pos_id]\n",
        "\n",
        "        sampled_negs = random.sample(hard_negatives, min(3, len(hard_negatives)))\n",
        "        for neg_id in sampled_negs:\n",
        "            if neg_id not in evidence_corpus:\n",
        "                continue\n",
        "            neg_text = evidence_corpus[neg_id]\n",
        "            triplet_examples.append(InputExample(texts=[claim_text, pos_text, neg_text]))\n",
        "\n",
        "print(f\"Prepared {len(triplet_examples)} triplet examples.\")\n",
        "\n",
        "# Train with TripletLoss\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)\n",
        "\n",
        "train_dataloader = DataLoader(triplet_examples, shuffle=True, batch_size=8)\n",
        "train_loss = losses.TripletLoss(\n",
        "    model=model,\n",
        "    distance_metric=losses.TripletDistanceMetric.COSINE,\n",
        "    triplet_margin=0.3\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_objectives=[(train_dataloader, train_loss)],\n",
        "    epochs=4,\n",
        "    optimizer_params={'lr': 2e-5},\n",
        "    warmup_steps=300,\n",
        "    show_progress_bar=True,\n",
        "    output_path=model_save_path\n",
        ")\n",
        "\n",
        "print(f\"Model saved to: {model_save_path}\")\n",
        "\n",
        "# Build and Save FAISS Index for Dense Retrieval\n",
        "model = SentenceTransformer(model_save_path)\n",
        "embedding_dim = model.get_sentence_embedding_dimension()\n",
        "index = faiss.IndexFlatIP(embedding_dim)\n",
        "evid_ids = list(evidence_corpus.keys())\n",
        "evid_texts = list(evidence_corpus.values())\n",
        "\n",
        "print(\"Encoding evidence for FAISS index...\")\n",
        "evid_embeddings = model.encode(\n",
        "    evid_texts,\n",
        "    batch_size=64,\n",
        "    show_progress_bar=True,\n",
        "    normalize_embeddings=True\n",
        ")\n",
        "index.add(np.array(evid_embeddings).astype('float32'))\n",
        "faiss.write_index(index, faiss_index_path)\n",
        "\n",
        "print(f\"FAISS index built with {index.ntotal} documents and saved to: {faiss_index_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na3p1IrkiaL4",
        "outputId": "98fef24e-3a15-47c5-8ec0-6556c72e4753"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating @Top-5 on train set: 100%|██████████| 1228/1228 [03:19<00:00,  6.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Set Evaluation @Top-5:\n",
            "Claim-level Recall: 24.48% (1009/4122 gold evidences matched)\n",
            "Instance-level Accuracy (all gold matched): 8.47% (104/1228 claims)\n",
            "High-level Recall-hit rate (≥1 gold matched): 680/1228 (55.37%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating @Top-50 on train set: 100%|██████████| 1228/1228 [03:18<00:00,  6.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Set Evaluation @Top-50:\n",
            "Claim-level Recall: 59.70% (2461/4122 gold evidences matched)\n",
            "Instance-level Accuracy (all gold matched): 35.50% (436/1228 claims)\n",
            "High-level Recall-hit rate (≥1 gold matched): 1053/1228 (85.75%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating @Top-100 on train set: 100%|██████████| 1228/1228 [03:18<00:00,  6.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Set Evaluation @Top-100:\n",
            "Claim-level Recall: 69.84% (2879/4122 gold evidences matched)\n",
            "Instance-level Accuracy (all gold matched): 46.25% (568/1228 claims)\n",
            "High-level Recall-hit rate (≥1 gold matched): 1114/1228 (90.72%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating @Top-500 on train set: 100%|██████████| 1228/1228 [03:17<00:00,  6.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Set Evaluation @Top-500:\n",
            "Claim-level Recall: 86.73% (3575/4122 gold evidences matched)\n",
            "Instance-level Accuracy (all gold matched): 72.07% (885/1228 claims)\n",
            "High-level Recall-hit rate (≥1 gold matched): 1190/1228 (96.91%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating @Top-1000 on train set: 100%|██████████| 1228/1228 [03:19<00:00,  6.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Set Evaluation @Top-1000:\n",
            "Claim-level Recall: 91.36% (3766/4122 gold evidences matched)\n",
            "Instance-level Accuracy (all gold matched): 81.84% (1005/1228 claims)\n",
            "High-level Recall-hit rate (≥1 gold matched): 1203/1228 (97.96%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Config\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "train_claim_file = os.path.join(data_dir, \"train-claims-preprocessed2.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "model_path = os.path.join(data_dir, \"fine_tuned_dpr_triplet_model\")\n",
        "faiss_index_file = os.path.join(data_dir, \"evidence_faiss_.index\")\n",
        "\n",
        "# Load model, FAISS index, and data\n",
        "model = SentenceTransformer(model_path)\n",
        "index = faiss.read_index(faiss_index_file)\n",
        "\n",
        "with open(train_claim_file, 'r') as f:\n",
        "    train_claims = json.load(f)\n",
        "with open(evidence_file, 'r') as f:\n",
        "    evidence_corpus = json.load(f)\n",
        "\n",
        "evid_ids = list(evidence_corpus.keys())\n",
        "\n",
        "# Dense retrieval function\n",
        "def dense_retrieve(claim_text: str, top_k: int = 40):\n",
        "    query_vec = model.encode([claim_text], normalize_embeddings=True).astype('float32')\n",
        "    _, I = index.search(query_vec, top_k)\n",
        "    return [evid_ids[i] for i in I[0]]\n",
        "\n",
        "# Recall@K and Accuracy@K on Train Set\n",
        "def evaluate_on_train_set(claims_data, k=40):\n",
        "    total_claims = 0\n",
        "    recall_hits = 0\n",
        "    exact_hits = 0\n",
        "    total_gold_evids = 0\n",
        "    matched_gold_evids = 0\n",
        "\n",
        "    for cid, entry in tqdm(claims_data.items(), desc=f\"Evaluating @Top-{k} on train set\"):\n",
        "        claim_text = entry[\"claim_text\"]\n",
        "        gold_ids = set(entry.get(\"evidences\", []))\n",
        "        if not gold_ids:\n",
        "            continue\n",
        "\n",
        "        retrieved_ids = set(dense_retrieve(claim_text, top_k=k))\n",
        "        matched = retrieved_ids & gold_ids\n",
        "\n",
        "        total_claims += 1\n",
        "        total_gold_evids += len(gold_ids)\n",
        "        matched_gold_evids += len(matched)\n",
        "\n",
        "        if matched:\n",
        "            recall_hits += 1\n",
        "        if matched == gold_ids:\n",
        "            exact_hits += 1\n",
        "\n",
        "    # Compute metrics\n",
        "    item_level_recall = matched_gold_evids / total_gold_evids if total_gold_evids > 0 else 0\n",
        "    exact_accuracy = exact_hits / total_claims if total_claims > 0 else 0\n",
        "    recall_hit_rate = recall_hits / total_claims if total_claims > 0 else 0\n",
        "\n",
        "    # Report\n",
        "    print(f\"\\nTrain Set Evaluation @Top-{k}:\")\n",
        "    print(f\"Claim-level Recall: {item_level_recall:.2%} ({matched_gold_evids}/{total_gold_evids} gold evidences matched)\")\n",
        "    print(f\"Instance-level Accuracy (all gold matched): {exact_accuracy:.2%} ({exact_hits}/{total_claims} claims)\")\n",
        "    print(f\"High-level Recall-hit rate (≥1 gold matched): {recall_hits}/{total_claims} ({recall_hit_rate:.2%})\")\n",
        "\n",
        "\n",
        "# Run evaluation\n",
        "for k in [5, 50, 100, 500, 1000]:\n",
        "    evaluate_on_train_set(train_claims, k)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O8kZVUWm5Yq",
        "outputId": "1e6f5749-6c8f-4e56-8e48-facac00942d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating & Saving @Top-100: 100%|██████████| 1228/1228 [03:20<00:00,  6.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Set Evaluation @Top-100:\n",
            "Claim-level Recall: 69.84% (2879/4122)\n",
            "Instance-level Accuracy (all gold matched): 46.25% (568/1228)\n",
            "Recall-hit rate (≥1 gold matched): 1114/1228 (90.72%)\n",
            "Output written to: /content/drive/MyDrive/NLP_content/train-claims-pre-ranked-minilm.json\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "train_claim_file = os.path.join(data_dir, \"train-claims-preprocessed2.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "model_path = os.path.join(data_dir, \"fine_tuned_dpr_triplet_model\")\n",
        "faiss_index_file = os.path.join(data_dir, \"evidence_faiss_minilm.index\")\n",
        "output_file = os.path.join(data_dir, \"train-claims-pre-ranked-minilm.json\")\n",
        "\n",
        "# Load model, FAISS index, and data\n",
        "model = SentenceTransformer(model_path)\n",
        "index = faiss.read_index(faiss_index_file)\n",
        "\n",
        "with open(train_claim_file, 'r') as f:\n",
        "    train_claims = json.load(f)\n",
        "with open(evidence_file, 'r') as f:\n",
        "    evidence_corpus = json.load(f)\n",
        "\n",
        "evid_ids = list(evidence_corpus.keys())\n",
        "\n",
        "# Dense retrieval function\n",
        "def dense_retrieve(claim_text: str, top_k: int = 100):\n",
        "    query_vec = model.encode([claim_text], normalize_embeddings=True).astype('float32')\n",
        "    D, I = index.search(query_vec, top_k)\n",
        "    return [(evid_ids[i], float(D[0][idx])) for idx, i in enumerate(I[0])]\n",
        "\n",
        "# Evaluation and export\n",
        "def evaluate_and_export(claims_data, k=100):\n",
        "    total_claims = 0\n",
        "    recall_hits = 0\n",
        "    exact_hits = 0\n",
        "    total_gold_evids = 0\n",
        "    matched_gold_evids = 0\n",
        "    output_with_retrieval = {}\n",
        "\n",
        "    for cid, entry in tqdm(claims_data.items(), desc=f\"Evaluating & Saving @Top-{k}\"):\n",
        "        claim_text = entry[\"claim_text\"]\n",
        "        gold_ids = set(entry.get(\"evidences\", []))\n",
        "        if not gold_ids:\n",
        "            continue\n",
        "\n",
        "        retrieved = dense_retrieve(claim_text, top_k=k)\n",
        "        retrieved_ids = [eid for eid, _ in retrieved]\n",
        "        retrieved_set = set(retrieved_ids)\n",
        "        matched = retrieved_set & gold_ids\n",
        "\n",
        "        total_claims += 1\n",
        "        total_gold_evids += len(gold_ids)\n",
        "        matched_gold_evids += len(matched)\n",
        "\n",
        "        if matched:\n",
        "            recall_hits += 1\n",
        "        if matched == gold_ids:\n",
        "            exact_hits += 1\n",
        "\n",
        "        output_with_retrieval[cid] = {\n",
        "            \"claim_text\": claim_text,\n",
        "            \"claim_label\": entry.get(\"claim_label\", \"\"),\n",
        "            \"evidences\": list(gold_ids),\n",
        "            \"re_ranked_evidence\": retrieved_ids,\n",
        "            \"re_ranked_scores\": [round(score, 5) for _, score in retrieved]\n",
        "        }\n",
        "\n",
        "    # Metrics\n",
        "    item_level_recall = matched_gold_evids / total_gold_evids if total_gold_evids > 0 else 0\n",
        "    exact_accuracy = exact_hits / total_claims if total_claims > 0 else 0\n",
        "    recall_hit_rate = recall_hits / total_claims if total_claims > 0 else 0\n",
        "\n",
        "    print(f\"\\nTrain Set Evaluation @Top-{k}:\")\n",
        "    print(f\"Claim-level Recall: {item_level_recall:.2%} ({matched_gold_evids}/{total_gold_evids})\")\n",
        "    print(f\"Instance-level Accuracy (all gold matched): {exact_accuracy:.2%} ({exact_hits}/{total_claims})\")\n",
        "    print(f\"Recall-hit rate (≥1 gold matched): {recall_hits}/{total_claims} ({recall_hit_rate:.2%})\")\n",
        "\n",
        "    # Export to file\n",
        "    with open(output_file, 'w') as f_out:\n",
        "        json.dump(output_with_retrieval, f_out, indent=2)\n",
        "    print(f\"Output written to: {output_file}\")\n",
        "\n",
        "evaluate_and_export(train_claims, k=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZHjTcC38ZO7"
      },
      "source": [
        "##### 2.1.2.3 RoBERTa-base DPR Bi-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "766c6b6313c949a198e844f11cf567e3",
            "cd104672e522448c8c93c02ffe6a1f1c",
            "0c5abba786834efcbb0fc3e6af4a57d3",
            "b0954ecfa15343e99bab6f97c99cf509",
            "2bf0772b45a445cd95a374d1eb3723b0",
            "ca9e22bb375d423db7b183edf7a214da",
            "339dcaf4a3bb4695813fb87f4feafc11",
            "4b9f4b3aa555463bbe05695bcd01f79b",
            "5739169dc8fa45138f57f991b6b9ceeb",
            "ce256dc69af74e77b99b8ea46811712d",
            "f5de222d72cf4d208960841315b77f51"
          ]
        },
        "id": "_9fc1KrxrGSt",
        "outputId": "3eafc1fd-eb1e-4244-c5b3-f20c1548b9ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Constructing triplets: 100%|██████████| 1228/1228 [00:00<00:00, 14729.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prepared 27808 RoBERTa triplet examples.\n",
            "Training for 24 dynamically calculated epochs\n",
            "\n",
            "Epoch 1/24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 3476/3476 [05:57<00:00,  9.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average epoch loss: 0.0379\n",
            "Model improved and saved to /content/drive/MyDrive/NLP_content/roberta_dpr_biencoder\n",
            "\n",
            "Epoch 2/24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 3476/3476 [05:56<00:00,  9.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average epoch loss: 0.0125\n",
            "Model improved and saved to /content/drive/MyDrive/NLP_content/roberta_dpr_biencoder\n",
            "\n",
            "Epoch 3/24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 3476/3476 [05:57<00:00,  9.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average epoch loss: 0.0064\n",
            "Model improved and saved to /content/drive/MyDrive/NLP_content/roberta_dpr_biencoder\n",
            "\n",
            "Epoch 4/24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 3476/3476 [05:56<00:00,  9.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average epoch loss: 0.0038\n",
            "Model improved and saved to /content/drive/MyDrive/NLP_content/roberta_dpr_biencoder\n",
            "\n",
            "Epoch 5/24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 3476/3476 [05:55<00:00,  9.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average epoch loss: 0.0023\n",
            "Model improved and saved to /content/drive/MyDrive/NLP_content/roberta_dpr_biencoder\n",
            "\n",
            "Epoch 6/24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 3476/3476 [05:56<00:00,  9.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average epoch loss: 0.0018\n",
            "Model improved and saved to /content/drive/MyDrive/NLP_content/roberta_dpr_biencoder\n",
            "\n",
            "Epoch 7/24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 3476/3476 [05:55<00:00,  9.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average epoch loss: 0.0014\n",
            "Model improved and saved to /content/drive/MyDrive/NLP_content/roberta_dpr_biencoder\n",
            "\n",
            "Epoch 8/24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 3476/3476 [05:54<00:00,  9.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average epoch loss: 0.0010\n",
            "Model improved and saved to /content/drive/MyDrive/NLP_content/roberta_dpr_biencoder\n",
            "\n",
            "Epoch 9/24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 3476/3476 [05:53<00:00,  9.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average epoch loss: 0.0010\n",
            "Model improved and saved to /content/drive/MyDrive/NLP_content/roberta_dpr_biencoder\n",
            "\n",
            "Epoch 10/24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 3476/3476 [05:54<00:00,  9.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average epoch loss: 0.0008\n",
            "Model improved and saved to /content/drive/MyDrive/NLP_content/roberta_dpr_biencoder\n",
            "Encoding evidence for FAISS index...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "766c6b6313c949a198e844f11cf567e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/18888 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index saved to /content/drive/MyDrive/NLP_content/roberta_faiss.index with 1208827 documents.\n"
          ]
        }
      ],
      "source": [
        "# RoBERTa-base DPR Bi-Encoder Training with TripletLoss and Dynamic Epochs, Early Stopping\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
        "from sentence_transformers.util import batch_to_device\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Config and File Paths\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "triplet_source_file = os.path.join(data_dir, \"train-claims-with-negatives-bm25.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "model_save_path = os.path.join(data_dir, \"roberta_dpr_biencoder\")\n",
        "faiss_index_path = os.path.join(data_dir, \"roberta_faiss.index\")\n",
        "\n",
        "# Load claim/evidence data\n",
        "with open(triplet_source_file, 'r') as f:\n",
        "    claim_data = json.load(f)\n",
        "with open(evidence_file, 'r') as f:\n",
        "    evidence_corpus = json.load(f)\n",
        "\n",
        "# Build Triplet Examples\n",
        "triplet_examples = []\n",
        "for cid, item in tqdm(claim_data.items(), desc=\"Constructing triplets\"):\n",
        "    claim_text = item[\"claim_text\"]\n",
        "    bm25_evidence = item.get(\"BM25_evidence\", [])\n",
        "    hard_negatives = item.get(\"hard_negative\", [])\n",
        "\n",
        "    if not bm25_evidence or not hard_negatives:\n",
        "        continue\n",
        "\n",
        "    for pos_item in bm25_evidence:\n",
        "        pos_id = pos_item.get(\"id\") if isinstance(pos_item, dict) else pos_item\n",
        "        if not pos_id or pos_id not in evidence_corpus:\n",
        "            continue\n",
        "        pos_text = evidence_corpus[pos_id]\n",
        "\n",
        "        sampled_negs = random.sample(hard_negatives, min(8, len(hard_negatives)))\n",
        "        for neg_item in sampled_negs:\n",
        "            neg_id = neg_item.get(\"id\") if isinstance(neg_item, dict) else neg_item\n",
        "            if not neg_id or neg_id not in evidence_corpus:\n",
        "                continue\n",
        "            neg_text = evidence_corpus[neg_id]\n",
        "\n",
        "            triplet_examples.append(InputExample(texts=[claim_text, pos_text, neg_text]))\n",
        "\n",
        "print(f\"Prepared {len(triplet_examples)} RoBERTa triplet examples.\")\n",
        "\n",
        "# Initialize RoBERTa bi-encoder\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = SentenceTransformer('sentence-transformers/roberta-base-nli-mean-tokens', device=device)\n",
        "\n",
        "# Custom Training Loop with Gradient Accumulation and Early Stopping\n",
        "batch_size = 8\n",
        "accumulation_steps = 8\n",
        "train_dataloader = DataLoader(\n",
        "    triplet_examples,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=model.smart_batching_collate  # keep this\n",
        ")\n",
        "\n",
        "# Dynamic epoch calculation\n",
        "desired_updates = 10000\n",
        "steps_per_epoch = len(train_dataloader) // accumulation_steps\n",
        "epochs = math.ceil(desired_updates / steps_per_epoch)\n",
        "print(f\"Training for {epochs} dynamically calculated epochs\")\n",
        "\n",
        "loss_fn = losses.TripletLoss(model=model, distance_metric=losses.TripletDistanceMetric.COSINE, triplet_margin=0.3)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Early stopping config\n",
        "patience = 3\n",
        "best_loss = float('inf')\n",
        "early_stop_counter = 0\n",
        "max_epochs = 10\n",
        "\n",
        "model.train()\n",
        "for epoch in range(min(epochs, max_epochs)):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    optimizer.zero_grad()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training\")):\n",
        "        features, labels = batch\n",
        "        features = [batch_to_device(f, model.device) for f in features]\n",
        "\n",
        "        loss = loss_fn(features, labels)\n",
        "        epoch_loss += loss.item()\n",
        "        loss = loss / accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        if (step + 1) % accumulation_steps == 0 or (step + 1) == len(train_dataloader):\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_dataloader)\n",
        "    print(f\"Average epoch loss: {avg_loss:.4f}\")\n",
        "\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        early_stop_counter = 0\n",
        "        model.save(model_save_path)\n",
        "        print(f\"Model improved and saved to {model_save_path}\")\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "        print(f\"No improvement. Early stop counter: {early_stop_counter}/{patience}\")\n",
        "        if early_stop_counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "\n",
        "# Build FAISS index\n",
        "model = SentenceTransformer(model_save_path)\n",
        "embedding_dim = model.get_sentence_embedding_dimension()\n",
        "index = faiss.IndexFlatIP(embedding_dim)\n",
        "evid_ids = list(evidence_corpus.keys())\n",
        "evid_texts = list(evidence_corpus.values())\n",
        "\n",
        "print(\"Encoding evidence for FAISS index...\")\n",
        "evid_embeddings = model.encode(\n",
        "    evid_texts,\n",
        "    batch_size=64,\n",
        "    show_progress_bar=True,\n",
        "    normalize_embeddings=True\n",
        ")\n",
        "index.add(np.array(evid_embeddings).astype('float32'))\n",
        "faiss.write_index(index, faiss_index_path)\n",
        "print(f\"FAISS index saved to {faiss_index_path} with {index.ntotal} documents.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGYhFsAc0g-w",
        "outputId": "c93074f5-4485-41f9-ef27-bfbfb91e5a98"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating @Top-5 on train set: 100%|██████████| 1228/1228 [04:33<00:00,  4.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[RoBERTa DPR] Train Set Evaluation @Top-5:\n",
            "Claim-level Recall: 34.28% (1413/4122 gold evidences matched)\n",
            "Instance-level Accuracy (all gold matched): 12.79% (157/1228 claims)\n",
            "Recall-hit rate (≥1 gold matched): 872/1228 (71.01%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating @Top-50 on train set: 100%|██████████| 1228/1228 [04:31<00:00,  4.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[RoBERTa DPR] Train Set Evaluation @Top-50:\n",
            "Claim-level Recall: 66.98% (2761/4122 gold evidences matched)\n",
            "Instance-level Accuracy (all gold matched): 41.21% (506/1228 claims)\n",
            "Recall-hit rate (≥1 gold matched): 1124/1228 (91.53%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating @Top-100 on train set: 100%|██████████| 1228/1228 [04:34<00:00,  4.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[RoBERTa DPR] Train Set Evaluation @Top-100:\n",
            "Claim-level Recall: 75.42% (3109/4122 gold evidences matched)\n",
            "Instance-level Accuracy (all gold matched): 52.69% (647/1228 claims)\n",
            "Recall-hit rate (≥1 gold matched): 1154/1228 (93.97%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating @Top-500 on train set: 100%|██████████| 1228/1228 [04:35<00:00,  4.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[RoBERTa DPR] Train Set Evaluation @Top-500:\n",
            "Claim-level Recall: 88.91% (3665/4122 gold evidences matched)\n",
            "Instance-level Accuracy (all gold matched): 76.30% (937/1228 claims)\n",
            "Recall-hit rate (≥1 gold matched): 1201/1228 (97.80%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating @Top-1000 on train set: 100%|██████████| 1228/1228 [04:36<00:00,  4.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[RoBERTa DPR] Train Set Evaluation @Top-1000:\n",
            "Claim-level Recall: 91.63% (3777/4122 gold evidences matched)\n",
            "Instance-level Accuracy (all gold matched): 82.33% (1011/1228 claims)\n",
            "Recall-hit rate (≥1 gold matched): 1210/1228 (98.53%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Config for RoBERTa DPR\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "train_claim_file = os.path.join(data_dir, \"train-claims-preprocessed2.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "model_path = os.path.join(data_dir, \"roberta_dpr_biencoder\")\n",
        "faiss_index_file = os.path.join(data_dir, \"roberta_faiss.index\")\n",
        "\n",
        "# Load model, FAISS index, and data\n",
        "model = SentenceTransformer(model_path)\n",
        "index = faiss.read_index(faiss_index_file)\n",
        "\n",
        "with open(train_claim_file, 'r') as f:\n",
        "    train_claims = json.load(f)\n",
        "with open(evidence_file, 'r') as f:\n",
        "    evidence_corpus = json.load(f)\n",
        "\n",
        "evid_ids = list(evidence_corpus.keys())\n",
        "\n",
        "# Dense retrieval function\n",
        "def dense_retrieve(claim_text: str, top_k: int = 40):\n",
        "    query_vec = model.encode([claim_text], normalize_embeddings=True).astype('float32')\n",
        "    _, I = index.search(query_vec, top_k)\n",
        "    return [evid_ids[i] for i in I[0]]\n",
        "\n",
        "# Evaluation on Train Set\n",
        "def evaluate_on_train_set(claims_data, k=40):\n",
        "    total_claims = 0\n",
        "    recall_hits = 0\n",
        "    exact_hits = 0\n",
        "    total_gold_evids = 0\n",
        "    matched_gold_evids = 0\n",
        "\n",
        "    for cid, entry in tqdm(claims_data.items(), desc=f\"Evaluating @Top-{k} on train set\"):\n",
        "        claim_text = entry[\"claim_text\"]\n",
        "        gold_ids = set(entry.get(\"evidences\", []))\n",
        "        if not gold_ids:\n",
        "            continue\n",
        "\n",
        "        retrieved_ids = set(dense_retrieve(claim_text, top_k=k))\n",
        "        matched = retrieved_ids & gold_ids\n",
        "\n",
        "        total_claims += 1\n",
        "        total_gold_evids += len(gold_ids)\n",
        "        matched_gold_evids += len(matched)\n",
        "\n",
        "        if matched:\n",
        "            recall_hits += 1\n",
        "        if matched == gold_ids:\n",
        "            exact_hits += 1\n",
        "\n",
        "    # Metrics\n",
        "    item_level_recall = matched_gold_evids / total_gold_evids if total_gold_evids > 0 else 0\n",
        "    exact_accuracy = exact_hits / total_claims if total_claims > 0 else 0\n",
        "    recall_hit_rate = recall_hits / total_claims if total_claims > 0 else 0\n",
        "\n",
        "    # Report\n",
        "    print(f\"\\n[RoBERTa DPR] Train Set Evaluation @Top-{k}:\")\n",
        "    print(f\"Claim-level Recall: {item_level_recall:.2%} ({matched_gold_evids}/{total_gold_evids} gold evidences matched)\")\n",
        "    print(f\"Instance-level Accuracy (all gold matched): {exact_accuracy:.2%} ({exact_hits}/{total_claims} claims)\")\n",
        "    print(f\"Recall-hit rate (≥1 gold matched): {recall_hits}/{total_claims} ({recall_hit_rate:.2%})\")\n",
        "\n",
        "# Run evaluation\n",
        "for k in [5, 50, 100, 500, 1000]:\n",
        "    evaluate_on_train_set(train_claims, k)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UltvbQ6YLg0z",
        "outputId": "b8f6dc63-5a35-400a-dadb-484069728a23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieving Top-100 evidences: 100%|██████████| 1228/1228 [06:35<00:00,  3.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved retrieval output to: /content/drive/MyDrive/NLP_content/train-claims-pre-ranked-roberta.json\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the chosen k = 100\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "train_claim_file = os.path.join(data_dir, \"train-claims-preprocessed2.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "model_path = os.path.join(data_dir, \"roberta_dpr_biencoder\")\n",
        "faiss_index_file = os.path.join(data_dir, \"roberta_faiss.index\")\n",
        "output_path = os.path.join(data_dir, \"train-claims-pre-ranked-roberta.json\")\n",
        "\n",
        "model = SentenceTransformer(model_path)\n",
        "index = faiss.read_index(faiss_index_file)\n",
        "\n",
        "with open(train_claim_file, 'r') as f:\n",
        "    train_claims = json.load(f)\n",
        "with open(evidence_file, 'r') as f:\n",
        "    evidence_corpus = json.load(f)\n",
        "\n",
        "evid_ids = list(evidence_corpus.keys())\n",
        "\n",
        "# Dense retrieval function\n",
        "def dense_retrieve_with_scores(claim_text: str, top_k: int = 100):\n",
        "    query_vec = model.encode([claim_text], normalize_embeddings=True).astype('float32')\n",
        "    scores, indices = index.search(query_vec, top_k)\n",
        "    result = [(evid_ids[i], float(scores[0][idx])) for idx, i in enumerate(indices[0])]\n",
        "    return result\n",
        "\n",
        "# Main retrieval\n",
        "def attach_top_k_retrieval(claims_data, k=100, output_file=output_path):\n",
        "    output_with_retrieval = {}\n",
        "\n",
        "    for cid, entry in tqdm(claims_data.items(), desc=f\"Retrieving Top-{k} evidences\"):\n",
        "        claim_text = entry[\"claim_text\"]\n",
        "        gold_ids = set(entry.get(\"evidences\", []))\n",
        "        retrieved = dense_retrieve_with_scores(claim_text, top_k=k)\n",
        "\n",
        "        retrieved_ids_ordered = [docid for docid, _ in retrieved]\n",
        "        retrieved_scores = [round(score, 5) for _, score in retrieved]\n",
        "\n",
        "        output_with_retrieval[cid] = {\n",
        "            \"claim_text\": claim_text,\n",
        "            \"claim_label\": entry.get(\"claim_label\", \"\"),\n",
        "            \"evidences\": list(gold_ids),\n",
        "            \"re_ranked_evidence\": retrieved_ids_ordered,\n",
        "            \"re_ranked_scores\": retrieved_scores\n",
        "        }\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(output_with_retrieval, f, indent=2)\n",
        "    print(f\"\\nSaved retrieval output to: {output_file}\")\n",
        "\n",
        "attach_top_k_retrieval(train_claims, k=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVlPPKbv0Q0a",
        "outputId": "60d7dd25-0296-4342-ebb1-5218909bd6c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique evidence IDs in pre_ranked_pool: 25641\n",
            "Total unique gold evidence IDs: 3121\n",
            "Matched gold evidence IDs in pre_ranked_pool: 2468\n",
            "Coverage of gold evidences: 0.7908\n",
            "Exported 25641 unique evidence IDs to: /content/drive/MyDrive/NLP_content/unique_retrieved_evidence_ids_bm25.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Config\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "file_path = os.path.join(data_dir, \"train-claims-pre-ranked-roberta.json\")\n",
        "\n",
        "# Load JSON\n",
        "with open(file_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "unique_retrieved_ids = set()\n",
        "gold_evidence_ids = set()\n",
        "matched_gold_ids = set()\n",
        "\n",
        "for entry in data.values():\n",
        "    pool = entry.get(\"re_ranked_evidence\", [])\n",
        "    gold = entry.get(\"evidences\", [])\n",
        "\n",
        "    unique_retrieved_ids.update(pool)\n",
        "    gold_evidence_ids.update(gold)\n",
        "\n",
        "    for eid in gold:\n",
        "        if eid in pool:\n",
        "            matched_gold_ids.add(eid)\n",
        "\n",
        "# Output\n",
        "print(f\"Total unique evidence IDs in pre_ranked_pool: {len(unique_retrieved_ids)}\")\n",
        "print(f\"Total unique gold evidence IDs: {len(gold_evidence_ids)}\")\n",
        "print(f\"Matched gold evidence IDs in pre_ranked_pool: {len(matched_gold_ids)}\")\n",
        "print(f\"Coverage of gold evidences: {len(matched_gold_ids) / len(gold_evidence_ids):.4f}\")\n",
        "\n",
        "export_path = os.path.join(data_dir, \"unique_retrieved_evidence_ids_bm25.json\")\n",
        "with open(export_path, \"w\") as f:\n",
        "    json.dump(sorted(list(unique_retrieved_ids)), f, indent=2)\n",
        "\n",
        "print(f\"Exported {len(unique_retrieved_ids)} unique evidence IDs to: {export_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgHrh1mY1XDe",
        "outputId": "4be9d2b5-3094-493b-9c1f-1049089a5e14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique evidence IDs in pre_ranked_pool: 28461\n",
            "Total unique gold evidence IDs: 3121\n",
            "Matched gold evidence IDs in pre_ranked_pool: 2203\n",
            "Coverage of gold evidences: 0.7059\n",
            "Exported 28461 unique evidence IDs to: /content/drive/MyDrive/NLP_content/unique_retrieved_evidence_ids_minilm.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Config\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "file_path = os.path.join(data_dir, \"train-claims-pre-ranked-minilm.json\")\n",
        "\n",
        "# Load JSON\n",
        "with open(file_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "unique_retrieved_ids = set()\n",
        "gold_evidence_ids = set()\n",
        "matched_gold_ids = set()\n",
        "\n",
        "for entry in data.values():\n",
        "    pool = entry.get(\"re_ranked_evidence\", [])\n",
        "    gold = entry.get(\"evidences\", [])\n",
        "\n",
        "    unique_retrieved_ids.update(pool)\n",
        "    gold_evidence_ids.update(gold)\n",
        "\n",
        "    for eid in gold:\n",
        "        if eid in pool:\n",
        "            matched_gold_ids.add(eid)\n",
        "\n",
        "# Output\n",
        "print(f\"Total unique evidence IDs in pre_ranked_pool: {len(unique_retrieved_ids)}\")\n",
        "print(f\"Total unique gold evidence IDs: {len(gold_evidence_ids)}\")\n",
        "print(f\"Matched gold evidence IDs in pre_ranked_pool: {len(matched_gold_ids)}\")\n",
        "print(f\"Coverage of gold evidences: {len(matched_gold_ids) / len(gold_evidence_ids):.4f}\")\n",
        "export_path = os.path.join(data_dir, \"unique_retrieved_evidence_ids_minilm.json\")\n",
        "with open(export_path, \"w\") as f:\n",
        "    json.dump(sorted(list(unique_retrieved_ids)), f, indent=2)\n",
        "\n",
        "print(f\"Exported {len(unique_retrieved_ids)} unique evidence IDs to: {export_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyUCVk0jrGlq"
      },
      "source": [
        "#### 2.1.3 Hybrid Union - Pre-rank\n",
        "The choice of is based on the evaluation on the same dev set in 2.1.2 and 2.1.3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9L3nmAHB3n_",
        "outputId": "383813ff-e2bc-4068-d490-9d81f505148a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BM25 pool size: 100.00\n",
            "Average dense pool size: 100.00\n",
            "Average combined pool size: 200.00\n",
            "Average BM25 unique items: 100.00\n",
            "Average dense unique items: 100.00\n",
            "Average duplicates per claim: 16.24\n",
            "Average evidence pool length: 183.76\n",
            "Merged pre-rank pool saved: /content/drive/MyDrive/NLP_content/merged_pre_rank_pool.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Config\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "bm25_file_path = os.path.join(data_dir, \"train-claims-with-negatives-bm25.json\")\n",
        "biencoder_file_path = os.path.join(data_dir, \"train-claims-pre-ranked-minilm.json\")\n",
        "output_path = os.path.join(data_dir, \"merged_pre_rank_pool.json\")\n",
        "\n",
        "# Load files\n",
        "with open(bm25_file_path, 'r') as f:\n",
        "    bm25_data = json.load(f)\n",
        "with open(biencoder_file_path, 'r') as f:\n",
        "    biencoder_data = json.load(f)\n",
        "\n",
        "final_merged_data = {}\n",
        "total_duplicates = 0\n",
        "total_pool_length = 0\n",
        "total_bm25_size = 0\n",
        "total_dense_size = 0\n",
        "total_combined_size = 0\n",
        "total_bm25_unique = 0\n",
        "total_dense_unique = 0\n",
        "num_claims = 0\n",
        "\n",
        "for cid in bm25_data:\n",
        "    claim_text = bm25_data[cid][\"claim_text\"]\n",
        "    claim_label = bm25_data[cid].get(\"claim_label\", \"\")\n",
        "    gold_evidences = bm25_data[cid].get(\"evidences\", [])\n",
        "\n",
        "    # BM25: gold + hard negatives (up to 100)\n",
        "    bm25_gold = [item[\"id\"] for item in bm25_data[cid].get(\"BM25_evidence\", []) if isinstance(item, dict) and \"id\" in item]\n",
        "    num_bm25_gold = len(bm25_gold)\n",
        "    hard_negatives = [item[\"id\"] for item in bm25_data[cid].get(\"hard_negative\", []) if isinstance(item, dict) and \"id\" in item]\n",
        "    needed_negatives = max(0, 100 - num_bm25_gold)\n",
        "    bm25_pool = bm25_gold + hard_negatives[:needed_negatives]\n",
        "\n",
        "    # Dense retrieval pool\n",
        "    dense_raw = biencoder_data.get(cid, {}).get(\"re_ranked_evidence\", [])[:100]\n",
        "    dense_pool = []\n",
        "    for ev in dense_raw:\n",
        "        if isinstance(ev, str):\n",
        "            dense_pool.append(ev)\n",
        "        elif isinstance(ev, dict) and \"id\" in ev:\n",
        "            dense_pool.append(ev[\"id\"])\n",
        "\n",
        "    # Combine and deduplicate, tracking contributions\n",
        "    combined_pool = bm25_pool + dense_pool\n",
        "    seen = set()\n",
        "    pre_ranked_pool = []\n",
        "    bm25_unique = 0\n",
        "    dense_unique = 0\n",
        "\n",
        "    for ev in combined_pool:\n",
        "        if isinstance(ev, str) and ev not in seen:\n",
        "            seen.add(ev)\n",
        "            pre_ranked_pool.append(ev)\n",
        "            if ev in bm25_pool:\n",
        "                bm25_unique += 1\n",
        "            if ev in dense_pool:\n",
        "                dense_unique += 1\n",
        "        elif isinstance(ev, str):\n",
        "            total_duplicates += 1\n",
        "\n",
        "    final_merged_data[cid] = {\n",
        "        \"claim_text\": claim_text,\n",
        "        \"claim_label\": claim_label,\n",
        "        \"evidences\": gold_evidences,\n",
        "        \"pre_ranked_pool\": pre_ranked_pool\n",
        "    }\n",
        "\n",
        "    # Track sizes and contributions\n",
        "    total_bm25_size += len(bm25_pool)\n",
        "    total_dense_size += len(dense_pool)\n",
        "    total_combined_size += len(combined_pool)\n",
        "    total_pool_length += len(pre_ranked_pool)\n",
        "    total_bm25_unique += bm25_unique\n",
        "    total_dense_unique += dense_unique\n",
        "    num_claims += 1\n",
        "\n",
        "# Save merged result\n",
        "with open(output_path, 'w') as f:\n",
        "    json.dump(final_merged_data, f, indent=2)\n",
        "\n",
        "# Compute and print statistics\n",
        "avg_duplicates = total_duplicates / num_claims if num_claims > 0 else 0\n",
        "avg_pool_length = total_pool_length / num_claims if num_claims > 0 else 0\n",
        "avg_bm25_size = total_bm25_size / num_claims if num_claims > 0 else 0\n",
        "avg_dense_size = total_dense_size / num_claims if num_claims > 0 else 0\n",
        "avg_combined_size = total_combined_size / num_claims if num_claims > 0 else 0\n",
        "avg_bm25_unique = total_bm25_unique / num_claims if num_claims > 0 else 0\n",
        "avg_dense_unique = total_dense_unique / num_claims if num_claims > 0 else 0\n",
        "\n",
        "print(f\"Average BM25 pool size: {avg_bm25_size:.2f}\")\n",
        "print(f\"Average dense pool size: {avg_dense_size:.2f}\")\n",
        "print(f\"Average combined pool size: {avg_combined_size:.2f}\")\n",
        "print(f\"Average BM25 unique items: {avg_bm25_unique:.2f}\")\n",
        "print(f\"Average dense unique items: {avg_dense_unique:.2f}\")\n",
        "print(f\"Average duplicates per claim: {avg_duplicates:.2f}\")\n",
        "print(f\"Average evidence pool length: {avg_pool_length:.2f}\")\n",
        "print(f\"Merged pre-rank pool saved: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieV2PpH7sOqO"
      },
      "outputs": [],
      "source": [
        "# Evaluation of gold evidence coverage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kzADT5gx-1k",
        "outputId": "55ea4924-56db-4a58-b6c2-9257ba43a21c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating merged_pre_rank_pool.json: 100%|██████████| 1228/1228 [00:00<00:00, 70254.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation: merged_pre_rank_pool.json ---\n",
            "Recall@100: 0.8948\n",
            "Precision@100: 0.0164\n",
            "F1@100: 0.0321\n",
            "Accuracy@100 (all gold in top-k): 0.7516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_pre_ranked_retrieval(\n",
        "    data_dir=\"/content/drive/MyDrive/NLP_content\",\n",
        "    gold_claim_filename=\"train-claims-preprocessed2.json\",\n",
        "    pre_rank_filename=\"merged_pre_rank_pool.json\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fnkm5cIE7W_"
      },
      "source": [
        "### 2.2 Evidence Retrieval - Re-ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phJkvBGDh_Ei"
      },
      "source": [
        "#### 2.2.1 Preprocessing for Two-Phase Cross-Encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAW1KCwMFMD7",
        "outputId": "fbd30bdc-992a-4d09-f3d1-c8f97be23490"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing claims:   0%|          | 1/1228 [00:00<07:29,  2.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample claim claim-1937:\n",
            "  Gold IDs: {'evidence-442946', 'evidence-12171', 'evidence-1194317'}\n",
            "  Sampled BM25 IDs: ['evidence-36224', 'evidence-1008043', 'evidence-373200']\n",
            "  Sampled Dense IDs: ['evidence-881617', 'evidence-631684', 'evidence-761183']\n",
            "  Hard negative text (1st): {'text': 'united states electric power plants emit 2.4 billion tons carbon dioxide carbon dioxide year roughly 40 percent nations total emissions', 'label': 0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing claims: 100%|██████████| 1228/1228 [06:20<00:00,  3.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved Phase 1 (gold + random) to: /content/drive/MyDrive/NLP_content/training_rerank_phase1.json\n",
            "Saved Phase 2 (gold + hard) to: /content/drive/MyDrive/NLP_content/training_rerank_phase2.json\n",
            "Phase 1: 1228 claims, avg 8.36 candidates\n",
            "Phase 2: 1228 claims, avg 13.36 candidates\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuration\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "merged_file = os.path.join(data_dir, \"merged_pre_rank_pool.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "output_phase1 = os.path.join(data_dir, \"training_rerank_phase1.json\")\n",
        "output_phase2 = os.path.join(data_dir, \"training_rerank_phase2.json\")\n",
        "\n",
        "# Tuning\n",
        "NUM_RANDOM_NEGATIVES = 5\n",
        "NUM_HARD_NEGATIVES = 10  # 5 from BM25 + 5 from Dense\n",
        "\n",
        "# Load input files\n",
        "with open(merged_file) as f:\n",
        "    merged_data = json.load(f)\n",
        "\n",
        "with open(evidence_file) as f:\n",
        "    evidence_corpus = json.load(f)\n",
        "\n",
        "phase1_data = []\n",
        "phase2_data = []\n",
        "all_ids = set(evidence_corpus.keys())\n",
        "\n",
        "# Process with progress bar\n",
        "for cid, entry in tqdm(merged_data.items(), desc=\"Processing claims\"):\n",
        "    claim = entry[\"claim_text\"]\n",
        "    gold_ids = set(entry.get(\"evidences\", []))\n",
        "    pre_ranked_list = entry.get(\"pre_ranked_pool\", [])\n",
        "\n",
        "    if not gold_ids:\n",
        "        continue\n",
        "\n",
        "    # Gold evidence\n",
        "    gold_texts = [\n",
        "        {\"text\": evidence_corpus[eid], \"label\": 1}\n",
        "        for eid in gold_ids if eid in evidence_corpus\n",
        "    ]\n",
        "\n",
        "    # Phase 1: random negatives\n",
        "    possible_randoms = list(all_ids - set(pre_ranked_list) - gold_ids)\n",
        "    sampled_random_ids = random.sample(possible_randoms, min(NUM_RANDOM_NEGATIVES, len(possible_randoms)))\n",
        "\n",
        "    random_neg_texts = [\n",
        "        {\"text\": evidence_corpus[eid], \"label\": 0}\n",
        "        for eid in sampled_random_ids if eid in evidence_corpus\n",
        "    ]\n",
        "\n",
        "    phase1_data.append({\n",
        "        \"claim\": claim,\n",
        "        \"candidates\": gold_texts + random_neg_texts\n",
        "    })\n",
        "\n",
        "    # Phase 2: hard negatives split from BM25 and Dense\n",
        "    filtered_hard_ids = [eid for eid in pre_ranked_list if eid not in gold_ids]\n",
        "    hard_candidate_ids = filtered_hard_ids[24:183]  # Rank 25–183\n",
        "\n",
        "    # Split assumed BM25/Dense\n",
        "    split_index = 92  # Fixed half of 184\n",
        "    bm25_range = hard_candidate_ids[:split_index - 24]\n",
        "    dense_range = hard_candidate_ids[split_index - 24:]\n",
        "\n",
        "    bm25_samples = random.sample(bm25_range, min(5, len(bm25_range)))\n",
        "    dense_samples = random.sample(dense_range, min(5, len(dense_range)))\n",
        "    sampled_hard_ids = bm25_samples + dense_samples\n",
        "\n",
        "    hard_neg_texts = [\n",
        "        {\"text\": evidence_corpus[eid], \"label\": 0}\n",
        "        for eid in sampled_hard_ids if eid in evidence_corpus\n",
        "    ]\n",
        "\n",
        "    if len(phase1_data) == 1:\n",
        "        print(f\"\\nSample claim {cid}:\")\n",
        "        print(f\"  Gold IDs: {gold_ids}\")\n",
        "        print(f\"  Sampled BM25 IDs: {bm25_samples[:3]}\")\n",
        "        print(f\"  Sampled Dense IDs: {dense_samples[:3]}\")\n",
        "        print(f\"  Hard negative text (1st): {hard_neg_texts[0] if hard_neg_texts else 'None'}\")\n",
        "\n",
        "    phase2_data.append({\n",
        "        \"claim\": claim,\n",
        "        \"candidates\": gold_texts + hard_neg_texts\n",
        "    })\n",
        "\n",
        "# Save output files\n",
        "with open(output_phase1, 'w') as f:\n",
        "    json.dump(phase1_data, f, indent=2)\n",
        "print(f\"\\nSaved Phase 1 (gold + random) to: {output_phase1}\")\n",
        "\n",
        "with open(output_phase2, 'w') as f:\n",
        "    json.dump(phase2_data, f, indent=2)\n",
        "print(f\"Saved Phase 2 (gold + hard) to: {output_phase2}\")\n",
        "\n",
        "# Stats\n",
        "avg_phase1 = sum(len(d['candidates']) for d in phase1_data) / len(phase1_data) if phase1_data else 0\n",
        "avg_phase2 = sum(len(d['candidates']) for d in phase2_data) / len(phase2_data) if phase2_data else 0\n",
        "print(f\"Phase 1: {len(phase1_data)} claims, avg {avg_phase1:.2f} candidates\")\n",
        "print(f\"Phase 2: {len(phase2_data)} claims, avg {avg_phase2:.2f} candidates\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHkLjAM_3oV4",
        "outputId": "2c6a0ea7-c866-45bc-88ab-83f579846585"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NLP_content/training_rerank_phase1.json is valid JSON\n",
            "/content/drive/MyDrive/NLP_content/training_rerank_phase2.json is valid JSON\n"
          ]
        }
      ],
      "source": [
        "# Validate rerank two-phase training data\n",
        "import json\n",
        "import os\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "phase1_path = os.path.join(data_dir, \"training_rerank_phase1.json\")\n",
        "phase2_path = os.path.join(data_dir, \"training_rerank_phase2.json\")\n",
        "\n",
        "for file_path in [phase1_path, phase2_path]:\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            json.load(f)\n",
        "        print(f\"{file_path} is valid JSON\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"{file_path} is invalid JSON: {e}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"{file_path} not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbabVOtaT20h"
      },
      "outputs": [],
      "source": [
        "#Class Imbalance\n",
        "from collections import Counter\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "phase1_path = os.path.join(data_dir, \"training_rerank_phase1.json\")\n",
        "phase2_path = os.path.join(data_dir, \"training_rerank_phase2.json\")\n",
        "\n",
        "def compute_label_distribution(*datasets):\n",
        "    counter = Counter()\n",
        "    for data in datasets:\n",
        "        for entry in data:\n",
        "            for cand in entry[\"candidates\"]:\n",
        "                counter[cand[\"label\"]] += 1\n",
        "    return counter\n",
        "\n",
        "# Load and compute\n",
        "with open(phase1_path) as f1, open(phase2_path) as f2:\n",
        "    phase1 = json.load(f1)\n",
        "    phase2 = json.load(f2)\n",
        "\n",
        "label_counts = compute_label_distribution(phase1, phase2)\n",
        "total = sum(label_counts.values())\n",
        "class_weights = [total / label_counts[i] for i in sorted(label_counts)]\n",
        "\n",
        "print(\"Class counts:\", label_counts)\n",
        "print(\"Class weights:\", class_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrAdPiDntygv"
      },
      "source": [
        "#### 2.2.2 MiniLM Cross-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eoCJcmXx4Tc9",
        "outputId": "4731eee0-b28c-4ac0-bd13-3c5c427b4abe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "2c993e7dbd264cdfb3e92fd741793f21",
              "pip_warning": {
                "packages": [
                  "datasets"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install --upgrade datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8e45fbf0254844d2abe04aa52c1eaecf",
            "41319ff5d4884a5c8efab047a599e0e8",
            "f51e0825565e47a1987cd3589d6b4764",
            "c4ad28135705421d84e96b54defb5097",
            "4a33f42dbf0b4583b141621465d1bf4c",
            "ef6737d68b734469a390c7aab3bc377e",
            "360fa62902be4120a71efd323857c9c3",
            "f462b1fb993f4d17871e93d9f6d137c7",
            "d8560020a05743b5bfd8168f642be38e",
            "0b0db236a444411591813b192638c51b",
            "c5d29afcf63040fe8416c81b35ebe0b9",
            "905025c6281148f6865af7dadfe49455",
            "80542cd4de9248f1b990846a4ede99fb",
            "bb35a9d075ed4decaa32b51430251e8a",
            "10b39e97988848d58d3685d087f56698",
            "23bb932ad1764d34bd6cba51794a2041",
            "5eaf0216e46e41448ccde61e5d492ebc",
            "c193ea9972114e6193763c1e08b07260",
            "e72f885b2dd84604a8c3ea77b2f8d732",
            "3b9586c8cd204d5c8dfb6cac6a584e55",
            "63216aa2e88849c0928c17c29c663c3d",
            "0698e41899824b2f93cb0ef8b52945e8"
          ]
        },
        "id": "RrA9mWQY32El",
        "outputId": "d7628dbd-b26a-446d-94c4-cbbea6e0f94b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumPy version: 2.0.2\n",
            "Transformers version: 4.51.3\n",
            "Datasets version: 3.6.0\n",
            "Loading Phase 1 data...\n",
            "Loading Phase 2 data...\n",
            "First Phase 1 tuple: ('scientific evidence carbon dioxide pollutant higher carbon dioxide concentrations actually help ecosystems support plant animal life', 'higher carbon dioxide concentrations favourably affect plant growth demand water', 1)\n",
            "First Phase 2 tuple: ('scientific evidence carbon dioxide pollutant higher carbon dioxide concentrations actually help ecosystems support plant animal life', 'higher carbon dioxide concentrations favourably affect plant growth demand water', 1)\n",
            "Converting to Hugging Face datasets...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10261/10261 [00:00<00:00, 1859001.92it/s]\n",
            "100%|██████████| 16402/16402 [00:00<00:00, 1711445.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phase 1 examples: 10261\n",
            "Phase 2 examples: 16402\n",
            "First Phase 1 item: {'claim': 'scientific evidence carbon dioxide pollutant higher carbon dioxide concentrations actually help ecosystems support plant animal life', 'evidence': 'higher carbon dioxide concentrations favourably affect plant growth demand water', 'label': 1.0}\n",
            "Phase 1 keys: ['claim', 'evidence', 'label']\n",
            "Dataset features: {'claim': Value(dtype='string', id=None), 'evidence': Value(dtype='string', id=None), 'label': Value(dtype='float64', id=None)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing datasets...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e45fbf0254844d2abe04aa52c1eaecf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10261 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "905025c6281148f6865af7dadfe49455",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/16402 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Post-tokenization Phase 1 item: {'label': tensor(1.), 'input_ids': tensor([  101,  4045,  3350,  6351, 14384,  8554, 13210,  3372,  3020,  6351,\n",
            "        14384, 14061,  2941,  2393, 20440,  2490,  3269,  4111,  2166,   102,\n",
            "         3020,  6351, 14384, 14061,  7927,  8231,  7461,  3269,  3930,  5157,\n",
            "         2300,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n",
            "\n",
            "Training Phase 1: Gold vs Random Negatives...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1926' max='1926' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1926/1926 1:08:48, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>29.362200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.530600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.166600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.153600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.130600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.125400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.099600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.086600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.076000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.069000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.066400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.057600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.051600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.051100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.047600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.045400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.036900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.038100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.037400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.033800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.030300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.030800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.039900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.027700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.026100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.023300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.021600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.027500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.022600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.024800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.023300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.022800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.019400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.022400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.017200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.026800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model after Phase 1...\n",
            "\n",
            "Training Phase 2: Gold vs Hard Negatives...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2052' max='2052' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2052/2052 1:11:25, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.315200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.166000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.177000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.173600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.162800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.160200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.160200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.160900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.169700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.161100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.160800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.141700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.170700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.152600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.152200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.161900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.147000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.160700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.160700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.156300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.156500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.148000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.128500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.136100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.146700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.150300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.141900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.144800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.154200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.141600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.140600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.145200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.142400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.135400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.134900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.138600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.143200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.134800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.141200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.131400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.144900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving final model after Phase 2...\n",
            "\n",
            "Evaluating Full Metrics on Training Set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring candidates: 100%|██████████| 1228/1228 [41:35<00:00,  2.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evidence Retrieval F-score (F): 0.2045\n",
            "Evidence Retrieval Recall: 0.2902\n",
            "Evidence Retrieval Precision: 0.1743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from datasets import Dataset\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import datasets\n",
        "\n",
        "# # Verify versions\n",
        "# print(\"NumPy version:\", np.__version__)\n",
        "# print(\"Transformers version:\", transformers.__version__)\n",
        "# print(\"Datasets version:\", datasets.__version__)\n",
        "\n",
        "# Configuration\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "phase1_path = os.path.join(data_dir, \"training_rerank_phase1.json\")\n",
        "phase2_path = os.path.join(data_dir, \"training_rerank_phase2.json\")\n",
        "pre_rank_file = os.path.join(data_dir, \"merged_pre_rank_pool.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "\n",
        "def load_train_pairs_json_array(phase_path):\n",
        "    result = []\n",
        "    try:\n",
        "        with open(phase_path, 'r') as f:\n",
        "            entries = json.load(f)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error loading {phase_path}: {e}\")\n",
        "        raise\n",
        "    except FileNotFoundError:\n",
        "        print(f\"{phase_path} not found\")\n",
        "        raise\n",
        "    for entry in entries:\n",
        "        claim = entry.get(\"claim\") or entry.get(\"claim_text\", \"\")\n",
        "        candidates = entry.get(\"candidates\", [])\n",
        "        if not claim or not candidates:\n",
        "            print(f\"Skipping invalid entry in {phase_path}: claim={claim}, candidates={len(candidates)}\")\n",
        "            continue\n",
        "        for cand in candidates:\n",
        "            text = cand.get(\"text\", \"\")\n",
        "            label = cand.get(\"label\", 0)\n",
        "            if text:\n",
        "                result.append((claim, text, label))\n",
        "    return result\n",
        "\n",
        "# Load and validate data\n",
        "print(\"Loading Phase 1 data...\")\n",
        "train_pairs_phase1 = load_train_pairs_json_array(phase1_path)\n",
        "print(\"Loading Phase 2 data...\")\n",
        "train_pairs_phase2 = load_train_pairs_json_array(phase2_path)\n",
        "\n",
        "print(\"First Phase 1 tuple:\", train_pairs_phase1[0] if train_pairs_phase1 else \"No tuples\")\n",
        "print(\"First Phase 2 tuple:\", train_pairs_phase2[0] if train_pairs_phase2 else \"No tuples\")\n",
        "\n",
        "print(\"Converting to Hugging Face datasets...\")\n",
        "train_dataset_phase1 = Dataset.from_list([\n",
        "    {\"claim\": c, \"evidence\": e, \"label\": float(lbl)} for (c, e, lbl) in tqdm(train_pairs_phase1)\n",
        "])\n",
        "train_dataset_phase2 = Dataset.from_list([\n",
        "    {\"claim\": c, \"evidence\": e, \"label\": float(lbl)} for (c, e, lbl) in tqdm(train_pairs_phase2)\n",
        "])\n",
        "\n",
        "print(f\"Phase 1 examples: {len(train_dataset_phase1)}\")\n",
        "print(f\"Phase 2 examples: {len(train_dataset_phase2)}\")\n",
        "print(\"First Phase 1 item:\", train_dataset_phase1[0] if train_dataset_phase1 else \"No data\")\n",
        "print(\"Phase 1 keys:\", list(train_dataset_phase1[0].keys()) if train_dataset_phase1 else \"No keys\")\n",
        "print(\"Dataset features:\", train_dataset_phase1.features if train_dataset_phase1 else \"No features\")\n",
        "\n",
        "# Initialize model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    encodings = tokenizer(examples[\"claim\"], examples[\"evidence\"], padding='max_length', truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "    return {\n",
        "        \"input_ids\": encodings[\"input_ids\"],\n",
        "        \"attention_mask\": encodings[\"attention_mask\"],\n",
        "        \"label\": torch.tensor(examples[\"label\"], dtype=torch.float)\n",
        "    }\n",
        "\n",
        "# Tokenize datasets\n",
        "print(\"Tokenizing datasets...\")\n",
        "train_dataset_phase1 = train_dataset_phase1.map(tokenize_function, batched=True, remove_columns=[\"claim\", \"evidence\"])\n",
        "train_dataset_phase2 = train_dataset_phase2.map(tokenize_function, batched=True, remove_columns=[\"claim\", \"evidence\"])\n",
        "\n",
        "# Set format for training\n",
        "train_dataset_phase1.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "train_dataset_phase2.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "# Verify dataset\n",
        "print(\"Post-tokenization Phase 1 item:\", train_dataset_phase1[0])\n",
        "\n",
        "# Phase 1 training\n",
        "training_args_phase1 = TrainingArguments(\n",
        "    output_dir=\"reranker_model_phase1\",\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    warmup_steps=100,\n",
        "    logging_steps=50,\n",
        "    logging_dir=\"logs_phase1\",\n",
        "    save_strategy=\"no\",\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "trainer_phase1 = Trainer(\n",
        "    model=model,\n",
        "    args=training_args_phase1,\n",
        "    train_dataset=train_dataset_phase1,\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
        ")\n",
        "\n",
        "print(\"\\nTraining Phase 1: Gold vs Random Negatives...\")\n",
        "trainer_phase1.train()\n",
        "print(\"Saving model after Phase 1...\")\n",
        "trainer_phase1.save_model(\"reranker_model_phase1_final\")\n",
        "\n",
        "# Phase 2 training\n",
        "training_args_phase2 = TrainingArguments(\n",
        "    output_dir=\"reranker_model_phase2\",\n",
        "    overwrite_output_dir=True,\n",
        "    eval_strategy=\"no\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    warmup_steps=50,\n",
        "    logging_steps=50,\n",
        "    logging_dir=\"logs_phase2\",\n",
        "    save_strategy=\"no\",\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "trainer_phase2 = Trainer(\n",
        "    model=model,\n",
        "    args=training_args_phase2,\n",
        "    train_dataset=train_dataset_phase2,\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
        ")\n",
        "\n",
        "print(\"\\nTraining Phase 2: Gold vs Hard Negatives...\")\n",
        "trainer_phase2.train()\n",
        "print(\"Saving final model after Phase 2...\")\n",
        "trainer_phase2.save_model(\"reranker_model_final_minilm1\")\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nEvaluating Full Metrics on Training Set...\")\n",
        "try:\n",
        "    with open(pre_rank_file) as f:\n",
        "        rerank_pool = json.load(f)\n",
        "    with open(evidence_file) as f:\n",
        "        evidence_corpus = json.load(f)\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"Error loading evaluation files: {e}\")\n",
        "    raise\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Evaluation file not found: {e}\")\n",
        "    raise\n",
        "\n",
        "model.eval()\n",
        "recalls = []\n",
        "precisions = []\n",
        "f_scores = []\n",
        "task4_data = []\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for cid, entry in tqdm(rerank_pool.items(), desc=\"Scoring candidates\"):\n",
        "    claim_text = entry.get(\"claim_text\", \"\")\n",
        "    claim_label = entry[\"claim_label\"]\n",
        "    if claim_label is None:\n",
        "        print(f\"Missing claim_label for claim {cid}\")\n",
        "        continue\n",
        "    gold_ids = set(entry.get(\"evidences\", []))\n",
        "    candidates = entry.get(\"pre_ranked_pool\", [])\n",
        "    if not claim_text or not gold_ids or not candidates:\n",
        "        print(f\"Skipping claim {cid}: invalid data\")\n",
        "        continue\n",
        "    texts = [evidence_corpus[eid] for eid in candidates if eid in evidence_corpus]\n",
        "    pairs = [(claim_text, txt) for txt in texts]\n",
        "    if not pairs:\n",
        "        continue\n",
        "\n",
        "    encoded = tokenizer.batch_encode_plus(pairs, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**{k: v.to(device) for k, v in encoded.items()})\n",
        "    scores = outputs.logits.squeeze()\n",
        "    topk_indices = torch.topk(scores, k=min(5, len(scores))).indices.tolist()\n",
        "    topk_ids = [candidates[i] for i in topk_indices]\n",
        "\n",
        "    evidence_correct = sum(1 for g in gold_ids if g in topk_ids)\n",
        "    evidence_recall = evidence_correct / len(gold_ids) if gold_ids else 0.0\n",
        "    recalls.append(evidence_recall)\n",
        "    evidence_precision = evidence_correct / len(topk_ids) if topk_ids else 0.0\n",
        "    precisions.append(evidence_precision)\n",
        "    evidence_fscore = (2 * evidence_precision * evidence_recall) / (evidence_precision + evidence_recall) if (evidence_precision + evidence_recall) > 0 else 0.0\n",
        "    f_scores.append(evidence_fscore)\n",
        "\n",
        "    task4_data.append({\n",
        "        \"claim_id\": cid,\n",
        "        \"claim_text\": claim_text,\n",
        "        \"claim_label\": claim_label,\n",
        "        \"top_evidence_ids\": topk_ids,\n",
        "        \"gold_evidence_ids\": list(gold_ids)\n",
        "    })\n",
        "\n",
        "mean_f = np.mean(f_scores if f_scores else [0.0])\n",
        "mean_recall = np.mean(recalls if recalls else [0.0])\n",
        "mean_precision = np.mean(precisions if precisions else [0.0])\n",
        "\n",
        "print(f\"Evidence Retrieval F-score (F): {mean_f:.4f}\")\n",
        "print(f\"Evidence Retrieval Recall: {mean_recall:.4f}\")\n",
        "print(f\"Evidence Retrieval Precision: {mean_precision:.4f}\")\n",
        "\n",
        "# Save Task 4 dataset\n",
        "with open(\"task4_input_minilm.json\", \"w\") as f:\n",
        "    json.dump(task4_data, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a06604f7cf3c41ea8b269b4209dad138",
            "0089ae86a72b4d4f8e87473878f3e98a",
            "a441c1e184ac4157acc41c8f96250eb9",
            "f2bb402ae11a4f15bd78e73098be82db",
            "27e690f1b80f4bdaa6fdbc28ea057275",
            "0c821b9e138b4a4587d80637946593fd",
            "7f5412cae7d84021ba96630a053ef0a9",
            "f5bec42416cc41eb9fcc409ea37d5409",
            "c61d7d432ae148b8bb4917607f9114a6",
            "e545d983a5bd4936aa1a1e2de1789cba",
            "f02b3927d026487f9683b8036a7b95ac",
            "5cc1d8dbab77428aaeea0f6391ba6463",
            "2103a5a1555d4e29b21776c7940d7a9f",
            "3f52e9c4ba2847dc9f1506ffc9020473",
            "a50e820f42cd48689734de1c9b668914",
            "7cce747ed7b643c5a43281004b4767e0",
            "4fb2f04826ea4200a5db4d04e157b1b3",
            "82676b84a9ae4f1995d4c4b04ce75eac",
            "8d6cd886c6644492aa741e42bcec581d",
            "8a782f642b43477da171c1d01ef22492",
            "9a0b807121644e8995932ff8f132530c",
            "0d91c88fd5034d879e539fffa211ae8a"
          ]
        },
        "id": "7t4zRUi6VCEt",
        "outputId": "01a7a53a-df76-43b9-9e25-b5ba3218d760"
      },
      "outputs": [],
      "source": [
        "#NEED TO BE UPDATED - IMBALANCE CLASS + GRADIENT\n",
        "import os\n",
        "import json\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainerCallback\n",
        ")\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "\n",
        "# Configuration\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "phase1_path = os.path.join(data_dir, \"training_rerank_phase1.json\")\n",
        "phase2_path = os.path.join(data_dir, \"training_rerank_phase2.json\")\n",
        "pre_rank_file = os.path.join(data_dir, \"merged_pre_rank_pool.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "\n",
        "# Load training pairs\n",
        "def load_train_pairs_json_array(path):\n",
        "    with open(path) as f:\n",
        "        entries = json.load(f)\n",
        "    return [(entry[\"claim\"], cand[\"text\"], cand[\"label\"]) for entry in entries for cand in entry[\"candidates\"]]\n",
        "\n",
        "print(\"Loading training data...\")\n",
        "train_pairs_phase1 = load_train_pairs_json_array(phase1_path)\n",
        "train_pairs_phase2 = load_train_pairs_json_array(phase2_path)\n",
        "\n",
        "# Compute class weights for BCE\n",
        "all_labels = [lbl for (_, _, lbl) in train_pairs_phase1 + train_pairs_phase2]\n",
        "label_counts = Counter(all_labels)\n",
        "total = sum(label_counts.values())\n",
        "pos_weight = total / label_counts[1.0]\n",
        "print(\"Class counts:\", label_counts)\n",
        "print(\"Pos weight (for BCE):\", pos_weight)\n",
        "\n",
        "# Convert to datasets\n",
        "train_dataset_phase1 = Dataset.from_list([\n",
        "    {\"claim\": c, \"evidence\": e, \"label\": float(lbl)} for (c, e, lbl) in train_pairs_phase1\n",
        "])\n",
        "train_dataset_phase2 = Dataset.from_list([\n",
        "    {\"claim\": c, \"evidence\": e, \"label\": float(lbl)} for (c, e, lbl) in train_pairs_phase2\n",
        "])\n",
        "\n",
        "# Tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    encodings = tokenizer(examples[\"claim\"], examples[\"evidence\"], padding='max_length', truncation=True, max_length=256)\n",
        "    return {**encodings, \"label\": examples[\"label\"]}\n",
        "\n",
        "# Preprocess\n",
        "train_dataset_phase1 = train_dataset_phase1.map(tokenize_function, batched=True, remove_columns=[\"claim\", \"evidence\"])\n",
        "train_dataset_phase2 = train_dataset_phase2.map(tokenize_function, batched=True, remove_columns=[\"claim\", \"evidence\"])\n",
        "\n",
        "train_dataset_phase1.set_format(\"torch\")\n",
        "train_dataset_phase2.set_format(\"torch\")\n",
        "\n",
        "# Loss callback\n",
        "class LogLossCallback(TrainerCallback):\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs and \"loss\" in logs:\n",
        "            print(f\"Step {state.global_step} - loss: {logs['loss']:.4f}\")\n",
        "\n",
        "# Custom trainer with weighted BCE loss\n",
        "class BCETrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\").unsqueeze(1)  # (batch_size, 1)\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight).to(logits.device))\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Phase 1 Training Args\n",
        "training_args_phase1 = TrainingArguments(\n",
        "    output_dir=os.path.join(data_dir, \"reranker_model_phase1_minilm2\"),\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=3,\n",
        "    warmup_steps=100,\n",
        "    logging_steps=50,\n",
        "    logging_dir=os.path.join(data_dir, \"logs_phase1\"),\n",
        "    save_strategy=\"no\",\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "# Phase 2 Training Args\n",
        "training_args_phase2 = TrainingArguments(\n",
        "    output_dir=os.path.join(data_dir, \"reranker_model_phase2_minilm2\"),\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=2,\n",
        "    warmup_steps=50,\n",
        "    logging_steps=50,\n",
        "    logging_dir=os.path.join(data_dir, \"logs_phase2\"),\n",
        "    save_strategy=\"no\",\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "# Phase 1 Training\n",
        "print(\"\\nTraining Phase 1: Gold vs Random Negatives...\")\n",
        "trainer_phase1 = BCETrainer(\n",
        "    model=model,\n",
        "    args=training_args_phase1,\n",
        "    train_dataset=train_dataset_phase1,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer),\n",
        "    callbacks=[LogLossCallback()]\n",
        ")\n",
        "trainer_phase1.train()\n",
        "trainer_phase1.save_model(os.path.join(data_dir, \"reranker_model_phase1_final_minilm2\"))\n",
        "\n",
        "# Reload model\n",
        "print(\"\\nTraining Phase 2: Gold vs Hard Negatives...\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(os.path.join(data_dir, \"reranker_model_phase1_final_minilm2\"))\n",
        "trainer_phase2 = BCETrainer(\n",
        "    model=model,\n",
        "    args=training_args_phase2,\n",
        "    train_dataset=train_dataset_phase2,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer),\n",
        "    callbacks=[LogLossCallback()]\n",
        ")\n",
        "trainer_phase2.train()\n",
        "trainer_phase2.save_model(os.path.join(data_dir, \"reranker_model_final_minilm2\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "cvMyzAVxYpR-",
        "outputId": "7b064edf-e4d2-4969-bcf2-3f57dd5ba9ae"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Config\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "model_path = os.path.join(data_dir, \"reranker_model_final_minilm2\")\n",
        "pre_rank_file = os.path.join(data_dir, \"merged_pre_rank_pool.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "output_path = os.path.join(data_dir, \"classification_input_minilm.json\")\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Load data\n",
        "with open(pre_rank_file) as f:\n",
        "    rerank_pool = json.load(f)\n",
        "with open(evidence_file) as f:\n",
        "    evidence_corpus = json.load(f)\n",
        "\n",
        "recalls, precisions, f_scores = [], [], []\n",
        "task4_data = []\n",
        "\n",
        "# Scoring loop\n",
        "for cid, entry in tqdm(rerank_pool.items(), desc=\"Scoring candidates\"):\n",
        "    claim_text = entry.get(\"claim_text\", \"\")\n",
        "    claim_label = entry.get(\"claim_label\", None)\n",
        "    gold_ids = set(entry.get(\"evidences\", []))\n",
        "    candidates = entry.get(\"pre_ranked_pool\", [])\n",
        "\n",
        "    if not claim_text or not candidates or claim_label is None:\n",
        "        continue\n",
        "\n",
        "    texts = [evidence_corpus[eid] for eid in candidates if eid in evidence_corpus]\n",
        "    pairs = [(claim_text, txt) for txt in texts]\n",
        "    if not pairs:\n",
        "        continue\n",
        "\n",
        "    encoded = tokenizer.batch_encode_plus(pairs, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**{k: v.to(device) for k, v in encoded.items()})\n",
        "        probs = outputs.logits.squeeze()\n",
        "\n",
        "    topk_indices = torch.topk(scores, k=min(5, len(scores))).indices.tolist()\n",
        "    topk_ids = [candidates[i] for i in topk_indices]\n",
        "\n",
        "    correct = sum(1 for g in gold_ids if g in topk_ids)\n",
        "    recall = correct / len(gold_ids) if gold_ids else 0.0\n",
        "    precision = correct / len(topk_ids) if topk_ids else 0.0\n",
        "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    recalls.append(recall)\n",
        "    precisions.append(precision)\n",
        "    f_scores.append(f1)\n",
        "\n",
        "    task4_data.append({\n",
        "        \"claim_id\": cid,\n",
        "        \"claim_text\": claim_text,\n",
        "        \"claim_label\": claim_label,\n",
        "        \"top_evidence_ids\": topk_ids,\n",
        "        \"gold_evidence_ids\": list(gold_ids)\n",
        "    })\n",
        "\n",
        "# Report\n",
        "print(f\"Evidence Retrieval F-score (F): {np.mean(f_scores):.4f}\")\n",
        "print(f\"Evidence Retrieval Recall: {np.mean(recalls):.4f}\")\n",
        "print(f\"Evidence Retrieval Precision: {np.mean(precisions):.4f}\")\n",
        "\n",
        "# Save JSON\n",
        "with open(output_path, \"w\") as f:\n",
        "    json.dump(task4_data, f, indent=2)\n",
        "print(f\"Saved classification-ready file to: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EXfcGEyt7B-"
      },
      "source": [
        "#### 2.2.3 DistilBERT Cross-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559,
          "referenced_widgets": [
            "7e498e87b7294554b1b63db8a2947514",
            "9c0bfdc3ace94d2b9404b6e5813e5f53",
            "d5e381540d2541d5a5eba257712c3a0a",
            "d4c7165e038c4c998e799d4b0cbcb75a",
            "0ffd258ae7f449f191cd7189a7700cc6",
            "cdc08d0d5fc745a7874037e178c640e5",
            "e72eb0cec3254f65be0e91496cbe45ef",
            "a19c805293c94e51aaf5c0facce36ace",
            "e50e8fcfe5a046fda71d5485f73baba1",
            "c9bfc86fd751419b87296337e5529943",
            "775f3897dc584a9d851b523cfe47c4fc",
            "e5a71e51937a426fbfcf42cec7a09b2c",
            "daef646174374fa38180b33de07f9a3c",
            "e1f914c5af7347178403e9664b3f94ab",
            "8e02d22155564b5f84be975273ec5af9",
            "14b68aa577194b1ab63c12ec607b23b0",
            "15572f24bfeb406a87fc79628aa61ef5",
            "c3e680a34a894c569353d7d9a31f64ae",
            "79e235cce99b4ff098cb52ecef061d22",
            "074286f667084de68831a464d38b7133",
            "c6495826c4f64603a936972701f256f2",
            "644fb0c1e23a4a9aa55cd378d48531c5"
          ]
        },
        "id": "aHsz-JZd4M3L",
        "outputId": "89a99345-fe01-4321-95d1-3ec68e67bf4b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "# Paths\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "phase1_path = os.path.join(data_dir, \"training_rerank_phase1.json\")\n",
        "phase2_path = os.path.join(data_dir, \"training_rerank_phase2.json\")\n",
        "pre_rank_file = os.path.join(data_dir, \"merged_pre_rank_pool.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "\n",
        "# Load training data\n",
        "with open(phase1_path) as f:\n",
        "    phase1_raw = json.load(f)\n",
        "with open(phase2_path) as f:\n",
        "    phase2_raw = json.load(f)\n",
        "\n",
        "def convert_to_pairs(raw):\n",
        "    return [(entry[\"claim\"], cand[\"text\"], cand[\"label\"])\n",
        "            for entry in raw for cand in entry[\"candidates\"]]\n",
        "\n",
        "train_pairs_phase1 = convert_to_pairs(phase1_raw)\n",
        "train_pairs_phase2 = convert_to_pairs(phase2_raw)\n",
        "\n",
        "train_dataset_phase1 = Dataset.from_list([\n",
        "    {\"claim\": c, \"evidence\": e, \"label\": lbl} for (c, e, lbl) in train_pairs_phase1\n",
        "])\n",
        "train_dataset_phase2 = Dataset.from_list([\n",
        "    {\"claim\": c, \"evidence\": e, \"label\": lbl} for (c, e, lbl) in train_pairs_phase2\n",
        "])\n",
        "\n",
        "print(f\"Phase1 examples: {len(train_dataset_phase1)}\")\n",
        "print(f\"Phase2 examples: {len(train_dataset_phase2)}\")\n",
        "print(train_dataset_phase1[0])\n",
        "\n",
        "# Compute class weights from both phases\n",
        "def compute_label_distribution(*datasets):\n",
        "    counter = Counter()\n",
        "    for data in datasets:\n",
        "        for entry in data:\n",
        "            for cand in entry[\"candidates\"]:\n",
        "                counter[cand[\"label\"]] += 1\n",
        "    return counter\n",
        "\n",
        "label_counts = compute_label_distribution(phase1_raw, phase2_raw)\n",
        "total = sum(label_counts.values())\n",
        "class_weights = [total / label_counts[i] for i in sorted(label_counts)]\n",
        "print(\"Class counts:\", label_counts)\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "# Tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# Encode function\n",
        "def encode_batch(batch):\n",
        "    return tokenizer(batch[\"claim\"], batch[\"evidence\"],\n",
        "                     padding='max_length', truncation=True,\n",
        "                     max_length=256, return_tensors=\"pt\")\n",
        "\n",
        "# Custom trainer with class-weighted loss\n",
        "class WeightedTrainer(Trainer):\n",
        "    def __init__(self, class_weights, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        w0, w1 = class_weights.get(0.0, 1.0), class_weights.get(1.0, 1.0)\n",
        "        self.weight_tensor = torch.tensor([w0, w1])\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"label\").view(-1)\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits.view(-1)\n",
        "        weights = torch.where(labels == 1.0, self.weight_tensor[1], self.weight_tensor[0]).to(logits.device)\n",
        "        loss = BCEWithLogitsLoss(weight=weights)(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Phase 1 training\n",
        "training_args_phase1 = TrainingArguments(\n",
        "    output_dir=\"distilbert_reranker_phase1\",\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"no\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=3,\n",
        "    warmup_steps=100,\n",
        "    logging_steps=50,\n",
        "    logging_dir=\"logs_distil_phase1\",\n",
        "    save_strategy=\"no\",\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "trainer_phase1 = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args_phase1,\n",
        "    train_dataset=train_dataset_phase1,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=lambda data: encode_batch(data),\n",
        "    class_weights=class_weights\n",
        ")\n",
        "\n",
        "print(\"Training Phase 1 (DistilBERT): Gold vs Random Negatives...\")\n",
        "trainer_phase1.train()\n",
        "\n",
        "# Phase 2 training\n",
        "training_args_phase2 = TrainingArguments(\n",
        "    output_dir=\"distilbert_reranker_phase2\",\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"no\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=2,\n",
        "    warmup_steps=50,\n",
        "    logging_steps=50,\n",
        "    logging_dir=\"logs_distil_phase2\",\n",
        "    save_strategy=\"no\",\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "trainer_phase2 = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args_phase2,\n",
        "    train_dataset=train_dataset_phase2,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=lambda data: encode_batch(data),\n",
        "    class_weights=class_weights\n",
        ")\n",
        "\n",
        "print(\"Training Phase 2 (DistilBERT): Gold vs Hard Negatives...\")\n",
        "trainer_phase2.train()\n",
        "\n",
        "# Save final model\n",
        "final_model_path = os.path.join(data_dir, \"reranker_model_final_distilbert\")\n",
        "trainer_phase2.save_model(final_model_path)\n",
        "print(f\"Saved final model to: {final_model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrXOv-vYZWIJ"
      },
      "outputs": [],
      "source": [
        "# EVALUATION BLOCK\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Config\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "model_path = os.path.join(data_dir, \"reranker_model_final_distilbert\")\n",
        "pre_rank_file = os.path.join(data_dir, \"merged_pre_rank_pool.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "output_path = os.path.join(data_dir, \"classification_input_distilbert.json\")\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Load data\n",
        "with open(pre_rank_file) as f:\n",
        "    rerank_pool = json.load(f)\n",
        "with open(evidence_file) as f:\n",
        "    evidence_corpus = json.load(f)\n",
        "\n",
        "recalls, precisions, f_scores = [], [], []\n",
        "task4_data = []\n",
        "\n",
        "# Scoring loop\n",
        "for cid, entry in tqdm(rerank_pool.items(), desc=\"Scoring candidates\"):\n",
        "    claim_text = entry.get(\"claim_text\", \"\")\n",
        "    claim_label = entry.get(\"claim_label\", None)\n",
        "    gold_ids = set(entry.get(\"evidences\", []))\n",
        "    candidates = entry.get(\"pre_ranked_pool\", [])\n",
        "\n",
        "    if not claim_text or not candidates or claim_label is None:\n",
        "        continue\n",
        "\n",
        "    texts = [evidence_corpus[eid] for eid in candidates if eid in evidence_corpus]\n",
        "    pairs = [(claim_text, txt) for txt in texts]\n",
        "    if not pairs:\n",
        "        continue\n",
        "\n",
        "    encoded = tokenizer.batch_encode_plus(pairs, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**{k: v.to(device) for k, v in encoded.items()})\n",
        "        scores = torch.softmax(outputs.logits, dim=1)[:, 1]\n",
        "\n",
        "    topk_indices = torch.topk(scores, k=min(5, len(scores))).indices.tolist()\n",
        "    topk_ids = [candidates[i] for i in topk_indices]\n",
        "\n",
        "    correct = sum(1 for g in gold_ids if g in topk_ids)\n",
        "    recall = correct / len(gold_ids) if gold_ids else 0.0\n",
        "    precision = correct / len(topk_ids) if topk_ids else 0.0\n",
        "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    recalls.append(recall)\n",
        "    precisions.append(precision)\n",
        "    f_scores.append(f1)\n",
        "\n",
        "    task4_data.append({\n",
        "        \"claim_id\": cid,\n",
        "        \"claim_text\": claim_text,\n",
        "        \"claim_label\": claim_label,\n",
        "        \"top_evidence_ids\": topk_ids,\n",
        "        \"gold_evidence_ids\": list(gold_ids)\n",
        "    })\n",
        "\n",
        "# Report\n",
        "print(f\"Evidence Retrieval F-score (F): {np.mean(f_scores):.4f}\")\n",
        "print(f\"Evidence Retrieval Recall: {np.mean(recalls):.4f}\")\n",
        "print(f\"Evidence Retrieval Precision: {np.mean(precisions):.4f}\")\n",
        "\n",
        "# Save JSON\n",
        "with open(output_path, \"w\") as f:\n",
        "    json.dump(task4_data, f, indent=2)\n",
        "print(f\"Saved classification-ready file to: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKS0h1yBQr3F"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_reranker_results(json_path, top_k=5):\n",
        "    with open(json_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    recalls = []\n",
        "    precisions = []\n",
        "    f1s = []\n",
        "    accuracies = []\n",
        "\n",
        "    for entry in tqdm(data, desc=f\"Evaluating {os.path.basename(json_path)}\"):\n",
        "        gold_ids = set(entry[\"gold_evidence_ids\"])\n",
        "        predicted_ids = entry[\"top_evidence_ids\"][:top_k]\n",
        "\n",
        "        if not gold_ids or not predicted_ids:\n",
        "            continue\n",
        "\n",
        "        correct = sum(1 for gid in gold_ids if gid in predicted_ids)\n",
        "        recall = correct / len(gold_ids)\n",
        "        precision = correct / len(predicted_ids)\n",
        "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "        accuracy = int(gold_ids.issubset(set(predicted_ids)))  # all golds found in top-k\n",
        "\n",
        "        recalls.append(recall)\n",
        "        precisions.append(precision)\n",
        "        f1s.append(f1)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    print(f\"\\n--- Evaluation: {os.path.basename(json_path)} ---\")\n",
        "    print(f\"Recall@{top_k}: {np.mean(recalls):.4f}\")\n",
        "    print(f\"Precision@{top_k}: {np.mean(precisions):.4f}\")\n",
        "    print(f\"F1@{top_k}: {np.mean(f1s):.4f}\")\n",
        "    print(f\"Accuracy@{top_k} (all gold in top-k): {np.mean(accuracies):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K27KCD5rRCU1",
        "outputId": "afe8490f-fe2b-437a-af2a-9b2bb14e1bc6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating classification_input_minilm1.json: 100%|██████████| 1228/1228 [00:00<00:00, 351145.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation: classification_input_minilm1.json ---\n",
            "Recall@5: 0.2841\n",
            "Precision@5: 0.1715\n",
            "F1@5: 0.2009\n",
            "Accuracy@5 (all gold in top-k): 0.1059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating classification_input_minilm2.json: 100%|██████████| 1228/1228 [00:00<00:00, 377444.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation: classification_input_minilm2.json ---\n",
            "Recall@5: 0.3545\n",
            "Precision@5: 0.2156\n",
            "F1@5: 0.2522\n",
            "Accuracy@5 (all gold in top-k): 0.1368\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating classification_input_distilbert.json: 100%|██████████| 1228/1228 [00:00<00:00, 383144.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation: classification_input_distilbert.json ---\n",
            "Recall@5: 0.4613\n",
            "Precision@5: 0.2780\n",
            "F1@5: 0.3251\n",
            "Accuracy@5 (all gold in top-k): 0.1808\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "\n",
        "evaluate_reranker_results(os.path.join(data_dir, \"classification_input_minilm1.json\"))\n",
        "evaluate_reranker_results(os.path.join(data_dir, \"classification_input_minilm2.json\"))\n",
        "evaluate_reranker_results(os.path.join(data_dir, \"classification_input_distilbert.json\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMF4e7ZgFUDh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBV92M9IviLN"
      },
      "source": [
        "## 3.1 Evidence Retrieval - Pre-ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1sgCnpjwY6T"
      },
      "source": [
        "### 3.1.1 Baseline Model - BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4A_RGg_whrK",
        "outputId": "0e485efa-7f08-4d79-915f-94da1ea462f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BoW vectoriser and evidence matrix...\n",
            "Vectorising dev claims...\n",
            "Computing cosine similarity...\n",
            "Retrieving top 5 evidence IDs per dev claim...\n",
            "\n",
            "Saved top-5 BoW evidence retrieval results to: /content/drive/MyDrive/NLP_content/dev_claims_retrieved_bow_top5.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "import scipy.sparse\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Settings\n",
        "top_k = 5\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "\n",
        "# Load vectoriser and BoW matrix for evidence\n",
        "print(\"Loading BoW vectoriser and evidence matrix...\")\n",
        "bow_vectorizer = joblib.load(os.path.join(data_dir, \"bow_vectorizer.pkl\"))\n",
        "evidence_bow = scipy.sparse.load_npz(os.path.join(data_dir, \"evidence_p1_bow.npz\"))\n",
        "\n",
        "# Load evidence and dev claim data\n",
        "evidence_data = json.load(open(os.path.join(data_dir, \"evidence-preprocessed1.json\")))\n",
        "dev_claims_data = json.load(open(os.path.join(data_dir, \"dev-claims-preprocessed1.json\")))\n",
        "\n",
        "evidence_ids = list(evidence_data.keys())\n",
        "dev_claim_ids = list(dev_claims_data.keys())\n",
        "dev_claim_texts = [dev_claims_data[cid][\"claim_text\"] for cid in dev_claim_ids]\n",
        "\n",
        "# Vectorise dev claims using existing vectoriser\n",
        "print(\"Vectorising dev claims...\")\n",
        "dev_bow = bow_vectorizer.transform(dev_claim_texts)\n",
        "\n",
        "# Compute cosine similarity\n",
        "print(\"Computing cosine similarity...\")\n",
        "cosine_sim = cosine_similarity(dev_bow, evidence_bow)\n",
        "ranked_indices = np.argsort(-cosine_sim, axis=1)\n",
        "\n",
        "# Retrieve top-k evidence for each dev claim\n",
        "print(f\"Retrieving top {top_k} evidence IDs per dev claim...\")\n",
        "top_k_evidence = {\n",
        "    cid: [evidence_ids[i] for i in ranked_indices[idx][:top_k]]\n",
        "    for idx, cid in enumerate(dev_claim_ids)\n",
        "}\n",
        "\n",
        "# Build and save final output\n",
        "dev_claims_retrieved = {\n",
        "    cid: {\n",
        "        \"claim_text\": dev_claims_data[cid][\"claim_text\"],\n",
        "        \"pre_ranked_evidences\": top_k_evidence[cid]\n",
        "    }\n",
        "    for cid in dev_claim_ids\n",
        "}\n",
        "\n",
        "output_path = os.path.join(data_dir, \"dev_claims_retrieved_bow_top5.json\")\n",
        "with open(output_path, \"w\") as f:\n",
        "    json.dump(dev_claims_retrieved, f, indent=2)\n",
        "\n",
        "print(f\"\\nSaved top-5 BoW evidence retrieval results to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vFxu7ajw3mU",
        "outputId": "47875471-01a4-445e-e098-e8c171a4d46b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating dev_claims_retrieved_bow_top5.json: 100%|██████████| 154/154 [00:00<00:00, 220075.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation: dev_claims_retrieved_bow_top5.json ---\n",
            "Recall@5: 0.0752\n",
            "Precision@5: 0.0390\n",
            "F1@5: 0.0467\n",
            "Accuracy@5 (all gold in top-k): 0.0325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# File paths\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "gold_claim_file = os.path.join(data_dir, \"dev-claims-preprocessed1.json\")\n",
        "pre_rank_file = os.path.join(data_dir, \"dev_claims_retrieved_bow_top5.json\")\n",
        "pre_rank_filename = os.path.basename(pre_rank_file)\n",
        "\n",
        "# Load data\n",
        "with open(gold_claim_file) as f:\n",
        "    gold_claims = json.load(f)\n",
        "with open(pre_rank_file) as f:\n",
        "    pre_ranked = json.load(f)\n",
        "\n",
        "# Initialise metrics\n",
        "recalls, precisions, f1s = [], [], []\n",
        "accurate_full_match = 0\n",
        "total = 0\n",
        "\n",
        "# Evaluate\n",
        "for cid, entry in tqdm(pre_ranked.items(), desc=f\"Evaluating {pre_rank_filename}\"):\n",
        "    claim_text = entry.get(\"claim_text\", \"\")\n",
        "    pre_ranked_pool = set(entry.get(\"pre_ranked_evidences\", []))  # <-- adapted key\n",
        "    gold_ids = set(gold_claims.get(cid, {}).get(\"evidences\", []))\n",
        "\n",
        "    if not claim_text or not gold_ids or not pre_ranked_pool:\n",
        "        continue\n",
        "\n",
        "    correct = gold_ids & pre_ranked_pool\n",
        "    recall = len(correct) / len(gold_ids)\n",
        "    precision = len(correct) / len(pre_ranked_pool)\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    recalls.append(recall)\n",
        "    precisions.append(precision)\n",
        "    f1s.append(f1)\n",
        "\n",
        "    if gold_ids.issubset(pre_ranked_pool):\n",
        "        accurate_full_match += 1\n",
        "    total += 1\n",
        "\n",
        "# Report\n",
        "print(f\"\\n--- Evaluation: {pre_rank_filename} ---\")\n",
        "print(f\"Recall@{len(pre_ranked_pool)}: {np.mean(recalls):.4f}\")\n",
        "print(f\"Precision@{len(pre_ranked_pool)}: {np.mean(precisions):.4f}\")\n",
        "print(f\"F1@{len(pre_ranked_pool)}: {np.mean(f1s):.4f}\")\n",
        "print(f\"Accuracy@{len(pre_ranked_pool)} (all gold in top-k): {accurate_full_match / total:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FS1QY9ex5o2",
        "outputId": "8846b18c-790f-4e4f-8bf2-4ff39dc5062e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final classification input (Task 2 - BoW) saved to: /content/drive/MyDrive/NLP_content/dev_task2_input_bow.json\n",
            "Total claims processed: 154\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Paths\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "retrieved_file = os.path.join(data_dir, \"dev_claims_retrieved_bow_top5.json\")\n",
        "gold_file = os.path.join(data_dir, \"dev-claims.json\")\n",
        "output_path = os.path.join(data_dir, \"dev_task2_input_bow.json\")  # final output\n",
        "\n",
        "# Load retrieved and gold data\n",
        "with open(retrieved_file, 'r') as f:\n",
        "    retrieved_data = json.load(f)\n",
        "with open(gold_file, 'r') as f:\n",
        "    gold_data = json.load(f)\n",
        "\n",
        "final_output = {}\n",
        "\n",
        "for cid, entry in retrieved_data.items():\n",
        "    claim_text = entry.get(\"claim_text\", \"\")\n",
        "    pre_ranked = entry.get(\"pre_ranked_evidences\", [])\n",
        "    gold_evidences = gold_data.get(cid, {}).get(\"evidences\", [])\n",
        "    label = gold_data.get(cid, {}).get(\"claim_label\", \"\")\n",
        "\n",
        "    # Merge: ensure gold evidences are included\n",
        "    merged_set = []\n",
        "    seen = set()\n",
        "    for eid in pre_ranked + gold_evidences:\n",
        "        if eid not in seen:\n",
        "            seen.add(eid)\n",
        "            merged_set.append(eid)\n",
        "\n",
        "    final_output[cid] = {\n",
        "        \"claim_text\": claim_text,\n",
        "        \"claim_label\": label,\n",
        "        \"evidences\": gold_evidences,\n",
        "        \"pre_ranked_pool\": merged_set  # renamed for classification input\n",
        "    }\n",
        "\n",
        "# Save\n",
        "with open(output_path, 'w') as f:\n",
        "    json.dump(final_output, f, indent=2)\n",
        "\n",
        "print(f\"Final classification input (Task 2 - BoW) saved to: {output_path}\")\n",
        "print(f\"Total claims processed: {len(final_output)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdU_9Rbrv_yM"
      },
      "source": [
        "### 3.1.1 BM25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdDz4LvkwYDp",
        "outputId": "ae4fdb56-9aa1-4623-f1ab-e5999e729d21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BM25 Retrieval on Dev (Test) Set: 100%|██████████| 154/154 [00:01<00:00, 78.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Saved BM25 pre-ranked dev set (top 100) to: /content/drive/MyDrive/NLP_content/dev-claims-preranked-bm25.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from pyserini.search.lucene import LuceneSearcher\n",
        "\n",
        "# Config\n",
        "DATA_DIR = \"/content/drive/MyDrive/NLP_content\"\n",
        "INDEX_PATH = os.path.join(DATA_DIR, \"indexes/evidence_index\")\n",
        "DEV_INPUT = os.path.join(DATA_DIR, \"dev-claims-preprocessed2.json\")\n",
        "DEV_OUTPUT = os.path.join(DATA_DIR, \"dev-claims-preranked-bm25.json\")\n",
        "\n",
        "K1 = 0.5\n",
        "B = 0.3\n",
        "TOP_K = 100\n",
        "\n",
        "# Load Dev JSON\n",
        "def load_json_file(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "dev_data = load_json_file(DEV_INPUT)\n",
        "\n",
        "# Initialize BM25 Searcher\n",
        "searcher = LuceneSearcher(INDEX_PATH)\n",
        "searcher.set_bm25(k1=K1, b=B)\n",
        "\n",
        "# BM25 Retrieval for Dev Claims (as Test)\n",
        "bm25_outputs = {}\n",
        "\n",
        "for claim_id, claim_data in tqdm(dev_data.items(), desc=\"BM25 Retrieval on Dev (Test) Set\"):\n",
        "    claim_text = claim_data[\"claim_text\"]\n",
        "\n",
        "    hits = searcher.search(claim_text, TOP_K)\n",
        "    retrieved_ids = [hit.docid for hit in hits]\n",
        "\n",
        "    bm25_outputs[claim_id] = {\n",
        "        \"claim_text\": claim_text,\n",
        "        \"claim_label\": claim_data.get(\"claim_label\", \"\"),\n",
        "        \"pre_ranked_pool\": retrieved_ids\n",
        "    }\n",
        "\n",
        "# Save\n",
        "with open(DEV_OUTPUT, \"w\") as f:\n",
        "    json.dump(bm25_outputs, f, indent=2)\n",
        "\n",
        "print(f\"\\n Saved BM25 pre-ranked dev set (top {TOP_K}) to: {DEV_OUTPUT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-Quhy-ewIBh"
      },
      "source": [
        "### 3.1.2 MiniLM Bi-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1gN_dgQ1dKi",
        "outputId": "900273ba-5838-4c65-946c-825f7e8cc1ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieving top-100 with MiniLM FAISS: 100%|██████████| 154/154 [00:24<00:00,  6.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved MiniLM pre-ranked top-100 evidence to: /content/drive/MyDrive/NLP_content/dev-preranked-minilm.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Config\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "dev_claim_file = os.path.join(data_dir, \"dev-claims-preprocessed2.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "model_path = os.path.join(data_dir, \"fine_tuned_dpr_triplet_model\")\n",
        "faiss_index_file = os.path.join(data_dir, \"evidence_faiss_minilm.index\")\n",
        "output_file = os.path.join(data_dir, \"dev-preranked-minilm.json\")\n",
        "top_k = 100\n",
        "\n",
        "# Load model, FAISS index, and data\n",
        "model = SentenceTransformer(model_path)\n",
        "index = faiss.read_index(faiss_index_file)\n",
        "\n",
        "with open(dev_claim_file, 'r') as f:\n",
        "    dev_claims = json.load(f)\n",
        "with open(evidence_file, 'r') as f:\n",
        "    evidence_corpus = json.load(f)\n",
        "\n",
        "evid_ids = list(evidence_corpus.keys())\n",
        "\n",
        "# Dense retrieval\n",
        "def dense_retrieve(claim_text: str, top_k: int):\n",
        "    query_vec = model.encode([claim_text], normalize_embeddings=True).astype('float32')\n",
        "    D, I = index.search(query_vec, top_k)\n",
        "    return [(evid_ids[i], float(D[0][idx])) for idx, i in enumerate(I[0])]\n",
        "\n",
        "# Pre-rank only (no eval)\n",
        "pre_ranked_output = {}\n",
        "\n",
        "for cid, entry in tqdm(dev_claims.items(), desc=f\"Retrieving top-{top_k} with MiniLM FAISS\"):\n",
        "    claim_text = entry[\"claim_text\"]\n",
        "    retrieved = dense_retrieve(claim_text, top_k=top_k)\n",
        "    pre_ranked_output[cid] = {\n",
        "        \"claim_text\": claim_text,\n",
        "        \"claim_label\": entry.get(\"claim_label\", \"\"),\n",
        "        \"pre_ranked_pool\": [eid for eid, _ in retrieved]\n",
        "    }\n",
        "\n",
        "# Save output\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(pre_ranked_output, f, indent=2)\n",
        "\n",
        "print(f\"Saved MiniLM pre-ranked top-{top_k} evidence to: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlLc7_pjOhT8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_pre_ranked_retrieval(data_dir, gold_claim_filename, pre_rank_filename):\n",
        "    \"\"\"\n",
        "    Evaluate retrieval effectiveness of a pre-ranked evidence pool.\n",
        "\n",
        "    Args:\n",
        "        data_dir (str): Path to the directory containing JSON files.\n",
        "        gold_claim_filename (str): Filename of the gold claim file (e.g. \"dev-claims-preprocessed2.json\").\n",
        "        pre_rank_filename (str): Filename of the pre-ranked file (e.g. \"dev-preranked-minilm.json\").\n",
        "\n",
        "    Prints:\n",
        "        Mean Recall, Precision, F1, and Accuracy (all gold retrieved).\n",
        "    \"\"\"\n",
        "\n",
        "    gold_claim_file = os.path.join(data_dir, gold_claim_filename)\n",
        "    pre_rank_file = os.path.join(data_dir, pre_rank_filename)\n",
        "\n",
        "    # Load data\n",
        "    with open(gold_claim_file) as f:\n",
        "        gold_claims = json.load(f)\n",
        "    with open(pre_rank_file) as f:\n",
        "        pre_ranked = json.load(f)\n",
        "\n",
        "    recalls, precisions, f1s = [], [], []\n",
        "    accurate_full_match = 0\n",
        "    total = 0\n",
        "\n",
        "    for cid, entry in tqdm(pre_ranked.items(), desc=f\"Evaluating {pre_rank_filename}\"):\n",
        "        claim_text = entry.get(\"claim_text\", \"\")\n",
        "        pre_ranked_pool = set(entry.get(\"pre_ranked_pool\", []))\n",
        "        gold_ids = set(gold_claims.get(cid, {}).get(\"evidences\", []))\n",
        "\n",
        "        if not claim_text or not gold_ids or not pre_ranked_pool:\n",
        "            continue\n",
        "\n",
        "        correct = gold_ids & pre_ranked_pool\n",
        "        recall = len(correct) / len(gold_ids)\n",
        "        precision = len(correct) / len(pre_ranked_pool)\n",
        "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        recalls.append(recall)\n",
        "        precisions.append(precision)\n",
        "        f1s.append(f1)\n",
        "\n",
        "        if gold_ids.issubset(pre_ranked_pool):\n",
        "            accurate_full_match += 1\n",
        "        total += 1\n",
        "\n",
        "    print(f\"\\n--- Evaluation: {pre_rank_filename} ---\")\n",
        "    print(f\"Recall@100: {np.mean(recalls):.4f}\")\n",
        "    print(f\"Precision@100: {np.mean(precisions):.4f}\")\n",
        "    print(f\"F1@100: {np.mean(f1s):.4f}\")\n",
        "    print(f\"Accuracy@100 (all gold in top-k): {accurate_full_match / total:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ2UiG_mPx11",
        "outputId": "f07d46a6-bfe4-46df-e492-dd7449ecb33e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating dev-claims-preranked-bm25.json: 100%|██████████| 154/154 [00:00<00:00, 79002.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation: dev-claims-preranked-bm25.json ---\n",
            "Recall@100: 0.5389\n",
            "Precision@100: 0.0163\n",
            "F1@100: 0.0314\n",
            "Accuracy@100 (all gold in top-k): 0.2857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating dev-preranked-minilm.json: 100%|██████████| 154/154 [00:00<00:00, 92274.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation: dev-preranked-minilm.json ---\n",
            "Recall@100: 0.5939\n",
            "Precision@100: 0.0182\n",
            "F1@100: 0.0350\n",
            "Accuracy@100 (all gold in top-k): 0.3636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_pre_ranked_retrieval(\n",
        "    data_dir=\"/content/drive/MyDrive/NLP_content\",\n",
        "    gold_claim_filename=\"dev-claims-preprocessed2.json\",\n",
        "    pre_rank_filename=\"dev-claims-preranked-bm25.json\"\n",
        ")\n",
        "\n",
        "evaluate_pre_ranked_retrieval(\n",
        "    data_dir=\"/content/drive/MyDrive/NLP_content\",\n",
        "    gold_claim_filename=\"dev-claims-preprocessed2.json\",\n",
        "    pre_rank_filename=\"dev-preranked-minilm.json\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWuHPbTHeH8o"
      },
      "source": [
        "### 3.1.3 Constuct Pre-rank Pool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-249rVYjePaw",
        "outputId": "74597f71-30b5-4669-d2ac-20cc6b216c94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merged dev pre-rank pool saved to: /content/drive/MyDrive/NLP_content/merged_dev_prerank_pool.json\n",
            "Average pool length: 184.62\n",
            "Total duplicate removals: 2369\n",
            "Claims missing gold evidence: 0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Config\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "bm25_file_path = os.path.join(data_dir, \"dev-claims-preranked-bm25.json\")\n",
        "dense_file_path = os.path.join(data_dir, \"dev-preranked-minilm.json\")\n",
        "gold_file_path = os.path.join(data_dir, \"dev-claims.json\")  # gold evidence here\n",
        "output_path = os.path.join(data_dir, \"merged_dev_prerank_pool.json\")\n",
        "\n",
        "# Load data\n",
        "with open(bm25_file_path, 'r') as f:\n",
        "    bm25_data = json.load(f)\n",
        "with open(dense_file_path, 'r') as f:\n",
        "    dense_data = json.load(f)\n",
        "with open(gold_file_path, 'r') as f:\n",
        "    gold_data = json.load(f)\n",
        "\n",
        "merged_output = {}\n",
        "total_pool_lengths = []\n",
        "total_duplicates = 0\n",
        "missing_gold = 0\n",
        "\n",
        "for cid in bm25_data:\n",
        "    bm25_entry = bm25_data[cid]\n",
        "    dense_entry = dense_data.get(cid, {})\n",
        "    gold_entry = gold_data.get(cid, {})\n",
        "\n",
        "    bm25_pool = bm25_entry.get(\"pre_ranked_pool\", [])[:100]\n",
        "    dense_pool = dense_entry.get(\"pre_ranked_pool\", [])[:100]\n",
        "\n",
        "    # Merge pools without duplicates\n",
        "    seen = set()\n",
        "    merged_pool = []\n",
        "    for eid in bm25_pool + dense_pool:\n",
        "        if eid not in seen:\n",
        "            seen.add(eid)\n",
        "            merged_pool.append(eid)\n",
        "        else:\n",
        "            total_duplicates += 1\n",
        "\n",
        "    gold_evidences = gold_entry.get(\"evidences\", [])\n",
        "    if not gold_evidences:\n",
        "        missing_gold += 1\n",
        "\n",
        "    merged_output[cid] = {\n",
        "        \"claim_text\": bm25_entry.get(\"claim_text\", \"\"),\n",
        "        \"claim_label\": bm25_entry.get(\"claim_label\", \"\"),\n",
        "        \"evidences\": gold_evidences,\n",
        "        \"pre_ranked_pool\": merged_pool\n",
        "    }\n",
        "    total_pool_lengths.append(len(merged_pool))\n",
        "\n",
        "# Save\n",
        "with open(output_path, 'w') as f:\n",
        "    json.dump(merged_output, f, indent=2)\n",
        "\n",
        "print(f\"Merged dev pre-rank pool saved to: {output_path}\")\n",
        "print(f\"Average pool length: {sum(total_pool_lengths) / len(total_pool_lengths):.2f}\")\n",
        "print(f\"Total duplicate removals: {total_duplicates}\")\n",
        "print(f\"Claims missing gold evidence: {missing_gold}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySRbwuCt1FGJ"
      },
      "source": [
        "### 3.1.4 RoBERTa DPR Bi-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4icfBGeSwG9l",
        "outputId": "c614b979-0981-4283-a0d4-5a4d8518c8c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating @Top-100 on dev set: 100%|██████████| 154/154 [00:47<00:00,  3.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[RoBERTa DPR] Dev Set Evaluation @Top-100:\n",
            "Claim-level Recall: 37.88% (186/491 gold evidences matched)\n",
            "Instance-level Accuracy (all gold matched): 18.18% (28/154 claims)\n",
            "Recall-hit rate (≥1 gold matched): 102/154 (66.23%)\n",
            "\n",
            "Output written to: /content/drive/MyDrive/NLP_content/dev-pre-ranked-roberta.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# THIS SHOULD NOT BE USED!!! DELETE LATER\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "dev_claim_file = os.path.join(data_dir, \"dev-claims-preprocessed2.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "model_path = os.path.join(data_dir, \"roberta_dpr_biencoder\")\n",
        "faiss_index_file = os.path.join(data_dir, \"roberta_faiss.index\")\n",
        "output_file = os.path.join(data_dir, \"dev-pre-ranked-roberta.json\")\n",
        "\n",
        "# Load model, FAISS index, and data\n",
        "model = SentenceTransformer(model_path)\n",
        "index = faiss.read_index(faiss_index_file)\n",
        "\n",
        "with open(dev_claim_file, 'r') as f:\n",
        "    dev_claims = json.load(f)\n",
        "with open(evidence_file, 'r') as f:\n",
        "    evidence_corpus = json.load(f)\n",
        "\n",
        "evid_ids = list(evidence_corpus.keys())\n",
        "\n",
        "\n",
        "# Dense retrieval function\n",
        "def dense_retrieve(claim_text: str, top_k: int = 100):\n",
        "    query_vec = model.encode([claim_text], normalize_embeddings=True).astype('float32')\n",
        "    D, I = index.search(query_vec, top_k)\n",
        "    evid_id_score_pairs = [(evid_ids[i], float(D[0][idx])) for idx, i in enumerate(I[0])]\n",
        "    return evid_id_score_pairs\n",
        "\n",
        "# Evaluation + attach retrieval results\n",
        "def evaluate_on_dev_set(claims_data, k=100):\n",
        "    total_claims = 0\n",
        "    recall_hits = 0\n",
        "    exact_hits = 0\n",
        "    total_gold_evids = 0\n",
        "    matched_gold_evids = 0\n",
        "    output_with_retrieval = {}\n",
        "\n",
        "    for cid, entry in tqdm(claims_data.items(), desc=f\"Evaluating @Top-{k} on dev set\"):\n",
        "        claim_text = entry[\"claim_text\"]\n",
        "        gold_ids = set(entry.get(\"evidences\", []))\n",
        "        if not gold_ids:\n",
        "            continue\n",
        "\n",
        "        retrieved = dense_retrieve(claim_text, top_k=k)\n",
        "        retrieved_ids_ordered = [eid for eid, _ in retrieved]\n",
        "        retrieved_set = set(retrieved_ids_ordered)\n",
        "        matched = retrieved_set & gold_ids\n",
        "\n",
        "        total_claims += 1\n",
        "        total_gold_evids += len(gold_ids)\n",
        "        matched_gold_evids += len(matched)\n",
        "\n",
        "        if matched:\n",
        "            recall_hits += 1\n",
        "        if matched == gold_ids:\n",
        "            exact_hits += 1\n",
        "\n",
        "        # Save result in output\n",
        "        output_with_retrieval[cid] = {\n",
        "            \"claim_text\": claim_text,\n",
        "            \"claim_label\": entry.get(\"claim_label\", \"\"),\n",
        "            \"evidences\": list(gold_ids),\n",
        "            \"re_ranked_evidence\": retrieved_ids_ordered,\n",
        "            \"re_ranked_scores\": [round(score, 5) for _, score in retrieved]\n",
        "        }\n",
        "\n",
        "    # Metrics\n",
        "    item_level_recall = matched_gold_evids / total_gold_evids if total_gold_evids > 0 else 0\n",
        "    exact_accuracy = exact_hits / total_claims if total_claims > 0 else 0\n",
        "    recall_hit_rate = recall_hits / total_claims if total_claims > 0 else 0\n",
        "\n",
        "    print(f\"\\n[RoBERTa DPR] Dev Set Evaluation @Top-{k}:\")\n",
        "    print(f\"Claim-level Recall: {item_level_recall:.2%} ({matched_gold_evids}/{total_gold_evids} gold evidences matched)\")\n",
        "    print(f\"Instance-level Accuracy (all gold matched): {exact_accuracy:.2%} ({exact_hits}/{total_claims} claims)\")\n",
        "    print(f\"Recall-hit rate (≥1 gold matched): {recall_hits}/{total_claims} ({recall_hit_rate:.2%})\")\n",
        "\n",
        "    # Save to JSON\n",
        "    with open(output_file, 'w') as f_out:\n",
        "        json.dump(output_with_retrieval, f_out, indent=2)\n",
        "    print(f\"\\nOutput written to: {output_file}\")\n",
        "\n",
        "evaluate_on_dev_set(dev_claims, k=100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcCg60-7v_-Y"
      },
      "source": [
        "## 3.2 Evidence Retrieval - Re-ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZkBkZsMwAG0"
      },
      "source": [
        "### 3.2.1 MiniLM Cross-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZVeNYIH9IaL",
        "outputId": "4967c527-de16-4cc7-aa6c-1d12f93213da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring with MiniLM reranker: 100%|██████████| 154/154 [00:11<00:00, 13.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[MiniLM Cross-Encoder Reranker Evaluation]\n",
            "Avg Recall:    0.3118\n",
            "Avg Precision: 0.1818\n",
            "Avg F1-score:  0.2143\n",
            "Saved Task 4 input to: /content/drive/MyDrive/NLP_content/task4_input_minilm_from_dev.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Config\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "model_path = os.path.join(data_dir, \"reranker_model_final_minilm2\")\n",
        "input_file = os.path.join(data_dir, \"merged_dev_prerank_pool.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "output_path = os.path.join(data_dir, \"task4_input_minilm_from_dev.json\")\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Load data\n",
        "with open(input_file) as f:\n",
        "    rerank_pool = json.load(f)\n",
        "with open(evidence_file) as f:\n",
        "    evidence_corpus = json.load(f)\n",
        "\n",
        "task4_data = []\n",
        "recalls = []\n",
        "precisions = []\n",
        "f1_scores = []\n",
        "\n",
        "for cid, entry in tqdm(rerank_pool.items(), desc=\"Scoring with MiniLM reranker\"):\n",
        "    claim_text = entry[\"claim_text\"]\n",
        "    claim_label = entry.get(\"claim_label\", \"\")\n",
        "    candidates = entry.get(\"pre_ranked_pool\", [])\n",
        "    gold_ids = set(entry.get(\"evidences\", []))\n",
        "\n",
        "    if not claim_text or not candidates:\n",
        "        continue\n",
        "\n",
        "    texts = [evidence_corpus[eid] for eid in candidates if eid in evidence_corpus]\n",
        "    pairs = [(claim_text, txt) for txt in texts]\n",
        "    if not pairs:\n",
        "        continue\n",
        "\n",
        "    encoded = tokenizer.batch_encode_plus(\n",
        "        pairs,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**{k: v.to(device) for k, v in encoded.items()})\n",
        "        # For regression-style model: use logits.squeeze()\n",
        "        # For classification model (num_labels=2): use class 1 probs\n",
        "        if outputs.logits.shape[-1] == 1:\n",
        "            scores = outputs.logits.squeeze()\n",
        "        else:\n",
        "            scores = torch.softmax(outputs.logits, dim=1)[:, 1]\n",
        "\n",
        "    topk_indices = torch.topk(scores, k=min(5, len(scores))).indices.tolist()\n",
        "    topk_ids = [candidates[i] for i in topk_indices]\n",
        "\n",
        "    # Evaluation\n",
        "    if gold_ids:\n",
        "        matched = sum(1 for g in gold_ids if g in topk_ids)\n",
        "        recall = matched / len(gold_ids)\n",
        "        precision = matched / len(topk_ids)\n",
        "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "        recalls.append(recall)\n",
        "        precisions.append(precision)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    task4_data.append({\n",
        "        \"claim_id\": cid,\n",
        "        \"claim_text\": claim_text,\n",
        "        \"claim_label\": claim_label,\n",
        "        \"top_evidence_ids\": topk_ids\n",
        "    })\n",
        "\n",
        "# Save classification-ready export\n",
        "with open(output_path, \"w\") as f:\n",
        "    json.dump(task4_data, f, indent=2)\n",
        "\n",
        "# Print evaluation summary\n",
        "print(\"\\n[MiniLM Cross-Encoder Reranker Evaluation]\")\n",
        "print(f\"Avg Recall:    {np.mean(recalls):.4f}\")\n",
        "print(f\"Avg Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Avg F1-score:  {np.mean(f1_scores):.4f}\")\n",
        "print(f\"Saved Task 4 input to: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPPyWLqkRwex"
      },
      "source": [
        "### 3.2.2 DistilBERT Cross-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grAYkNbYgRFi",
        "outputId": "889200f9-6dfd-4a6b-9aeb-3d8daad11260"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring and evaluating: 100%|██████████| 154/154 [00:32<00:00,  4.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[DistilBERT Cross-Encoder Re-ranker Evaluation]\n",
            "Avg Recall:    0.2184\n",
            "Avg Precision: 0.1182\n",
            "Avg F1-score:  0.1439\n",
            "Saved Task 4 classification input to: /content/drive/MyDrive/NLP_content/task4_input_distilbert_from_dev.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Config\n",
        "data_dir = \"/content/drive/MyDrive/NLP_content\"\n",
        "model_path = os.path.join(data_dir, \"reranker_model_final_distilbert\")\n",
        "input_file = os.path.join(data_dir, \"merged_dev_prerank_pool.json\")\n",
        "evidence_file = os.path.join(data_dir, \"evidence-preprocessed2.json\")\n",
        "output_path = os.path.join(data_dir, \"task4_input_distilbert_from_dev.json\")\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Load data\n",
        "with open(input_file) as f:\n",
        "    rerank_pool = json.load(f)\n",
        "with open(evidence_file) as f:\n",
        "    evidence_corpus = json.load(f)\n",
        "\n",
        "task4_data = []\n",
        "recalls = []\n",
        "precisions = []\n",
        "f1_scores = []\n",
        "\n",
        "for cid, entry in tqdm(rerank_pool.items(), desc=\"Scoring and evaluating\"):\n",
        "    claim_text = entry[\"claim_text\"]\n",
        "    claim_label = entry.get(\"claim_label\", \"\")\n",
        "    candidates = entry.get(\"pre_ranked_pool\", [])\n",
        "    gold_ids = set(entry.get(\"evidences\", []))\n",
        "\n",
        "    if not claim_text or not candidates:\n",
        "        continue\n",
        "\n",
        "    texts = [evidence_corpus[eid] for eid in candidates if eid in evidence_corpus]\n",
        "    pairs = [(claim_text, txt) for txt in texts]\n",
        "    if not pairs:\n",
        "        continue\n",
        "\n",
        "    encoded = tokenizer.batch_encode_plus(\n",
        "        pairs,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**{k: v.to(device) for k, v in encoded.items()})\n",
        "        scores = torch.softmax(outputs.logits, dim=1)[:, 1]  # class 1 = relevant\n",
        "\n",
        "    topk_indices = torch.topk(scores, k=min(5, len(scores))).indices.tolist()\n",
        "    topk_ids = [candidates[i] for i in topk_indices]\n",
        "\n",
        "    # Evaluation metrics\n",
        "    if gold_ids:\n",
        "        matched = sum(1 for g in gold_ids if g in topk_ids)\n",
        "        recall = matched / len(gold_ids)\n",
        "        precision = matched / len(topk_ids)\n",
        "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "        recalls.append(recall)\n",
        "        precisions.append(precision)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Output\n",
        "    task4_data.append({\n",
        "        \"claim_id\": cid,\n",
        "        \"claim_text\": claim_text,\n",
        "        \"claim_label\": claim_label,\n",
        "        \"top_evidence_ids\": topk_ids\n",
        "    })\n",
        "\n",
        "# Save classification-ready output\n",
        "with open(output_path, \"w\") as f:\n",
        "    json.dump(task4_data, f, indent=2)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"\\n[DistilBERT Cross-Encoder Re-ranker Evaluation]\")\n",
        "print(f\"Avg Recall:    {np.mean(recalls):.4f}\")\n",
        "print(f\"Avg Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Avg F1-score:  {np.mean(f1_scores):.4f}\")\n",
        "print(f\"Saved Task 4 classification input to: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25ikWjcGvh_b"
      },
      "source": [
        "## 3.3 Four-Class Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBTu_Mnsv-AE"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0089ae86a72b4d4f8e87473878f3e98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c821b9e138b4a4587d80637946593fd",
            "placeholder": "​",
            "style": "IPY_MODEL_7f5412cae7d84021ba96630a053ef0a9",
            "value": "Map: 100%"
          }
        },
        "0146f95811134b778f2b96cb49697f66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "017cbebcc9294ec797a50ab13c3b8815": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0352425c5228493596c4e6bd0acebce0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0405c3a0280c4ee890b9dd55528c9cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0698e41899824b2f93cb0ef8b52945e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "074286f667084de68831a464d38b7133": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a3366b6fbfa4027a92023f2af454088": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fc222c9d68e4d3b9e408eab62e96ec7",
            "placeholder": "​",
            "style": "IPY_MODEL_da2e03b743c446d9a23844fc145b91cd",
            "value": "config.json: 100%"
          }
        },
        "0b0db236a444411591813b192638c51b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c5abba786834efcbb0fc3e6af4a57d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b9f4b3aa555463bbe05695bcd01f79b",
            "max": 18888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5739169dc8fa45138f57f991b6b9ceeb",
            "value": 18888
          }
        },
        "0c821b9e138b4a4587d80637946593fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d91c88fd5034d879e539fffa211ae8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e453801e8b24aadb134fe4fb7e25d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ffd258ae7f449f191cd7189a7700cc6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10b39e97988848d58d3685d087f56698": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63216aa2e88849c0928c17c29c663c3d",
            "placeholder": "​",
            "style": "IPY_MODEL_0698e41899824b2f93cb0ef8b52945e8",
            "value": " 16402/16402 [00:02&lt;00:00, 5280.36 examples/s]"
          }
        },
        "14b68aa577194b1ab63c12ec607b23b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15572f24bfeb406a87fc79628aa61ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16c6a087fc3b42dc830cc5e04509c1fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1774d0da3e5c4e448f069f15fe5844f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1849298134d3487fa730b33b354de942": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19871eb281914fc0810d95d717bbd6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c819e8e024a44262be4a09d3580b691a",
            "placeholder": "​",
            "style": "IPY_MODEL_7d0c72e274dd4a929fb513733a151588",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "1ae4d182ba8145ec910960cc037f5faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dc2b4637afc42d39fe95daf202285be",
              "IPY_MODEL_bb4a705623d34fe3a1ca80f4b58f7557",
              "IPY_MODEL_89f51ccc2775496f880167da8ea1eadf"
            ],
            "layout": "IPY_MODEL_1b45b8389cf94e488c49b62a43283f48"
          }
        },
        "1b45b8389cf94e488c49b62a43283f48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "1c80ee6343944b0c9eb9e0d38c0cc115": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_210cd858d57e4a258a85471cfac35ec5",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_673e8b94c474446187261a3a8e3d83f0",
            "value": 90868376
          }
        },
        "1f21db38cf98420587b7af56f6120dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6aa85dc139024e979a17a810074f476f",
              "IPY_MODEL_64a52f1ba523441f97aed9de9503b118",
              "IPY_MODEL_63cd1e778208466ab190c9e0c1f99c61"
            ],
            "layout": "IPY_MODEL_6a7e1a62176b47df8de4b36c312d3158"
          }
        },
        "20962f360c2d4a24a197a2c29d849be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77056c33d67c48d2948e44ea43dd6412",
            "placeholder": "​",
            "style": "IPY_MODEL_d25340a09d244f69a81b4f6e9dd46f23",
            "value": " 350/350 [00:00&lt;00:00, 46.2kB/s]"
          }
        },
        "20aa3a5475db40218be2f2515a164488": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8186681c5c3b468891db65493a69d88e",
              "IPY_MODEL_3b76daa4eadb4a9fa95f9dad517ee9ab",
              "IPY_MODEL_f6c172a0952f48b6a89245cd256f538a"
            ],
            "layout": "IPY_MODEL_d5a31385f10948d48a326839053023d0"
          }
        },
        "2103a5a1555d4e29b21776c7940d7a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fb2f04826ea4200a5db4d04e157b1b3",
            "placeholder": "​",
            "style": "IPY_MODEL_82676b84a9ae4f1995d4c4b04ce75eac",
            "value": "Map: 100%"
          }
        },
        "210cd858d57e4a258a85471cfac35ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216f5cceaf234621b364b808ab9f0eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217dbb470042445bbe182584db9d3ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22a8a4a5b09d4731b0746f353fdec15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23bb932ad1764d34bd6cba51794a2041": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23fb174689e942a2b6b560a2b47f9efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87d1df9ec78142bc871b612a7fa0146b",
            "placeholder": "​",
            "style": "IPY_MODEL_be53796edb134a228a96c590b955dd13",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 1.36MB/s]"
          }
        },
        "27e690f1b80f4bdaa6fdbc28ea057275": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "291007ab7474474bb4f14a847eb5ba27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aa26fd385fc47b7b57b146eb9ce809a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bf0772b45a445cd95a374d1eb3723b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bff6428ab684ed3a940099eb1a6c400": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31620a6d010d4a4cb0add4ecbc74e79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31f77a8913644541a2d2779152e38eb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "339dcaf4a3bb4695813fb87f4feafc11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35685f7fc77d438480b182f3116c37f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "360fa62902be4120a71efd323857c9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36e027cf2e38486199cea7fca76bff29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3825a949fa7046aeb5dfeb1c35d0ef30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d3e49bb0e664aa9b8e3a92ee502dd79",
            "placeholder": "​",
            "style": "IPY_MODEL_48c983a1aa3f43b5b746ad1ed93df3e6",
            "value": "README.md: 100%"
          }
        },
        "38c58dfd4a9e4be0bfcf02125798f744": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38d0547ac5e14c3c86d4c1d9e7b537f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39b470e915d84cd9b6dfb2020041f478": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b76daa4eadb4a9fa95f9dad517ee9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_930a1f9b795a4ad490c63c799de0e5e5",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0d44775e5134acb9ff54457fe0c2da7",
            "value": 116
          }
        },
        "3b9586c8cd204d5c8dfb6cac6a584e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f52e9c4ba2847dc9f1506ffc9020473": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d6cd886c6644492aa741e42bcec581d",
            "max": 16402,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a782f642b43477da171c1d01ef22492",
            "value": 16402
          }
        },
        "3fd918f3eca344a59d081cb3f2a0c225": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ff372ec8c2a4dda85906a609c023351": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6ef1de376674965840ca13a20d3b3c5",
            "placeholder": "​",
            "style": "IPY_MODEL_76e867625f6042c39ef6210f507edb65",
            "value": "tokenizer.json: 100%"
          }
        },
        "40b01e7b84394ed3842793bacd30db72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d33a2a451f374928ae1847f9226063b4",
              "IPY_MODEL_1c80ee6343944b0c9eb9e0d38c0cc115",
              "IPY_MODEL_b0f251cafe1b417282b1542fd5055718"
            ],
            "layout": "IPY_MODEL_b92ec1277ab343cb8a0012b78228374c"
          }
        },
        "41319ff5d4884a5c8efab047a599e0e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef6737d68b734469a390c7aab3bc377e",
            "placeholder": "​",
            "style": "IPY_MODEL_360fa62902be4120a71efd323857c9c3",
            "value": "Map: 100%"
          }
        },
        "42e89f08f7bf41aea4cf7b73f64dfe25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "455070d5878b47bb9a7e0f52adc55075": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_604bb16234ad4ff391ab08a3306cd247",
            "placeholder": "​",
            "style": "IPY_MODEL_0e453801e8b24aadb134fe4fb7e25d86",
            "value": "vocab.txt: 100%"
          }
        },
        "48410095b41e4b80a9c0d288cf4e5491": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eac1ebb3c3104f2c9ba18fbef2dd0681",
            "placeholder": "​",
            "style": "IPY_MODEL_75e7fb34345249378d5359fa76083f18",
            "value": " 612/612 [00:00&lt;00:00, 73.7kB/s]"
          }
        },
        "48c983a1aa3f43b5b746ad1ed93df3e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49bb8c7a738141fa968e59f2cc99f829": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a33f42dbf0b4583b141621465d1bf4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b9f4b3aa555463bbe05695bcd01f79b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c30463a6dc04baeb6db1da9a9dbd878": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cafbf81dece421ea0749812587c7a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e27e614d6d544d59d72f09befba9cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef86e22b2934fb58509cfbaa3c766d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e856a14cbaa4e19b5ffeb1a0b93d96c",
            "placeholder": "​",
            "style": "IPY_MODEL_2bff6428ab684ed3a940099eb1a6c400",
            "value": " 53.0/53.0 [00:00&lt;00:00, 5.55kB/s]"
          }
        },
        "4f3786b346c64ae682876cf7b51daf88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb2f04826ea4200a5db4d04e157b1b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "500114f4c7694bb6a94ca0051b7bb7e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5011c2b8cbcf4e64a889285333243ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c69a2249f749dcb1f65e3d2ad86b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0352425c5228493596c4e6bd0acebce0",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b37d9ad9996e4aa8917bac6b5f9a1990",
            "value": 231508
          }
        },
        "5455dafb03544f3998f31f80863454bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5739169dc8fa45138f57f991b6b9ceeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "588b06a179df4ac1aff4663690ff0942": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_825d1df7b821415d829b619abd0b8449",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_017cbebcc9294ec797a50ab13c3b8815",
            "value": 190
          }
        },
        "5940ed873508463d8885dcd7a778a8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac68dd22ae5a4b25a2828c2cd2d5de96",
              "IPY_MODEL_588b06a179df4ac1aff4663690ff0942",
              "IPY_MODEL_c70cd3d4c82245228d005b4c88957586"
            ],
            "layout": "IPY_MODEL_0146f95811134b778f2b96cb49697f66"
          }
        },
        "5983771b1ff84ecebd687bb40600fd14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a30fadc98414f1fbc6a4936c114f1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31f77a8913644541a2d2779152e38eb3",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5983771b1ff84ecebd687bb40600fd14",
            "value": 349
          }
        },
        "5c13d5e47d6f4b0caebf5e1ecbec6d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_455070d5878b47bb9a7e0f52adc55075",
              "IPY_MODEL_51c69a2249f749dcb1f65e3d2ad86b2b",
              "IPY_MODEL_e240989783324999a295455535008f67"
            ],
            "layout": "IPY_MODEL_fb6685afc509401590f055296dd9e35d"
          }
        },
        "5ca1a822c6904ffba99bc59bf1d10930": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f443a057bbdb4874bebdc9cb3a984012",
              "IPY_MODEL_ae10c0be2f2e46f8a3981f1bd8c598f6",
              "IPY_MODEL_4ef86e22b2934fb58509cfbaa3c766d9"
            ],
            "layout": "IPY_MODEL_e82abf7a887d43c798ae1dd265b656c7"
          }
        },
        "5cc1d8dbab77428aaeea0f6391ba6463": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2103a5a1555d4e29b21776c7940d7a9f",
              "IPY_MODEL_3f52e9c4ba2847dc9f1506ffc9020473",
              "IPY_MODEL_a50e820f42cd48689734de1c9b668914"
            ],
            "layout": "IPY_MODEL_7cce747ed7b643c5a43281004b4767e0"
          }
        },
        "5d3e49bb0e664aa9b8e3a92ee502dd79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5eaf0216e46e41448ccde61e5d492ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fdb65e837eb41ac9939c669992436a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "602a6aef87ac4bc39a45789a3d464a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "604bb16234ad4ff391ab08a3306cd247": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63216aa2e88849c0928c17c29c663c3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63cd1e778208466ab190c9e0c1f99c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16c6a087fc3b42dc830cc5e04509c1fb",
            "placeholder": "​",
            "style": "IPY_MODEL_9e66a5966c664fb6980e6d12de64e042",
            "value": " 18888/18888 [03:09&lt;00:00, 132.40it/s]"
          }
        },
        "6409c7b96045486184be7bea5bcfb46f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "644fb0c1e23a4a9aa55cd378d48531c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64a52f1ba523441f97aed9de9503b118": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9609adc6a825429087e1ebdeaf4670b7",
            "max": 18888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0405c3a0280c4ee890b9dd55528c9cb7",
            "value": 18888
          }
        },
        "65099359d482443d9914f4f1473d9a34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673e8b94c474446187261a3a8e3d83f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "678de676cad44f57a4e86a1abaa6771a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e27e614d6d544d59d72f09befba9cd7",
            "placeholder": "​",
            "style": "IPY_MODEL_767245744ff548eabb1fcf5a1910bd65",
            "value": " 466k/466k [00:00&lt;00:00, 14.5MB/s]"
          }
        },
        "69486fbc512f4ea29133c7c072af3b38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a7e1a62176b47df8de4b36c312d3158": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa85dc139024e979a17a810074f476f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38d0547ac5e14c3c86d4c1d9e7b537f0",
            "placeholder": "​",
            "style": "IPY_MODEL_bdc5d2599d3d446d92689b90e738b982",
            "value": "Batches: 100%"
          }
        },
        "6d88b543318d47f2af9d61fafed75f8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f31188390f743d6876373b9e926b927": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e2256e98c840c8baad385c54646cce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74e327f1c4974392af4903eb7001d98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ff372ec8c2a4dda85906a609c023351",
              "IPY_MODEL_de8b890b526e4dd7a52f413c0617d27d",
              "IPY_MODEL_678de676cad44f57a4e86a1abaa6771a"
            ],
            "layout": "IPY_MODEL_35685f7fc77d438480b182f3116c37f5"
          }
        },
        "75e7fb34345249378d5359fa76083f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "766c6b6313c949a198e844f11cf567e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd104672e522448c8c93c02ffe6a1f1c",
              "IPY_MODEL_0c5abba786834efcbb0fc3e6af4a57d3",
              "IPY_MODEL_b0954ecfa15343e99bab6f97c99cf509"
            ],
            "layout": "IPY_MODEL_2bf0772b45a445cd95a374d1eb3723b0"
          }
        },
        "767245744ff548eabb1fcf5a1910bd65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76e867625f6042c39ef6210f507edb65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77056c33d67c48d2948e44ea43dd6412": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "775f3897dc584a9d851b523cfe47c4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79e235cce99b4ff098cb52ecef061d22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b0853bbacf846569f08bacbae7e3b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d88b543318d47f2af9d61fafed75f8f",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f02be075907411cb3b1fc0e8f194211",
            "value": 612
          }
        },
        "7c8da8544f784b9aa50973766d4bcf6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cce747ed7b643c5a43281004b4767e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d0c72e274dd4a929fb513733a151588": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dc2b4637afc42d39fe95daf202285be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c8da8544f784b9aa50973766d4bcf6b",
            "placeholder": "​",
            "style": "IPY_MODEL_d0b970afe07f479aa78b0093f2d3f405",
            "value": "Computing widget examples:   0%"
          }
        },
        "7e3f5b53b8664954b67545935417d2f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e498e87b7294554b1b63db8a2947514": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c0bfdc3ace94d2b9404b6e5813e5f53",
              "IPY_MODEL_d5e381540d2541d5a5eba257712c3a0a",
              "IPY_MODEL_d4c7165e038c4c998e799d4b0cbcb75a"
            ],
            "layout": "IPY_MODEL_0ffd258ae7f449f191cd7189a7700cc6"
          }
        },
        "7f5412cae7d84021ba96630a053ef0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80542cd4de9248f1b990846a4ede99fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eaf0216e46e41448ccde61e5d492ebc",
            "placeholder": "​",
            "style": "IPY_MODEL_c193ea9972114e6193763c1e08b07260",
            "value": "Map: 100%"
          }
        },
        "805e36cb74734913a633d9f12c9b19d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_216f5cceaf234621b364b808ab9f0eb5",
            "placeholder": "​",
            "style": "IPY_MODEL_a8360e40715f48d0b168c90f0058556d",
            "value": " 112/112 [00:00&lt;00:00, 14.8kB/s]"
          }
        },
        "8186681c5c3b468891db65493a69d88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f3786b346c64ae682876cf7b51daf88",
            "placeholder": "​",
            "style": "IPY_MODEL_4cafbf81dece421ea0749812587c7a90",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "825d1df7b821415d829b619abd0b8449": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82676b84a9ae4f1995d4c4b04ce75eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87aaff89a0f244ef82129fb45595e5d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87d1df9ec78142bc871b612a7fa0146b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89f51ccc2775496f880167da8ea1eadf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_291007ab7474474bb4f14a847eb5ba27",
            "placeholder": "​",
            "style": "IPY_MODEL_2aa26fd385fc47b7b57b146eb9ce809a",
            "value": " 0/1 [00:00&lt;?, ?example/s]"
          }
        },
        "8a782f642b43477da171c1d01ef22492": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d6cd886c6644492aa741e42bcec581d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d77c036742e40e896abc183ff53b55d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e02d22155564b5f84be975273ec5af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6495826c4f64603a936972701f256f2",
            "placeholder": "​",
            "style": "IPY_MODEL_644fb0c1e23a4a9aa55cd378d48531c5",
            "value": " 16402/16402 [00:02&lt;00:00, 5994.18 examples/s]"
          }
        },
        "8e45fbf0254844d2abe04aa52c1eaecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41319ff5d4884a5c8efab047a599e0e8",
              "IPY_MODEL_f51e0825565e47a1987cd3589d6b4764",
              "IPY_MODEL_c4ad28135705421d84e96b54defb5097"
            ],
            "layout": "IPY_MODEL_4a33f42dbf0b4583b141621465d1bf4c"
          }
        },
        "8f02be075907411cb3b1fc0e8f194211": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "905025c6281148f6865af7dadfe49455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80542cd4de9248f1b990846a4ede99fb",
              "IPY_MODEL_bb35a9d075ed4decaa32b51430251e8a",
              "IPY_MODEL_10b39e97988848d58d3685d087f56698"
            ],
            "layout": "IPY_MODEL_23bb932ad1764d34bd6cba51794a2041"
          }
        },
        "930a1f9b795a4ad490c63c799de0e5e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93ab1c350b1c4352bf5a48d74021a303": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a3366b6fbfa4027a92023f2af454088",
              "IPY_MODEL_7b0853bbacf846569f08bacbae7e3b95",
              "IPY_MODEL_48410095b41e4b80a9c0d288cf4e5491"
            ],
            "layout": "IPY_MODEL_abfc0d9e53894d668bd4b2fae4e23b97"
          }
        },
        "9609adc6a825429087e1ebdeaf4670b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "988c476294034cd793d6c332c90b3c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a049c36706af4574b615c27c0bfcf21f",
            "placeholder": "​",
            "style": "IPY_MODEL_d3eaa160df0943308591ef2c93aa47e1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9a0b807121644e8995932ff8f132530c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c0bfdc3ace94d2b9404b6e5813e5f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc08d0d5fc745a7874037e178c640e5",
            "placeholder": "​",
            "style": "IPY_MODEL_e72eb0cec3254f65be0e91496cbe45ef",
            "value": "Map: 100%"
          }
        },
        "9e66a5966c664fb6980e6d12de64e042": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e856a14cbaa4e19b5ffeb1a0b93d96c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fc222c9d68e4d3b9e408eab62e96ec7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a049c36706af4574b615c27c0bfcf21f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a06604f7cf3c41ea8b269b4209dad138": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0089ae86a72b4d4f8e87473878f3e98a",
              "IPY_MODEL_a441c1e184ac4157acc41c8f96250eb9",
              "IPY_MODEL_f2bb402ae11a4f15bd78e73098be82db"
            ],
            "layout": "IPY_MODEL_27e690f1b80f4bdaa6fdbc28ea057275"
          }
        },
        "a19c805293c94e51aaf5c0facce36ace": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a284ba47f0194d0dae7a0af2ca3f572b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5595cf0efd5478d9cf9276990928548",
              "IPY_MODEL_5a30fadc98414f1fbc6a4936c114f1c6",
              "IPY_MODEL_d913aea91bd241e08b4ac0270ba66a3f"
            ],
            "layout": "IPY_MODEL_6f31188390f743d6876373b9e926b927"
          }
        },
        "a441c1e184ac4157acc41c8f96250eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5bec42416cc41eb9fcc409ea37d5409",
            "max": 10262,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c61d7d432ae148b8bb4917607f9114a6",
            "value": 10262
          }
        },
        "a50e820f42cd48689734de1c9b668914": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a0b807121644e8995932ff8f132530c",
            "placeholder": "​",
            "style": "IPY_MODEL_0d91c88fd5034d879e539fffa211ae8a",
            "value": " 16402/16402 [00:02&lt;00:00, 6033.04 examples/s]"
          }
        },
        "a6d82789820c4a1f9a50d837b98fe292": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6ef1de376674965840ca13a20d3b3c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8360e40715f48d0b168c90f0058556d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abfc0d9e53894d668bd4b2fae4e23b97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac68dd22ae5a4b25a2828c2cd2d5de96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6409c7b96045486184be7bea5bcfb46f",
            "placeholder": "​",
            "style": "IPY_MODEL_d876af2d1bfe4d189e58400bd35badaf",
            "value": "config.json: 100%"
          }
        },
        "ad3ca0606ca34f10badf7370490293f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae10c0be2f2e46f8a3981f1bd8c598f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fd918f3eca344a59d081cb3f2a0c225",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6d82789820c4a1f9a50d837b98fe292",
            "value": 53
          }
        },
        "b0954ecfa15343e99bab6f97c99cf509": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce256dc69af74e77b99b8ea46811712d",
            "placeholder": "​",
            "style": "IPY_MODEL_f5de222d72cf4d208960841315b77f51",
            "value": " 18888/18888 [15:51&lt;00:00, 71.15it/s]"
          }
        },
        "b0d44775e5134acb9ff54457fe0c2da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0f251cafe1b417282b1542fd5055718": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39b470e915d84cd9b6dfb2020041f478",
            "placeholder": "​",
            "style": "IPY_MODEL_31620a6d010d4a4cb0add4ecbc74e79f",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 62.0MB/s]"
          }
        },
        "b37d9ad9996e4aa8917bac6b5f9a1990": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4366ce21ed7416487bf76f306fa92f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b92ec1277ab343cb8a0012b78228374c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb35a9d075ed4decaa32b51430251e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e72f885b2dd84604a8c3ea77b2f8d732",
            "max": 16402,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b9586c8cd204d5c8dfb6cac6a584e55",
            "value": 16402
          }
        },
        "bb4a705623d34fe3a1ca80f4b58f7557": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4a43c722a8f4073be47cd3482c84687",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22a8a4a5b09d4731b0746f353fdec15a",
            "value": 1
          }
        },
        "bcd962d17143472c9d55de9734155891": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdc5d2599d3d446d92689b90e738b982": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be53796edb134a228a96c590b955dd13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c193ea9972114e6193763c1e08b07260": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3e680a34a894c569353d7d9a31f64ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4ad28135705421d84e96b54defb5097": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b0db236a444411591813b192638c51b",
            "placeholder": "​",
            "style": "IPY_MODEL_c5d29afcf63040fe8416c81b35ebe0b9",
            "value": " 10261/10261 [00:01&lt;00:00, 6496.07 examples/s]"
          }
        },
        "c5d29afcf63040fe8416c81b35ebe0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c61d7d432ae148b8bb4917607f9114a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6495826c4f64603a936972701f256f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c70cd3d4c82245228d005b4c88957586": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4366ce21ed7416487bf76f306fa92f9",
            "placeholder": "​",
            "style": "IPY_MODEL_5455dafb03544f3998f31f80863454bb",
            "value": " 190/190 [00:00&lt;00:00, 24.2kB/s]"
          }
        },
        "c819e8e024a44262be4a09d3580b691a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9bfc86fd751419b87296337e5529943": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca9e22bb375d423db7b183edf7a214da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb110b7dfba04f10996331bebf5b9adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d77c036742e40e896abc183ff53b55d",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcd962d17143472c9d55de9734155891",
            "value": 350
          }
        },
        "cd104672e522448c8c93c02ffe6a1f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca9e22bb375d423db7b183edf7a214da",
            "placeholder": "​",
            "style": "IPY_MODEL_339dcaf4a3bb4695813fb87f4feafc11",
            "value": "Batches: 100%"
          }
        },
        "cdc08d0d5fc745a7874037e178c640e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce256dc69af74e77b99b8ea46811712d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0b970afe07f479aa78b0093f2d3f405": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d25340a09d244f69a81b4f6e9dd46f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d33a2a451f374928ae1847f9226063b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e3f5b53b8664954b67545935417d2f7",
            "placeholder": "​",
            "style": "IPY_MODEL_5fdb65e837eb41ac9939c669992436a4",
            "value": "model.safetensors: 100%"
          }
        },
        "d3eaa160df0943308591ef2c93aa47e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4c7165e038c4c998e799d4b0cbcb75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9bfc86fd751419b87296337e5529943",
            "placeholder": "​",
            "style": "IPY_MODEL_775f3897dc584a9d851b523cfe47c4fc",
            "value": " 10262/10262 [00:01&lt;00:00, 6158.79 examples/s]"
          }
        },
        "d5a31385f10948d48a326839053023d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5e381540d2541d5a5eba257712c3a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a19c805293c94e51aaf5c0facce36ace",
            "max": 10262,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e50e8fcfe5a046fda71d5485f73baba1",
            "value": 10262
          }
        },
        "d8560020a05743b5bfd8168f642be38e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d876af2d1bfe4d189e58400bd35badaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d913aea91bd241e08b4ac0270ba66a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deb15ee6cbb449f2a71b3bd887b0b522",
            "placeholder": "​",
            "style": "IPY_MODEL_fcf1401362b74fd08dba2422d4b9badb",
            "value": " 349/349 [00:00&lt;00:00, 42.5kB/s]"
          }
        },
        "da2e03b743c446d9a23844fc145b91cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "daef646174374fa38180b33de07f9a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15572f24bfeb406a87fc79628aa61ef5",
            "placeholder": "​",
            "style": "IPY_MODEL_c3e680a34a894c569353d7d9a31f64ae",
            "value": "Map: 100%"
          }
        },
        "de8b890b526e4dd7a52f413c0617d27d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42e89f08f7bf41aea4cf7b73f64dfe25",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1774d0da3e5c4e448f069f15fe5844f6",
            "value": 466247
          }
        },
        "deb15ee6cbb449f2a71b3bd887b0b522": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1f914c5af7347178403e9664b3f94ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79e235cce99b4ff098cb52ecef061d22",
            "max": 16402,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_074286f667084de68831a464d38b7133",
            "value": 16402
          }
        },
        "e240989783324999a295455535008f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69486fbc512f4ea29133c7c072af3b38",
            "placeholder": "​",
            "style": "IPY_MODEL_1849298134d3487fa730b33b354de942",
            "value": " 232k/232k [00:00&lt;00:00, 528kB/s]"
          }
        },
        "e4a43c722a8f4073be47cd3482c84687": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e50e8fcfe5a046fda71d5485f73baba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e545d983a5bd4936aa1a1e2de1789cba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5595cf0efd5478d9cf9276990928548": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36e027cf2e38486199cea7fca76bff29",
            "placeholder": "​",
            "style": "IPY_MODEL_217dbb470042445bbe182584db9d3ee7",
            "value": "modules.json: 100%"
          }
        },
        "e5a71e51937a426fbfcf42cec7a09b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_daef646174374fa38180b33de07f9a3c",
              "IPY_MODEL_e1f914c5af7347178403e9664b3f94ab",
              "IPY_MODEL_8e02d22155564b5f84be975273ec5af9"
            ],
            "layout": "IPY_MODEL_14b68aa577194b1ab63c12ec607b23b0"
          }
        },
        "e72eb0cec3254f65be0e91496cbe45ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e72f885b2dd84604a8c3ea77b2f8d732": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e82abf7a887d43c798ae1dd265b656c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e92e5a35908b43a793ca49da2bc83f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7f2b9ce9cf549f784c33df8c06093ea",
            "max": 10454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49bb8c7a738141fa968e59f2cc99f829",
            "value": 10454
          }
        },
        "ea7d1b0add57479b872a48e446d5f9cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_988c476294034cd793d6c332c90b3c91",
              "IPY_MODEL_cb110b7dfba04f10996331bebf5b9adc",
              "IPY_MODEL_20962f360c2d4a24a197a2c29d849be7"
            ],
            "layout": "IPY_MODEL_4c30463a6dc04baeb6db1da9a9dbd878"
          }
        },
        "eac1ebb3c3104f2c9ba18fbef2dd0681": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef6737d68b734469a390c7aab3bc377e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f02b3927d026487f9683b8036a7b95ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2bb402ae11a4f15bd78e73098be82db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e545d983a5bd4936aa1a1e2de1789cba",
            "placeholder": "​",
            "style": "IPY_MODEL_f02b3927d026487f9683b8036a7b95ac",
            "value": " 10262/10262 [00:01&lt;00:00, 5872.96 examples/s]"
          }
        },
        "f32f048c6f274ff79396def6c867d640": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19871eb281914fc0810d95d717bbd6e2",
              "IPY_MODEL_f391e1b820e44f7f91d41ed293a33b74",
              "IPY_MODEL_805e36cb74734913a633d9f12c9b19d4"
            ],
            "layout": "IPY_MODEL_65099359d482443d9914f4f1473d9a34"
          }
        },
        "f391e1b820e44f7f91d41ed293a33b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38c58dfd4a9e4be0bfcf02125798f744",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad3ca0606ca34f10badf7370490293f4",
            "value": 112
          }
        },
        "f443a057bbdb4874bebdc9cb3a984012": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71e2256e98c840c8baad385c54646cce",
            "placeholder": "​",
            "style": "IPY_MODEL_500114f4c7694bb6a94ca0051b7bb7e8",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "f462b1fb993f4d17871e93d9f6d137c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f51e0825565e47a1987cd3589d6b4764": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f462b1fb993f4d17871e93d9f6d137c7",
            "max": 10261,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8560020a05743b5bfd8168f642be38e",
            "value": 10261
          }
        },
        "f5bec42416cc41eb9fcc409ea37d5409": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5de222d72cf4d208960841315b77f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6c172a0952f48b6a89245cd256f538a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5011c2b8cbcf4e64a889285333243ea6",
            "placeholder": "​",
            "style": "IPY_MODEL_602a6aef87ac4bc39a45789a3d464a35",
            "value": " 116/116 [00:00&lt;00:00, 13.1kB/s]"
          }
        },
        "f7f2b9ce9cf549f784c33df8c06093ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa7d869ed6a44920816669ff19107f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3825a949fa7046aeb5dfeb1c35d0ef30",
              "IPY_MODEL_e92e5a35908b43a793ca49da2bc83f45",
              "IPY_MODEL_23fb174689e942a2b6b560a2b47f9efb"
            ],
            "layout": "IPY_MODEL_87aaff89a0f244ef82129fb45595e5d7"
          }
        },
        "fb6685afc509401590f055296dd9e35d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcf1401362b74fd08dba2422d4b9badb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
